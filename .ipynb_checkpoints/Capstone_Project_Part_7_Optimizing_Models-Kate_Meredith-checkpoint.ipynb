{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953ed9c0",
   "metadata": {},
   "source": [
    "# Capstone Project Part 7: Optimizing Models\n",
    "\n",
    "**Authur:** Kate Meredith \n",
    "\n",
    "**Date:** September-November 2022\n",
    "\n",
    "**Notebook #**: 7 of\n",
    "\n",
    "## Background\n",
    "\n",
    "**Source:** Data was collected from [CoffeeReview.com](https://www.coffeereview.com/). See prior notebooks for details on scraping, cleaning, compilation and text transformation. \n",
    "\n",
    "**Goal:** Optimize models on full data set (both text transformed and original numerical values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2d3d1",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Documentation on [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- Documentation on [Lasso Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- Documentation on [ElasticNet Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)\n",
    "- [Differences](https://towardsdatascience.com/whats-the-difference-between-linear-regression-lasso-ridge-and-elasticnet-8f997c60cf29) between linear, ridge, lasso and elastic net regression\n",
    "- How to [add headers back after scaling data](https://stackoverflow.com/questions/29586323/how-to-retain-column-headers-of-data-frame-after-pre-processing-in-scikit-learn)\n",
    "- Getting model [results as a dataframe](https://stackoverflow.com/questions/51734180/converting-statsmodels-summary-object-to-pandas-dataframe)\n",
    "- Using first row as [column headers](https://stackoverflow.com/questions/31328861/python-pandas-replacing-header-with-top-row)\n",
    "- Filtering sorted array to [get top N values](https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d4ee2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Importing Libraries](#header1)\n",
    "* [2. Importing the Data and EDA](#header2)\n",
    "* [3. Scaling the Data](#header3)\n",
    "* [4. Principal Component Analysis](#header4)\n",
    "* [5. Optimizing the Models](#header5)\n",
    "    * [5.1 Linear Regression](#subheader51)\n",
    "    * [5.2 XGBoost Regressor](#subheader52)\n",
    "* [6. Comparing all Models](#header6)\n",
    "* [7. Further Model Interpretation](#header7)\n",
    "    * [7.1 Using Stats Models for Additional Insights](#subheader71)\n",
    "    * [7.2 SKLearn Elastic Net Model Interpretation](#subheader72)\n",
    "* [8. Conclusion](#header8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235584d",
   "metadata": {},
   "source": [
    "## Importing Libraries  <a class=\"anchor\" id=\"header1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3552bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tempfile import mkdtemp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95567a0a",
   "metadata": {},
   "source": [
    "## 2. Importing the Data and EDA <a class=\"anchor\" id=\"header2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113fe582",
   "metadata": {},
   "source": [
    "In the last notebook, the text was transformed using a few different methods. Given time limitations, this will move forward with the data transformation method that worked best: TFIDF Vectorization. The data has already been split into remain (training), validation, and test data. These datasets will be imported here to use.\n",
    "\n",
    "Importing the remain (training) data and exploring some initial info about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1884d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4194 entries, 0 to 4193\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(621), int64(9), object(2)\n",
      "memory usage: 20.2+ MB\n"
     ]
    }
   ],
   "source": [
    "Xremain_df_tfidf = pd.read_csv('tfidf_Xremain_combo_df.csv')\n",
    "Xremain_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed88598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 632)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d7791",
   "metadata": {},
   "source": [
    "The remain data set has 4,194 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13558f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honeymoon Espresso</td>\n",
       "      <td>Choosy Gourmet</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medium-Dark Roast</td>\n",
       "      <td>Kona Love Coffee Co.</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>46</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kathakwa Kenya</td>\n",
       "      <td>Caribou Coffee</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Costa Rica Geisha Honey COE 2018 2nd Place</td>\n",
       "      <td>Dragonfly Coffee Roasters</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>50</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taitung Guanshan Lot 12 (Single-Serve Capsule)</td>\n",
       "      <td>Sancoffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      coffee_name               roaster_name  \\\n",
       "0                              Honeymoon Espresso             Choosy Gourmet   \n",
       "1                               Medium-Dark Roast       Kona Love Coffee Co.   \n",
       "2                                  Kathakwa Kenya             Caribou Coffee   \n",
       "3      Costa Rica Geisha Honey COE 2018 2nd Place  Dragonfly Coffee Roasters   \n",
       "4  Taitung Guanshan Lot 12 (Single-Serve Capsule)                  Sancoffee   \n",
       "\n",
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  ...  \\\n",
       "0      3  2020           44             52      9        8     8       9  ...   \n",
       "1      2  2022           46             64      8        8     9       9  ...   \n",
       "2      8  2014           52             66      9        8     9       9  ...   \n",
       "3     11  2018           50             76      9        9     9       9  ...   \n",
       "4      2  2015           86             86      8        7     8       8  ...   \n",
       "\n",
       "   wild  willem  wine  winey  winy  wisteria      wood  woody  zest  zesty  \n",
       "0   0.0     0.0   0.0    0.0   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "1   0.0     0.0   0.0    0.0   0.0       0.0  0.215396    0.0   0.0    0.0  \n",
       "2   0.0     0.0   0.0    0.0   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "3   0.0     0.0   0.0    0.0   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "4   0.0     0.0   0.0    0.0   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8d9ea",
   "metadata": {},
   "source": [
    "Most of the columns come from the vectorized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8749f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1049 entries, 0 to 1048\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(619), int64(11), object(2)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#importing the validation data and checking out the info\n",
    "Xval_df_tfidf = pd.read_csv('tfidf_Xval_combo_df.csv')\n",
    "Xval_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313c5ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 632)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd1a98",
   "metadata": {},
   "source": [
    "The validation data set has 1,049 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069355df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ardent Ethiopia Natural</td>\n",
       "      <td>JBC Coffee Roasters</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mocha Java, Harrar Style</td>\n",
       "      <td>Susan's Coffee and Tea</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sulawesi Toraja Peaberry</td>\n",
       "      <td>P.T. Mega Agmist Indonesia</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worka Ethiopia</td>\n",
       "      <td>JBC Coffee Roasters</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethiopia Oromia</td>\n",
       "      <td>Caffe Luxxe</td>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>49</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                coffee_name                roaster_name  month  year  \\\n",
       "0   Ardent Ethiopia Natural         JBC Coffee Roasters     11  2020   \n",
       "1  Mocha Java, Harrar Style      Susan's Coffee and Tea      1  1998   \n",
       "2  Sulawesi Toraja Peaberry  P.T. Mega Agmist Indonesia      6  2012   \n",
       "3            Worka Ethiopia         JBC Coffee Roasters      8  2016   \n",
       "4           Ethiopia Oromia                 Caffe Luxxe      8  2017   \n",
       "\n",
       "   bean_agtron  ground_agtron  aroma  acidity  body  flavor  ...  wild  \\\n",
       "0           57             77     10        9     9      10  ...   0.0   \n",
       "1           43             49      5        4     5       5  ...   0.0   \n",
       "2           48             73      8        9     9       9  ...   0.0   \n",
       "3           58             78      9        9     9       9  ...   0.0   \n",
       "4           49             72      9        8     9       9  ...   0.0   \n",
       "\n",
       "   willem  wine  winey  winy  wisteria     wood  woody  zest  zesty  \n",
       "0     0.0   0.0    0.0   0.0       0.0  0.00000    0.0   0.0    0.0  \n",
       "1     0.0   0.0    0.0   0.0       0.0  0.00000    0.0   0.0    0.0  \n",
       "2     0.0   0.0    0.0   0.0       0.0  0.00000    0.0   0.0    0.0  \n",
       "3     0.0   0.0    0.0   0.0       0.0  0.00000    0.0   0.0    0.0  \n",
       "4     0.0   0.0    0.0   0.0       0.0  0.19191    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad82135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(620), int64(10), object(2)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#importing the test data and checking out the info\n",
    "Xtest_df_tfidf = pd.read_csv('tfidf_Xtest_combo_df.csv')\n",
    "Xtest_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be65476a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 632)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b02b9a",
   "metadata": {},
   "source": [
    "The test dataframe has 1311 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619f35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PBS Blend K-Cup</td>\n",
       "      <td>Green Mountain Coffee</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washed Yirgacheffe</td>\n",
       "      <td>Bird Rock Coffee Roasters</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rwanda Coopac Cooperative</td>\n",
       "      <td>Wonderstate Coffee</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India Badnekhan Estate</td>\n",
       "      <td>Devon Plantations</td>\n",
       "      <td>8</td>\n",
       "      <td>2002</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India Monsooned Malabar</td>\n",
       "      <td>Mayorga Coffee Roasters</td>\n",
       "      <td>7</td>\n",
       "      <td>2004</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coffee_name               roaster_name  month  year  \\\n",
       "0            PBS Blend K-Cup      Green Mountain Coffee      4  2007   \n",
       "1         Washed Yirgacheffe  Bird Rock Coffee Roasters      7  2014   \n",
       "2  Rwanda Coopac Cooperative         Wonderstate Coffee      6  2009   \n",
       "3     India Badnekhan Estate          Devon Plantations      8  2002   \n",
       "4    India Monsooned Malabar    Mayorga Coffee Roasters      7  2004   \n",
       "\n",
       "   bean_agtron  ground_agtron  aroma  acidity  body  flavor  ...  wild  \\\n",
       "0           50             50      7        7     7       7  ...   0.0   \n",
       "1           54             76      9        9     8       9  ...   0.0   \n",
       "2           53             68      8        8     8       8  ...   0.0   \n",
       "3           47             45      9        8     7       8  ...   0.0   \n",
       "4           35             47      7        7     8       7  ...   0.0   \n",
       "\n",
       "   willem  wine     winey  winy  wisteria      wood  woody  zest  zesty  \n",
       "0     0.0   0.0  0.000000   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "1     0.0   0.0  0.000000   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "2     0.0   0.0  0.000000   0.0       0.0  0.204984    0.0   0.0    0.0  \n",
       "3     0.0   0.0  0.275726   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "4     0.0   0.0  0.000000   0.0       0.0  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bc3c5",
   "metadata": {},
   "source": [
    "Importing the y values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9c15b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             92\n",
       "1             91\n",
       "2             93\n",
       "3             94\n",
       "4             88"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_remain_df = pd.read_csv('y_remain_df.csv')\n",
    "y_remain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8ea157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92\n",
       "1       91\n",
       "2       93\n",
       "3       94\n",
       "4       88\n",
       "        ..\n",
       "4189    88\n",
       "4190    94\n",
       "4191    92\n",
       "4192    93\n",
       "4193    92\n",
       "Name: overall_score, Length: 4194, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_remain = y_remain_df['overall_score']\n",
    "y_remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4629e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             97\n",
       "1             79\n",
       "2             93\n",
       "3             95\n",
       "4             93"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_df = pd.read_csv('y_val_df.csv')\n",
    "y_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f42d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       97\n",
       "1       79\n",
       "2       93\n",
       "3       95\n",
       "4       93\n",
       "        ..\n",
       "1044    94\n",
       "1045    94\n",
       "1046    87\n",
       "1047    94\n",
       "1048    90\n",
       "Name: overall_score, Length: 1049, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_val = y_val_df['overall_score']\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4f5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             85\n",
       "1             94\n",
       "2             90\n",
       "3             92\n",
       "4             83"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.read_csv('y_test_df.csv')\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7130df20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       85\n",
       "1       94\n",
       "2       90\n",
       "3       92\n",
       "4       83\n",
       "        ..\n",
       "1306    95\n",
       "1307    91\n",
       "1308    93\n",
       "1309    89\n",
       "1310    93\n",
       "Name: overall_score, Length: 1311, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_test = y_test_df['overall_score']\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4966e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying no null values introduced during vectorizing process\n",
    "Xremain_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e39c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1093d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c57fc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_remain.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d362a7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59014536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f722192",
   "metadata": {},
   "source": [
    "Dropping the remaining text columns `coffee_name` and `roaster_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3080792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremain_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b89be237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>22.620335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>46</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19.623815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>44.977300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>50</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>40.015416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>25.045275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0      3  2020           44             52      9        8     8       9   \n",
       "1      2  2022           46             64      8        8     9       9   \n",
       "2      8  2014           52             66      9        8     9       9   \n",
       "3     11  2018           50             76      9        9     9       9   \n",
       "4      2  2015           86             86      8        7     8       8   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  wild  willem  wine  winey  winy  wisteria  \\\n",
       "0           8    22.620335  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "1           7    19.623815  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "2           8    44.977300  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "3           8    40.015416  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "4           7    25.045275  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "\n",
       "       wood  woody  zest  zesty  \n",
       "0  0.000000    0.0   0.0    0.0  \n",
       "1  0.215396    0.0   0.0    0.0  \n",
       "2  0.000000    0.0   0.0    0.0  \n",
       "3  0.000000    0.0   0.0    0.0  \n",
       "4  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d51e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b86eeff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>43.074761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>41.083064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>23.128402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>43.074761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>49</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34.019470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0     11  2020           57             77     10        9     9      10   \n",
       "1      1  1998           43             49      5        4     5       5   \n",
       "2      6  2012           48             73      8        9     9       9   \n",
       "3      8  2016           58             78      9        9     9       9   \n",
       "4      8  2017           49             72      9        8     9       9   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  wild  willem  wine  winey  winy  wisteria  \\\n",
       "0           9    43.074761  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "1           5    41.083064  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "2           8    23.128402  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "3           9    43.074761  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "4           8    34.019470  ...   0.0     0.0   0.0    0.0   0.0       0.0   \n",
       "\n",
       "      wood  woody  zest  zesty  \n",
       "0  0.00000    0.0   0.0    0.0  \n",
       "1  0.00000    0.0   0.0    0.0  \n",
       "2  0.00000    0.0   0.0    0.0  \n",
       "3  0.00000    0.0   0.0    0.0  \n",
       "4  0.19191    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52ac45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23af1cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>44.337125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>32.840162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>43.556917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2002</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12.976794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.275726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2004</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>39.081798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0      4  2007           50             50      7        7     7       7   \n",
       "1      7  2014           54             76      9        9     8       9   \n",
       "2      6  2009           53             68      8        8     8       8   \n",
       "3      8  2002           47             45      9        8     7       8   \n",
       "4      7  2004           35             47      7        7     8       7   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  wild  willem  wine     winey  winy  wisteria  \\\n",
       "0           7    44.337125  ...   0.0     0.0   0.0  0.000000   0.0       0.0   \n",
       "1           9    32.840162  ...   0.0     0.0   0.0  0.000000   0.0       0.0   \n",
       "2           8    43.556917  ...   0.0     0.0   0.0  0.000000   0.0       0.0   \n",
       "3           8    12.976794  ...   0.0     0.0   0.0  0.275726   0.0       0.0   \n",
       "4           7    39.081798  ...   0.0     0.0   0.0  0.000000   0.0       0.0   \n",
       "\n",
       "       wood  woody  zest  zesty  \n",
       "0  0.000000    0.0   0.0    0.0  \n",
       "1  0.000000    0.0   0.0    0.0  \n",
       "2  0.204984    0.0   0.0    0.0  \n",
       "3  0.000000    0.0   0.0    0.0  \n",
       "4  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36a60a",
   "metadata": {},
   "source": [
    "## 3. Scaling the Data <a class=\"anchor\" id=\"header3\"></a>\n",
    "\n",
    "While scaling isn't required for all the model types (like linear regression), we'll go ahead and scale now to simplify the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "347b51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting min max scaler on remain data\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(Xremain_df_tfidf)\n",
    "\n",
    "#transforming the all the X data\n",
    "X_mm_scaled_remain = mm_scaler.transform(Xremain_df_tfidf)\n",
    "X_mm_scaled_val = mm_scaler.transform(Xval_df_tfidf)\n",
    "X_mm_scaled_test = mm_scaler.transform(Xtest_df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fed3cae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18181818, 0.92      , 0.44      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.09090909, 1.        , 0.46666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63636364, 0.68      , 0.54666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.92      , 0.44      , ..., 0.        , 0.44691187,\n",
       "        0.        ],\n",
       "       [0.        , 0.84      , 0.65333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.54545455, 0.76      , 0.6       , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview scaled date\n",
    "X_mm_scaled_remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cf71317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.559541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.806526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.758189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.612355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.181818  0.92     0.440000       0.459770  0.875  0.777778  0.666667   \n",
       "1  0.090909  1.00     0.466667       0.597701  0.750  0.777778  0.833333   \n",
       "2  0.636364  0.68     0.546667       0.620690  0.875  0.777778  0.833333   \n",
       "3  0.909091  0.84     0.520000       0.735632  0.875  0.888889  0.833333   \n",
       "4  0.090909  0.72     1.000000       0.850575  0.750  0.666667  0.666667   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  wild  willem  wine  winey  winy  \\\n",
       "0  0.888889       0.750     0.588732  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "1  0.888889       0.625     0.559541  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "2  0.888889       0.750     0.806526  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "3  0.888889       0.750     0.758189  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "4  0.777778       0.625     0.612355  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "\n",
       "   wisteria      wood  woody  zest  zesty  \n",
       "0       0.0  0.000000    0.0   0.0    0.0  \n",
       "1       0.0  0.377216    0.0   0.0    0.0  \n",
       "2       0.0  0.000000    0.0   0.0    0.0  \n",
       "3       0.0  0.000000    0.0   0.0    0.0  \n",
       "4       0.0  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_remain = pd.DataFrame(X_mm_scaled_remain, columns = Xremain_df_tfidf.columns)\n",
    "\n",
    "#verify headers added back\n",
    "X_mm_scaled_remain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1557bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90909091, 0.92      , 0.61333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.04      , 0.42666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45454545, 0.6       , 0.49333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.72727273, 0.32      , 0.34666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63636364, 0.44      , 0.49333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.54545455, 0.6       , 0.50666667, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm_scaled_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91639020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.787992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.593681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.787992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.699778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.909091  0.92     0.613333       0.747126  1.000  0.888889  0.833333   \n",
       "1  0.000000  0.04     0.426667       0.425287  0.375  0.333333  0.166667   \n",
       "2  0.454545  0.60     0.493333       0.701149  0.750  0.888889  0.833333   \n",
       "3  0.636364  0.76     0.626667       0.758621  0.875  0.888889  0.833333   \n",
       "4  0.636364  0.80     0.506667       0.689655  0.875  0.777778  0.833333   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  wild  willem  wine  winey  winy  \\\n",
       "0  1.000000       0.875     0.787992  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "1  0.444444       0.375     0.768589  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "2  0.888889       0.750     0.593681  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "3  0.888889       0.875     0.787992  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "4  0.888889       0.750     0.699778  ...   0.0     0.0   0.0    0.0   0.0   \n",
       "\n",
       "   wisteria      wood  woody  zest  zesty  \n",
       "0       0.0  0.000000    0.0   0.0    0.0  \n",
       "1       0.0  0.000000    0.0   0.0    0.0  \n",
       "2       0.0  0.000000    0.0   0.0    0.0  \n",
       "3       0.0  0.000000    0.0   0.0    0.0  \n",
       "4       0.0  0.336086    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_val = pd.DataFrame(X_mm_scaled_val, columns = Xval_df_tfidf.columns)\n",
    "X_mm_scaled_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362fb5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27272727, 0.4       , 0.52      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.54545455, 0.68      , 0.57333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45454545, 0.48      , 0.56      , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.54545455, 0.84      , 0.57333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36363636, 0.52      , 0.37333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.8       , 0.62666667, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm_scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06b5f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winey</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.800289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.688290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.792689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.494788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.749094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.272727  0.40     0.520000       0.436782  0.625  0.666667  0.500000   \n",
       "1  0.545455  0.68     0.573333       0.735632  0.875  0.888889  0.666667   \n",
       "2  0.454545  0.48     0.560000       0.643678  0.750  0.777778  0.666667   \n",
       "3  0.636364  0.20     0.480000       0.379310  0.875  0.777778  0.500000   \n",
       "4  0.545455  0.28     0.320000       0.402299  0.625  0.666667  0.666667   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  wild  willem  wine     winey  winy  \\\n",
       "0  0.666667       0.625     0.800289  ...   0.0     0.0   0.0  0.000000   0.0   \n",
       "1  0.888889       0.875     0.688290  ...   0.0     0.0   0.0  0.000000   0.0   \n",
       "2  0.777778       0.750     0.792689  ...   0.0     0.0   0.0  0.000000   0.0   \n",
       "3  0.777778       0.750     0.494788  ...   0.0     0.0   0.0  0.554661   0.0   \n",
       "4  0.666667       0.625     0.749094  ...   0.0     0.0   0.0  0.000000   0.0   \n",
       "\n",
       "   wisteria      wood  woody  zest  zesty  \n",
       "0       0.0  0.000000    0.0   0.0    0.0  \n",
       "1       0.0  0.000000    0.0   0.0    0.0  \n",
       "2       0.0  0.358982    0.0   0.0    0.0  \n",
       "3       0.0  0.000000    0.0   0.0    0.0  \n",
       "4       0.0  0.000000    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_test = pd.DataFrame(X_mm_scaled_test, columns = Xtest_df_tfidf.columns)\n",
    "X_mm_scaled_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4ce64",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis <a class=\"anchor\" id=\"header4\"></a>\n",
    "\n",
    "Given the number of dimensions in this dataset, simplifying our dimensions will may be beneficial. To do so, Pricipal Component Analysis (PCA) will be applied. However, we do lose interpretability with PCA. Therefore,  the models will be compared using PCA and the non-simplified data. If performance is similar, the non-simplified data can be used in order to retain interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "456f96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate and fit the PCA model\n",
    "my_PCA = PCA(n_components = 0.9) #retaining 90% of the variance\n",
    "my_PCA.fit(X_mm_scaled_val)\n",
    "\n",
    "# transform data \n",
    "X_remain_PCA = my_PCA.transform(X_mm_scaled_remain)\n",
    "X_val_PCA = my_PCA.transform(X_mm_scaled_val)\n",
    "X_test_PCA = my_PCA.transform(X_mm_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d187e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance captured by PC1:  0.253\n",
      "Variance captured by PC2:  0.152\n",
      "Proportion of variance captured by PC1:  0.049\n",
      "Proportion of variance captured by PC2:  0.030\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variance captured by PC1: {my_PCA.explained_variance_[0]: 0.3f}\")\n",
    "print(f\"Variance captured by PC2: {my_PCA.explained_variance_[1]: 0.3f}\")\n",
    "\n",
    "print(f\"Proportion of variance captured by PC1: {my_PCA.explained_variance_ratio_[0]: 0.3f}\")\n",
    "print(f\"Proportion of variance captured by PC2: {my_PCA.explained_variance_ratio_[1]: 0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4f7be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (4194, 630)\n",
      "PCA Transformed: (4194, 277)\n"
     ]
    }
   ],
   "source": [
    "print(f'Original: {Xremain_df_tfidf.shape}')\n",
    "print(f'PCA Transformed: {X_remain_PCA.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaee630",
   "metadata": {},
   "source": [
    "PCA is able to capture 90% of the variance while decreasing the number of features significantly to 280 (down from 630)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71290779",
   "metadata": {},
   "source": [
    "## 5. Fitting the Models <a class=\"anchor\" id=\"header5\"></a>\n",
    "\n",
    "Below will fit each of the models, trying both the 'full' dataset and the PCA dataset. In all of these, the data is scaled. At the end, R2 results will be compared across all models.\n",
    "\n",
    "### 5.1 Linear Regression <a class=\"anchor\" id=\"subheader51\"></a>\n",
    "\n",
    "**\"Vanilla\" Linear Regression** \n",
    "\n",
    "This first uses a basic, \"vanilla\" linear regression model. This is what we used in previous notebooks to check in on how our data transformations were performing.\n",
    "\n",
    "For reference:\n",
    "- The best validation data R2 from running Linear Regression on the text data alone was about 0.761.\n",
    "- The best validation data R2 from running Linear Regression on the numeric data alone (meaning no vectorized text) was about 0.898.\n",
    "\n",
    "**Linear Regression: Min Max, Full Dataset**\n",
    " \n",
    "Below runs the model on the full, scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2b29d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_full training data is: 0.9408817380239718\n",
      "The R2 score for lr_model_full validation data is: 0.9025842705674784\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "lr_model_full = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "lr_model_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_full training data is: {lr_model_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_full_val_r2 = lr_model_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_full validation data is: {lr_model_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747bbd0",
   "metadata": {},
   "source": [
    "**Linear Regression: Min Max, PCA Dataset**\n",
    " \n",
    "Below runs the model on the simplified, scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "af9a091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_pca training data is: 0.9201855216374213\n",
      "The R2 score for lr_model_pca validation data is: 0.8959728426048407\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "lr_model_pca = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "lr_model_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_pca training data is: {lr_model_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_pca_val_r2 = lr_model_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_pca validation data is: {lr_model_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb4194",
   "metadata": {},
   "source": [
    "Interestingly, the full dataset does slightly better than the PCA version. This may be because using PCA did trade some information for fewer dimensions (e.g. fewer columns). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f795c",
   "metadata": {},
   "source": [
    "**Ridge Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Ridge Regression model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a7f47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Ridge()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a9f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [6.2], \n",
    "    \"model__solver\": ['sag'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09a19adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 6.2, 'model__solver': 'sag'}\n",
      "Best score: 0.9120997478973498\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48932369",
   "metadata": {},
   "source": [
    "Below will see how these parameters do with our remain (training) and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d86cae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_ridge_full training data is: 0.9359693918542785\n",
      "The R2 score for lr_model_ridge_full validation data is: 0.9098745867302618\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_ridge_full = Ridge(alpha=6.2, solver='sag')\n",
    "lr_model_ridge_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_ridge_full training data is: {lr_model_ridge_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_ridge_full_val_r2 = lr_model_ridge_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_ridge_full validation data is: {lr_model_ridge_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaccdb2",
   "metadata": {},
   "source": [
    "**Ridge Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Ridge Regression model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "749def42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Ridge()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef009b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [3.5], \n",
    "    \"model__solver\": ['sag'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ce030db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 3.5, 'model__solver': 'sag'}\n",
      "Best score: 0.9068516513539085\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262eb2dd",
   "metadata": {},
   "source": [
    "Ridge regression on the PCA data does slightly less well than the full dataset. The best parameters for it are shown above. Below will see how these do with the remain and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6731068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_ridge_pca training data is: 0.9194928820732233\n",
      "The R2 score for lr_model_ridge_pca validation data is: 0.9011979701874846\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_ridge_pca = Ridge(alpha=3.5, solver='sag')\n",
    "lr_model_ridge_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_ridge_pca training data is: {lr_model_ridge_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_ridge_pca_val_r2 = lr_model_ridge_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_ridge_pca validation data is: {lr_model_ridge_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376d1c2",
   "metadata": {},
   "source": [
    "**Lasso Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Lasso Regression model using the full datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16b58c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Lasso()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65f76f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__positive\": [False],\n",
    "    \"model__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abb37dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9131574911589692\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1ae01",
   "metadata": {},
   "source": [
    "The optimal Lasso Regression model uses parameters are shown above. Below will see how the model does with training and validation data using these optimized paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6552a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_lasso_full training data is: 0.9270599542538364\n",
      "The R2 score for lr_model_lasso_full validation data is: 0.907597542099871\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_lasso_full = Lasso(alpha=0.002, positive=False, warm_start=True)\n",
    "lr_model_lasso_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_lasso_full training data is: {lr_model_lasso_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_lasso_full_val_r2 = lr_model_lasso_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_lasso_full validation data is: {lr_model_lasso_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db305a92",
   "metadata": {},
   "source": [
    "**Lasso Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Lasso Regression model using the PCA datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35f3fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Lasso()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "667b7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__positive\": [False],\n",
    "    \"model__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1f7aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9045196074779615\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a855433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_lasso_pca training data is: 0.9142017685228763\n",
      "The R2 score for lr_model_lasso_pca validation data is: 0.9033447450950415\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_lasso_pca = Lasso(alpha=0.002, positive=False, warm_start=True)\n",
    "lr_model_lasso_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_lasso_pca training data is: {lr_model_lasso_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_lasso_pca_val_r2 = lr_model_lasso_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_lasso_pca validation data is: {lr_model_lasso_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde2e83",
   "metadata": {},
   "source": [
    "**ElasticeNet Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal ElasticNet Regression model on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30728ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", ElasticNet()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0a46861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__l1_ratio\": [0.4],\n",
    "    \"model__warm_start\": [True],\n",
    "    \"model__positive\": [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a7ffda66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__l1_ratio': 0.4, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9136891720109446\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc500db",
   "metadata": {},
   "source": [
    "Below will see how the optimized model does with the training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f10a5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_elastic_full training data is: 0.9319226114642285\n",
      "The R2 score for lr_model_elastic_full validation data is: 0.9101990891299294\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_elastic_full = ElasticNet(alpha=0.002, l1_ratio=0.4, positive=False, warm_start=True)\n",
    "lr_model_elastic_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_elastic_full training data is: {lr_model_elastic_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_elastic_full_val_r2 = lr_model_elastic_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_elastic_full validation data is: {lr_model_elastic_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101e491",
   "metadata": {},
   "source": [
    "**ElasticeNet Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal ElasticNet Regression model on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46417187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", ElasticNet()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "377b9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.001], \n",
    "    \"model__l1_ratio\": [0.2],\n",
    "    \"model__warm_start\": [True],\n",
    "    \"model__positive\": [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e43c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.001, 'model__l1_ratio': 0.2, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9069016414322609\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02763e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_elastic_pca training data is: 0.9165220287609357\n",
      "The R2 score for lr_model_elastic_pca validation data is: 0.9041516740152954\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_elastic_pca = ElasticNet(alpha=0.002, l1_ratio=0.4, positive=False, warm_start=True)\n",
    "lr_model_elastic_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_elastic_pca training data is: {lr_model_elastic_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_elastic_pca_val_r2 = lr_model_elastic_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_elastic_pca validation data is: {lr_model_elastic_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4353908",
   "metadata": {},
   "source": [
    "Below will compare R2 values calculated on the validation data to see how these different regression models perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ae9fe1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the models\n",
    "R2_dictionary = {'Linear Full R2': lr_model_full_val_r2, 'Linear PCA R2' :lr_model_pca_val_r2, 'Ridge Full R2': lr_model_ridge_full_val_r2, 'Ridge PCA R2': lr_model_ridge_pca_val_r2, 'Lasso Full R2': lr_model_lasso_full_val_r2, 'Lasso PCA R2': lr_model_lasso_pca_val_r2, 'Elastic Full R2': lr_model_elastic_full_val_r2, 'Elastic PCA R2': lr_model_elastic_pca_val_r2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "efc5911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting scores\n",
    "R2_values_sorted = dict(sorted(R2_dictionary.items(), key = operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af761a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elastic Full R2': 0.9101990891299294,\n",
       " 'Ridge Full R2': 0.9098745867302618,\n",
       " 'Lasso Full R2': 0.907597542099871,\n",
       " 'Elastic PCA R2': 0.9041516740152954,\n",
       " 'Lasso PCA R2': 0.9033447450950415,\n",
       " 'Linear Full R2': 0.9025842705674784,\n",
       " 'Ridge PCA R2': 0.9011979701874846,\n",
       " 'Linear PCA R2': 0.8959728426048407}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_values_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931425a9",
   "metadata": {},
   "source": [
    "**Comparing model performance**\n",
    "\n",
    "Looking at the different regression models, ElasticNet using the full dataset performed best with the validation data. In general, using the full dataset provided better results than PCA, which is good because interpretability can be preserved then. \n",
    "\n",
    "All things considered, the models perform pretty similarly. \n",
    "\n",
    "Below will look at another model type before drawing digging further on the models and drawing conclusions about which performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4fdea0",
   "metadata": {},
   "source": [
    "### 5.2 XG Boost Regressor <a class=\"anchor\" id=\"subheader52\"></a>\n",
    "\n",
    "For reference, the best validation R2 from running the baseline XGBoost Regressor model on numeric data alone (no vectorized text) was about 91.8. XG Boost was not run on the text only data.\n",
    "\n",
    "**XG Boost Regressor: Min Max, Full Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4388ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model training data is: 0.9926375397608137\n",
      "The R2 score for XGBR_model validation data is: 0.9022804820873469\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "XGBR_model = XGBRegressor()\n",
    "\n",
    "# 2. Fit the model\n",
    "XGBR_model.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model training data is: {XGBR_model.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "XGBR_model_val_r2 = XGBR_model.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for XGBR_model validation data is: {XGBR_model_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d048a2",
   "metadata": {},
   "source": [
    "Optimizing the XG Boost Model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ca21d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", XGBRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a6a9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__booster\": ['dart'], \n",
    "    \"model__eta\": [0.1],\n",
    "    \"model__gamma\": [1],\n",
    "    \"model__max_depth\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22165e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__booster': 'dart', 'model__eta': 0.1, 'model__gamma': 1, 'model__max_depth': 11}\n",
      "Best score: 0.9196504587392071\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ae500970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model_full training data is: 0.9921717669177883\n",
      "The R2 score for XGBR_model_full validation data is: 0.9157344141540313\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "XGBR_model_full = XGBRegressor(booster='dart', eta=0.1, gamma=1, max_depth=11)\n",
    "XGBR_model_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model_full training data is: {XGBR_model_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "XGBR_model_full_val_r2 = XGBR_model_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for XGBR_model_full validation data is: {XGBR_model_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf79c9c",
   "metadata": {},
   "source": [
    "The optimized XG Boost Model does slightly better than Linear Regression, though it is quite overfit.\n",
    "\n",
    "Fitting the XGBoost Regressor model on the PCA data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d7471e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", XGBRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1f7b665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__booster\": ['dart'], \n",
    "    \"model__eta\": [0.1],\n",
    "    \"model__gamma\": [1],\n",
    "    \"model__max_depth\": [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c632a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__booster': 'dart', 'model__eta': 0.1, 'model__gamma': 1, 'model__max_depth': 5}\n",
      "Best score: 0.8519782429252418\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c8c36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model_pca training data is: 0.9702665775242029\n",
      "The R2 score for XGBR_model_pca validation data is: 0.8466916761279962\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "XGBR_model_pca = XGBRegressor(booster='dart', eta=0.1, gamma=1, max_depth=5)\n",
    "XGBR_model_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model_pca training data is: {XGBR_model_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "XGBR_model_pca_val_r2 = XGBR_model_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for XGBR_model_pca validation data is: {XGBR_model_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7809e",
   "metadata": {},
   "source": [
    "## 6. Comparing All Models <a class=\"anchor\" id=\"header6\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4caa4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the models\n",
    "R2_dictionary = {'Linear Full R2': lr_model_full_val_r2, 'Linear PCA R2' :lr_model_pca_val_r2, 'Ridge Full R2': lr_model_ridge_full_val_r2, 'Ridge PCA R2': lr_model_ridge_pca_val_r2, 'Lasso Full R2': lr_model_lasso_full_val_r2, 'Lasso PCA R2': lr_model_lasso_pca_val_r2, 'Elastic Full R2': lr_model_elastic_full_val_r2, 'Elastic PCA R2': lr_model_elastic_pca_val_r2, 'XGBR Full R2': XGBR_model_full_val_r2, 'XGBR PCA R2': XGBR_model_pca_val_r2} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba07d54",
   "metadata": {},
   "source": [
    "Below compares all the models run, listing the one with the highest R2 first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d236fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBR Full R2': 0.9157344141540313,\n",
       " 'Elastic Full R2': 0.9101990891299294,\n",
       " 'Ridge Full R2': 0.9098745867302618,\n",
       " 'Lasso Full R2': 0.907597542099871,\n",
       " 'Elastic PCA R2': 0.9041516740152954,\n",
       " 'Lasso PCA R2': 0.9033447450950415,\n",
       " 'Linear Full R2': 0.9025842705674784,\n",
       " 'Ridge PCA R2': 0.9011979701874846,\n",
       " 'Linear PCA R2': 0.8959728426048407,\n",
       " 'XGBR PCA R2': 0.8466916761279962}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting scores\n",
    "R2_values_sorted = dict(sorted(R2_dictionary.items(), key = operator.itemgetter(1), reverse=True))\n",
    "R2_values_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c500fe",
   "metadata": {},
   "source": [
    "XGBR on the full dataset performs best, followed by ElasticNet on the full dataset. Overall, the PCA versions perform worse. XGBoost Regressor in particular takes a peformance hit when using the PCA data. Across the board, model performance is pretty similar, with the exception of the XGBR PCA version. \n",
    "\n",
    "At this stage, we'll pick one model to move forward with. We could use the XGBoost model on all the data, as it is the top model. However, interpretability is much more challenging. We could use a tool like SHAP to help with this. However, given how close the ElasticNet and other linear regression models are, we'll stick with the Linear Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374839d",
   "metadata": {},
   "source": [
    "## 7. Further Model Interpretation <a class=\"anchor\" id=\"header7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72475f",
   "metadata": {},
   "source": [
    "Our model has a pretty strong R2, but which features are important? To answer this question, below will look at Linear Regression coefficients and p-values.\n",
    "\n",
    "### 7.1 Using Stats Models for Additional Insights <a class=\"anchor\" id=\"subheader71\"></a>\n",
    "\n",
    "Unfortunately, SKLearn doesn't offer an easy way to way to get the p-values for the model. Instead, we'll use stats models to check on p-values. If the p-values shown using the stats model are significant, we can feel more confident in our linear regression models.\n",
    "\n",
    "With stats models, we do have to add a constant to X before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "128b03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the constant before modeling\n",
    "X_mm_remain_constant = sm.add_constant(X_mm_scaled_remain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbc05b",
   "metadata": {},
   "source": [
    "Running the model with stats models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d81166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>overall_score</td>  <th>  R-squared:         </th> <td>   0.943</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   93.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:24:46</td>     <th>  Log-Likelihood:    </th> <td> -5852.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4194</td>      <th>  AIC:               </th> <td>1.297e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3563</td>      <th>  BIC:               </th> <td>1.697e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   630</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   65.4234</td> <td>    0.407</td> <td>  160.702</td> <td> 0.000</td> <td>   64.625</td> <td>   66.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month</th>           <td>    0.0990</td> <td>    0.060</td> <td>    1.654</td> <td> 0.098</td> <td>   -0.018</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>            <td>   -0.1549</td> <td>    0.263</td> <td>   -0.590</td> <td> 0.555</td> <td>   -0.670</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bean_agtron</th>     <td>   -1.2737</td> <td>    0.361</td> <td>   -3.525</td> <td> 0.000</td> <td>   -1.982</td> <td>   -0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ground_agtron</th>   <td>    1.6821</td> <td>    0.298</td> <td>    5.639</td> <td> 0.000</td> <td>    1.097</td> <td>    2.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aroma</th>           <td>    8.7087</td> <td>    0.279</td> <td>   31.232</td> <td> 0.000</td> <td>    8.162</td> <td>    9.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidity</th>         <td>    5.0138</td> <td>    0.351</td> <td>   14.286</td> <td> 0.000</td> <td>    4.326</td> <td>    5.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body</th>            <td>    4.3515</td> <td>    0.220</td> <td>   19.745</td> <td> 0.000</td> <td>    3.919</td> <td>    4.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavor</th>          <td>    5.8711</td> <td>    0.418</td> <td>   14.057</td> <td> 0.000</td> <td>    5.052</td> <td>    6.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aftertaste</th>      <td>    6.1386</td> <td>    0.334</td> <td>   18.382</td> <td> 0.000</td> <td>    5.484</td> <td>    6.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roaster_lat</th>     <td>    0.5999</td> <td>    0.247</td> <td>    2.430</td> <td> 0.015</td> <td>    0.116</td> <td>    1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roaster_lon</th>     <td>    0.1462</td> <td>    0.091</td> <td>    1.607</td> <td> 0.108</td> <td>   -0.032</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_lat</th>      <td>   -0.6565</td> <td>    0.165</td> <td>   -3.974</td> <td> 0.000</td> <td>   -0.980</td> <td>   -0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_lon</th>      <td>   -0.0785</td> <td>    0.089</td> <td>   -0.884</td> <td> 0.377</td> <td>   -0.252</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acid</th>            <td>   -0.5576</td> <td>    0.580</td> <td>   -0.961</td> <td> 0.336</td> <td>   -1.695</td> <td>    0.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidity.1</th>       <td>   -0.2319</td> <td>    0.154</td> <td>   -1.503</td> <td> 0.133</td> <td>   -0.534</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidy</th>           <td>    1.2276</td> <td>    0.226</td> <td>    5.422</td> <td> 0.000</td> <td>    0.784</td> <td>    1.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>admired</th>         <td>    0.5630</td> <td>    0.409</td> <td>    1.376</td> <td> 0.169</td> <td>   -0.239</td> <td>    1.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aftertaste.1</th>    <td>    0.5086</td> <td>    0.277</td> <td>    1.839</td> <td> 0.066</td> <td>   -0.034</td> <td>    1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agave</th>           <td>    0.3993</td> <td>    0.633</td> <td>    0.630</td> <td> 0.528</td> <td>   -0.843</td> <td>    1.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aged</th>            <td>   -0.2333</td> <td>    0.504</td> <td>   -0.463</td> <td> 0.643</td> <td>   -1.221</td> <td>    0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agreeable</th>       <td>   -0.3362</td> <td>    0.411</td> <td>   -0.818</td> <td> 0.413</td> <td>   -1.142</td> <td>    0.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agreeably</th>       <td>    0.6268</td> <td>    0.353</td> <td>    1.775</td> <td> 0.076</td> <td>   -0.066</td> <td>    1.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alive</th>           <td>    0.4844</td> <td>    0.348</td> <td>    1.390</td> <td> 0.165</td> <td>   -0.199</td> <td>    1.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>almond</th>          <td>    0.2447</td> <td>    0.153</td> <td>    1.596</td> <td> 0.111</td> <td>   -0.056</td> <td>    0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amber</th>           <td>    0.4064</td> <td>    0.326</td> <td>    1.246</td> <td> 0.213</td> <td>   -0.233</td> <td>    1.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amplified</th>       <td>    0.0657</td> <td>    0.312</td> <td>    0.211</td> <td> 0.833</td> <td>   -0.546</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>anise</th>           <td>    0.4332</td> <td>    0.439</td> <td>    0.987</td> <td> 0.324</td> <td>   -0.427</td> <td>    1.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apple</th>           <td>    0.6837</td> <td>    0.214</td> <td>    3.198</td> <td> 0.001</td> <td>    0.265</td> <td>    1.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apricot</th>         <td>    0.3363</td> <td>    0.144</td> <td>    2.328</td> <td> 0.020</td> <td>    0.053</td> <td>    0.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatic</th>        <td>    0.0120</td> <td>    0.216</td> <td>    0.056</td> <td> 0.956</td> <td>   -0.411</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatically</th>    <td>    0.7165</td> <td>    0.349</td> <td>    2.051</td> <td> 0.040</td> <td>    0.032</td> <td>    1.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatics</th>       <td>   -0.0641</td> <td>    0.231</td> <td>   -0.278</td> <td> 0.781</td> <td>   -0.517</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>astringency</th>     <td>   -0.3130</td> <td>    0.229</td> <td>   -1.368</td> <td> 0.171</td> <td>   -0.762</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>astringent</th>      <td>   -0.5952</td> <td>    0.211</td> <td>   -2.815</td> <td> 0.005</td> <td>   -1.010</td> <td>   -0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>attractive</th>      <td>   -0.6140</td> <td>    0.303</td> <td>   -2.025</td> <td> 0.043</td> <td>   -1.208</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>authority</th>       <td>    0.3561</td> <td>    0.314</td> <td>    1.135</td> <td> 0.256</td> <td>   -0.259</td> <td>    0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b60</th>             <td>    0.7348</td> <td>    0.699</td> <td>    1.051</td> <td> 0.293</td> <td>   -0.636</td> <td>    2.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b70</th>             <td>   -0.2954</td> <td>    0.930</td> <td>   -0.318</td> <td> 0.751</td> <td>   -2.118</td> <td>    1.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>backgrounded</th>    <td>   -0.1173</td> <td>    0.204</td> <td>   -0.575</td> <td> 0.565</td> <td>   -0.517</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>baker</th>           <td>   -0.1056</td> <td>    0.189</td> <td>   -0.560</td> <td> 0.576</td> <td>   -0.475</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>baking</th>          <td>    0.2415</td> <td>    0.214</td> <td>    1.127</td> <td> 0.260</td> <td>   -0.179</td> <td>    0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>         <td>    0.6366</td> <td>    0.238</td> <td>    2.672</td> <td> 0.008</td> <td>    0.169</td> <td>    1.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balanced</th>        <td>    0.2262</td> <td>    0.105</td> <td>    2.146</td> <td> 0.032</td> <td>    0.020</td> <td>    0.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balancing</th>       <td>    0.3344</td> <td>    0.367</td> <td>    0.911</td> <td> 0.363</td> <td>   -0.386</td> <td>    1.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>banana</th>          <td>    0.1291</td> <td>    0.260</td> <td>    0.497</td> <td> 0.619</td> <td>   -0.380</td> <td>    0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>barrel</th>          <td>   -0.1806</td> <td>    0.321</td> <td>   -0.563</td> <td> 0.573</td> <td>   -0.810</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bay</th>             <td>   -0.6429</td> <td>    0.587</td> <td>   -1.096</td> <td> 0.273</td> <td>   -1.793</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bean</th>            <td>    0.0773</td> <td>    0.397</td> <td>    0.195</td> <td> 0.845</td> <td>   -0.700</td> <td>    0.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bergamot</th>        <td>    0.5193</td> <td>    0.262</td> <td>    1.985</td> <td> 0.047</td> <td>    0.006</td> <td>    1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>berries</th>         <td>    0.6369</td> <td>    0.319</td> <td>    1.996</td> <td> 0.046</td> <td>    0.011</td> <td>    1.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>berry</th>           <td>    1.1736</td> <td>    0.185</td> <td>    6.346</td> <td> 0.000</td> <td>    0.811</td> <td>    1.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>best</th>            <td>    1.4252</td> <td>    0.447</td> <td>    3.188</td> <td> 0.001</td> <td>    0.549</td> <td>    2.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>big</th>             <td>    0.3047</td> <td>    0.250</td> <td>    1.217</td> <td> 0.224</td> <td>   -0.186</td> <td>    0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bing</th>            <td>    0.2843</td> <td>    0.398</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.495</td> <td>    1.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bit</th>             <td>   -0.3650</td> <td>    0.244</td> <td>   -1.498</td> <td> 0.134</td> <td>   -0.843</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitter</th>          <td>   -1.4749</td> <td>    0.375</td> <td>   -3.938</td> <td> 0.000</td> <td>   -2.209</td> <td>   -0.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitterish</th>       <td>   -0.6420</td> <td>    0.452</td> <td>   -1.420</td> <td> 0.156</td> <td>   -1.528</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitterness</th>      <td>    0.7163</td> <td>    0.383</td> <td>    1.870</td> <td> 0.062</td> <td>   -0.035</td> <td>    1.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bittersweet</th>     <td>   -0.1348</td> <td>    0.158</td> <td>   -0.854</td> <td> 0.393</td> <td>   -0.444</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>           <td>    0.3972</td> <td>    0.188</td> <td>    2.115</td> <td> 0.035</td> <td>    0.029</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blackberry</th>      <td>    0.2717</td> <td>    0.215</td> <td>    1.266</td> <td> 0.206</td> <td>   -0.149</td> <td>    0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blend</th>           <td>   -0.3347</td> <td>    0.288</td> <td>   -1.160</td> <td> 0.246</td> <td>   -0.900</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blood</th>           <td>    0.0850</td> <td>    0.238</td> <td>    0.357</td> <td> 0.721</td> <td>   -0.382</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bloom</th>           <td>    0.1320</td> <td>    0.360</td> <td>    0.367</td> <td> 0.714</td> <td>   -0.573</td> <td>    0.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blooming</th>        <td>    0.0798</td> <td>    0.264</td> <td>    0.302</td> <td> 0.763</td> <td>   -0.438</td> <td>    0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blooms</th>          <td>    1.4819</td> <td>    0.444</td> <td>    3.334</td> <td> 0.001</td> <td>    0.611</td> <td>    2.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blossom</th>         <td>    0.0889</td> <td>    0.233</td> <td>    0.382</td> <td> 0.703</td> <td>   -0.368</td> <td>    0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blueberry</th>       <td>    0.4626</td> <td>    0.212</td> <td>    2.186</td> <td> 0.029</td> <td>    0.048</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bodied</th>          <td>    0.8341</td> <td>    0.237</td> <td>    3.514</td> <td> 0.000</td> <td>    0.369</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body.1</th>          <td>    0.1124</td> <td>    0.182</td> <td>    0.618</td> <td> 0.537</td> <td>   -0.244</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brandy</th>          <td>    0.4870</td> <td>    0.275</td> <td>    1.771</td> <td> 0.077</td> <td>   -0.052</td> <td>    1.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brazil</th>          <td>    0.3351</td> <td>    0.423</td> <td>    0.792</td> <td> 0.428</td> <td>   -0.494</td> <td>    1.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewed</th>          <td>    0.0293</td> <td>    0.722</td> <td>    0.041</td> <td> 0.968</td> <td>   -1.387</td> <td>    1.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewer</th>          <td>    1.0069</td> <td>    0.939</td> <td>    1.073</td> <td> 0.284</td> <td>   -0.834</td> <td>    2.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewing</th>         <td>    0.0094</td> <td>    1.062</td> <td>    0.009</td> <td> 0.993</td> <td>   -2.074</td> <td>    2.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bright</th>          <td>    0.3768</td> <td>    0.137</td> <td>    2.761</td> <td> 0.006</td> <td>    0.109</td> <td>    0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brightly</th>        <td>    0.1126</td> <td>    0.218</td> <td>    0.517</td> <td> 0.605</td> <td>   -0.314</td> <td>    0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brightness</th>      <td>   -0.2129</td> <td>    0.464</td> <td>   -0.459</td> <td> 0.647</td> <td>   -1.123</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brisk</th>           <td>   -0.0625</td> <td>    0.156</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.369</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>briskly</th>         <td>    0.2116</td> <td>    0.320</td> <td>    0.660</td> <td> 0.509</td> <td>   -0.417</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brittle</th>         <td>    0.5067</td> <td>    0.260</td> <td>    1.951</td> <td> 0.051</td> <td>   -0.002</td> <td>    1.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brown</th>           <td>    1.2040</td> <td>    0.699</td> <td>    1.723</td> <td> 0.085</td> <td>   -0.166</td> <td>    2.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buoyant</th>         <td>    0.0678</td> <td>    0.135</td> <td>    0.501</td> <td> 0.616</td> <td>   -0.198</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buoyantly</th>       <td>    0.4608</td> <td>    0.342</td> <td>    1.347</td> <td> 0.178</td> <td>   -0.210</td> <td>    1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>burned</th>          <td>   -0.6700</td> <td>    0.366</td> <td>   -1.831</td> <td> 0.067</td> <td>   -1.387</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>butter</th>          <td>    0.3722</td> <td>    0.158</td> <td>    2.352</td> <td> 0.019</td> <td>    0.062</td> <td>    0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>butterscotch</th>    <td>    0.7473</td> <td>    0.249</td> <td>    3.004</td> <td> 0.003</td> <td>    0.260</td> <td>    1.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buttery</th>         <td>    0.3204</td> <td>    0.228</td> <td>    1.405</td> <td> 0.160</td> <td>   -0.127</td> <td>    0.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>byron</th>           <td>    1.7443</td> <td>    0.570</td> <td>    3.059</td> <td> 0.002</td> <td>    0.626</td> <td>    2.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cacao</th>           <td>    0.2333</td> <td>    0.216</td> <td>    1.082</td> <td> 0.279</td> <td>   -0.189</td> <td>    0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>called</th>          <td>   -0.9198</td> <td>    0.409</td> <td>   -2.248</td> <td> 0.025</td> <td>   -1.722</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>candied</th>         <td>    0.4412</td> <td>    0.225</td> <td>    1.960</td> <td> 0.050</td> <td>-7.41e-05</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>candy</th>           <td>    0.6059</td> <td>    0.411</td> <td>    1.474</td> <td> 0.141</td> <td>   -0.200</td> <td>    1.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cane</th>            <td>    0.6055</td> <td>    0.700</td> <td>    0.865</td> <td> 0.387</td> <td>   -0.767</td> <td>    1.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cappuccino</th>      <td>    0.5358</td> <td>    0.561</td> <td>    0.954</td> <td> 0.340</td> <td>   -0.565</td> <td>    1.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>capsule</th>         <td>   -1.4669</td> <td>    1.156</td> <td>   -1.269</td> <td> 0.205</td> <td>   -3.733</td> <td>    0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caramel</th>         <td>    0.3637</td> <td>    0.181</td> <td>    2.012</td> <td> 0.044</td> <td>    0.009</td> <td>    0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caramelly</th>       <td>    0.6595</td> <td>    0.274</td> <td>    2.409</td> <td> 0.016</td> <td>    0.123</td> <td>    1.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carbon</th>          <td>   -1.1016</td> <td>    0.455</td> <td>   -2.419</td> <td> 0.016</td> <td>   -1.995</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cardamom</th>        <td>    0.1037</td> <td>    0.451</td> <td>    0.230</td> <td> 0.818</td> <td>   -0.780</td> <td>    0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carob</th>           <td>    0.3286</td> <td>    0.391</td> <td>    0.841</td> <td> 0.401</td> <td>   -0.438</td> <td>    1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carried</th>         <td>   -0.3843</td> <td>    0.374</td> <td>   -1.027</td> <td> 0.304</td> <td>   -1.118</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carries</th>         <td>    0.2158</td> <td>    0.175</td> <td>    1.233</td> <td> 0.218</td> <td>   -0.127</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carry</th>           <td>    0.0799</td> <td>    0.129</td> <td>    0.618</td> <td> 0.537</td> <td>   -0.174</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carrying</th>        <td>   -0.0271</td> <td>    0.307</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.629</td> <td>    0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cashew</th>          <td>    0.2880</td> <td>    0.201</td> <td>    1.434</td> <td> 0.152</td> <td>   -0.106</td> <td>    0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cedar</th>           <td>    0.2356</td> <td>    0.117</td> <td>    2.020</td> <td> 0.043</td> <td>    0.007</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cedary</th>          <td>    0.3418</td> <td>    0.269</td> <td>    1.270</td> <td> 0.204</td> <td>   -0.186</td> <td>    0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>center</th>          <td>    0.4055</td> <td>    0.398</td> <td>    1.019</td> <td> 0.308</td> <td>   -0.375</td> <td>    1.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centered</th>        <td>   -0.0436</td> <td>    0.198</td> <td>   -0.220</td> <td> 0.826</td> <td>   -0.433</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centers</th>         <td>   -0.0097</td> <td>    0.128</td> <td>   -0.076</td> <td> 0.939</td> <td>   -0.261</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>character</th>       <td>    0.2321</td> <td>    0.226</td> <td>    1.028</td> <td> 0.304</td> <td>   -0.210</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>charred</th>         <td>    0.1236</td> <td>    0.357</td> <td>    0.346</td> <td> 0.729</td> <td>   -0.577</td> <td>    0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cherry</th>          <td>    0.5093</td> <td>    0.162</td> <td>    3.151</td> <td> 0.002</td> <td>    0.192</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cherryish</th>       <td>    1.0127</td> <td>    0.248</td> <td>    4.080</td> <td> 0.000</td> <td>    0.526</td> <td>    1.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chocolate</th>       <td>    0.5726</td> <td>    0.125</td> <td>    4.565</td> <td> 0.000</td> <td>    0.327</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chocolaty</th>       <td>    0.4168</td> <td>    0.169</td> <td>    2.462</td> <td> 0.014</td> <td>    0.085</td> <td>    0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cinnamon</th>        <td>    0.5553</td> <td>    0.241</td> <td>    2.306</td> <td> 0.021</td> <td>    0.083</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cited</th>           <td>   -0.3593</td> <td>    0.491</td> <td>   -0.732</td> <td> 0.464</td> <td>   -1.321</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citrus</th>          <td>    0.2562</td> <td>    0.171</td> <td>    1.498</td> <td> 0.134</td> <td>   -0.079</td> <td>    0.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citrusy</th>         <td>    0.1491</td> <td>    0.231</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.304</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>classic</th>         <td>    0.9703</td> <td>    0.324</td> <td>    2.991</td> <td> 0.003</td> <td>    0.334</td> <td>    1.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clean</th>           <td>    0.8857</td> <td>    0.199</td> <td>    4.449</td> <td> 0.000</td> <td>    0.495</td> <td>    1.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cleanly</th>         <td>    0.2428</td> <td>    0.185</td> <td>    1.315</td> <td> 0.189</td> <td>   -0.119</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clear</th>           <td>    0.3539</td> <td>    0.349</td> <td>    1.014</td> <td> 0.311</td> <td>   -0.330</td> <td>    1.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clove</th>           <td>    0.4161</td> <td>    0.278</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.128</td> <td>    0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cocoa</th>           <td>    0.7480</td> <td>    0.159</td> <td>    4.704</td> <td> 0.000</td> <td>    0.436</td> <td>    1.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cocoaish</th>        <td>    0.1194</td> <td>    0.230</td> <td>    0.518</td> <td> 0.604</td> <td>   -0.332</td> <td>    0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coconut</th>         <td>    0.7503</td> <td>    0.269</td> <td>    2.789</td> <td> 0.005</td> <td>    0.223</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coffee</th>          <td>    0.0670</td> <td>    0.198</td> <td>    0.338</td> <td> 0.735</td> <td>   -0.322</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coffees</th>         <td>    0.7512</td> <td>    0.379</td> <td>    1.981</td> <td> 0.048</td> <td>    0.008</td> <td>    1.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cold</th>            <td>    1.2898</td> <td>    0.687</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.057</td> <td>    2.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complete</th>        <td>    0.4530</td> <td>    0.241</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.020</td> <td>    0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complex</th>         <td>    0.4363</td> <td>    0.104</td> <td>    4.184</td> <td> 0.000</td> <td>    0.232</td> <td>    0.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complexity</th>      <td>    0.9136</td> <td>    0.234</td> <td>    3.897</td> <td> 0.000</td> <td>    0.454</td> <td>    1.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complexly</th>       <td>    0.2302</td> <td>    0.217</td> <td>    1.060</td> <td> 0.289</td> <td>   -0.195</td> <td>    0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicate</th>      <td>    0.0598</td> <td>    0.356</td> <td>    0.168</td> <td> 0.867</td> <td>   -0.638</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicated</th>     <td>   -0.2081</td> <td>    0.164</td> <td>   -1.271</td> <td> 0.204</td> <td>   -0.529</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicates</th>     <td>    0.8059</td> <td>    0.330</td> <td>    2.441</td> <td> 0.015</td> <td>    0.158</td> <td>    1.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicating</th>    <td>    0.2048</td> <td>    0.313</td> <td>    0.655</td> <td> 0.513</td> <td>   -0.408</td> <td>    0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complication</th>    <td>   -0.1532</td> <td>    0.267</td> <td>   -0.573</td> <td> 0.567</td> <td>   -0.677</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complications</th>   <td>   -0.1966</td> <td>    0.302</td> <td>   -0.652</td> <td> 0.515</td> <td>   -0.788</td> <td>    0.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concord</th>         <td>    0.6140</td> <td>    0.421</td> <td>    1.458</td> <td> 0.145</td> <td>   -0.212</td> <td>    1.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>consolidates</th>    <td>    0.0527</td> <td>    0.105</td> <td>    0.504</td> <td> 0.614</td> <td>   -0.152</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>consolidating</th>   <td>   -0.1281</td> <td>    0.319</td> <td>   -0.402</td> <td> 0.688</td> <td>   -0.754</td> <td>    0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>continued</th>       <td>    0.1901</td> <td>    0.159</td> <td>    1.192</td> <td> 0.233</td> <td>   -0.123</td> <td>    0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>continuing</th>      <td>   -0.3295</td> <td>    0.222</td> <td>   -1.487</td> <td> 0.137</td> <td>   -0.764</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cools</th>           <td>   -0.3730</td> <td>    0.223</td> <td>   -1.676</td> <td> 0.094</td> <td>   -0.809</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>creamy</th>          <td>   -0.0316</td> <td>    0.153</td> <td>   -0.207</td> <td> 0.836</td> <td>   -0.331</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crisp</th>           <td>    0.3751</td> <td>    0.108</td> <td>    3.463</td> <td> 0.001</td> <td>    0.163</td> <td>    0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crisply</th>         <td>    0.7626</td> <td>    0.243</td> <td>    3.135</td> <td> 0.002</td> <td>    0.286</td> <td>    1.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cupper</th>          <td>    0.3957</td> <td>    0.337</td> <td>    1.176</td> <td> 0.240</td> <td>   -0.264</td> <td>    1.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cupping</th>         <td>    0.6082</td> <td>    0.344</td> <td>    1.767</td> <td> 0.077</td> <td>   -0.066</td> <td>    1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cups</th>            <td>   -2.1897</td> <td>    0.493</td> <td>   -4.438</td> <td> 0.000</td> <td>   -3.157</td> <td>   -1.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>currant</th>         <td>    0.3675</td> <td>    0.203</td> <td>    1.809</td> <td> 0.071</td> <td>   -0.031</td> <td>    0.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut</th>             <td>    0.0528</td> <td>    0.211</td> <td>    0.250</td> <td> 0.803</td> <td>   -0.362</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>            <td>    0.0264</td> <td>    0.128</td> <td>    0.207</td> <td> 0.836</td> <td>   -0.224</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>date</th>            <td>    0.6587</td> <td>    0.188</td> <td>    3.495</td> <td> 0.000</td> <td>    0.289</td> <td>    1.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deep</th>            <td>    0.3174</td> <td>    0.133</td> <td>    2.379</td> <td> 0.017</td> <td>    0.056</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepen</th>          <td>   -0.2034</td> <td>    0.296</td> <td>   -0.687</td> <td> 0.492</td> <td>   -0.784</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepening</th>       <td>    1.0644</td> <td>    0.309</td> <td>    3.443</td> <td> 0.001</td> <td>    0.458</td> <td>    1.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepens</th>         <td>    1.0057</td> <td>    0.334</td> <td>    3.013</td> <td> 0.003</td> <td>    0.351</td> <td>    1.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deeply</th>          <td>    0.3527</td> <td>    0.133</td> <td>    2.659</td> <td> 0.008</td> <td>    0.093</td> <td>    0.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>delicate</th>        <td>    0.4190</td> <td>    0.167</td> <td>    2.502</td> <td> 0.012</td> <td>    0.091</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>delicately</th>      <td>    0.2512</td> <td>    0.154</td> <td>    1.634</td> <td> 0.102</td> <td>   -0.050</td> <td>    0.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth</th>           <td>    0.2959</td> <td>    0.362</td> <td>    0.817</td> <td> 0.414</td> <td>   -0.414</td> <td>    1.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>described</th>       <td>    0.3180</td> <td>    0.506</td> <td>    0.628</td> <td> 0.530</td> <td>   -0.674</td> <td>    1.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>device</th>          <td>    0.0558</td> <td>    1.438</td> <td>    0.039</td> <td> 0.969</td> <td>   -2.763</td> <td>    2.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dimension</th>       <td>   -1.2144</td> <td>    0.280</td> <td>   -4.343</td> <td> 0.000</td> <td>   -1.763</td> <td>   -0.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dimensioned</th>     <td>    1.0323</td> <td>    0.387</td> <td>    2.671</td> <td> 0.008</td> <td>    0.275</td> <td>    1.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displayed</th>       <td>    0.3927</td> <td>    0.449</td> <td>    0.874</td> <td> 0.382</td> <td>   -0.488</td> <td>    1.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displays</th>        <td>    0.1814</td> <td>    0.323</td> <td>    0.561</td> <td> 0.575</td> <td>   -0.453</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinct</th>        <td>    0.3327</td> <td>    0.224</td> <td>    1.485</td> <td> 0.138</td> <td>   -0.107</td> <td>    0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinctive</th>     <td>    0.5034</td> <td>    0.388</td> <td>    1.298</td> <td> 0.194</td> <td>   -0.257</td> <td>    1.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinctly</th>      <td>   -0.1672</td> <td>    0.245</td> <td>   -0.684</td> <td> 0.494</td> <td>   -0.647</td> <td>    0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominate</th>        <td>    0.0262</td> <td>    0.184</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.334</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominated</th>       <td>   -0.5164</td> <td>    0.219</td> <td>   -2.362</td> <td> 0.018</td> <td>   -0.945</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominates</th>       <td>    0.0451</td> <td>    0.204</td> <td>    0.221</td> <td> 0.825</td> <td>   -0.354</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominating</th>      <td>    0.1279</td> <td>    0.359</td> <td>    0.356</td> <td> 0.722</td> <td>   -0.576</td> <td>    0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dried</th>           <td>    0.2410</td> <td>    0.152</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.057</td> <td>    0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drink</th>           <td>    0.2971</td> <td>    0.703</td> <td>    0.422</td> <td> 0.673</td> <td>   -1.082</td> <td>    1.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>driven</th>          <td>    0.1544</td> <td>    0.259</td> <td>    0.597</td> <td> 0.551</td> <td>   -0.353</td> <td>    0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dry</th>             <td>   -0.1590</td> <td>    0.147</td> <td>   -1.085</td> <td> 0.278</td> <td>   -0.447</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drying</th>          <td>   -0.3129</td> <td>    0.131</td> <td>   -2.382</td> <td> 0.017</td> <td>   -0.570</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dusk</th>            <td>    0.2131</td> <td>    0.348</td> <td>    0.612</td> <td> 0.540</td> <td>   -0.469</td> <td>    0.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earth</th>           <td>    0.5620</td> <td>    0.302</td> <td>    1.859</td> <td> 0.063</td> <td>   -0.031</td> <td>    1.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earthy</th>          <td>    0.1387</td> <td>    0.328</td> <td>    0.423</td> <td> 0.673</td> <td>   -0.505</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>edge</th>            <td>    0.4164</td> <td>    0.219</td> <td>    1.903</td> <td> 0.057</td> <td>   -0.013</td> <td>    0.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>edged</th>           <td>    0.1679</td> <td>    0.342</td> <td>    0.491</td> <td> 0.623</td> <td>   -0.502</td> <td>    0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>effervescent</th>    <td>    0.3038</td> <td>    0.354</td> <td>    0.859</td> <td> 0.391</td> <td>   -0.390</td> <td>    0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elegant</th>         <td>    0.5923</td> <td>    0.247</td> <td>    2.396</td> <td> 0.017</td> <td>    0.108</td> <td>    1.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elegantly</th>       <td>    0.7455</td> <td>    0.239</td> <td>    3.122</td> <td> 0.002</td> <td>    0.277</td> <td>    1.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emerge</th>          <td>    0.5664</td> <td>    0.350</td> <td>    1.618</td> <td> 0.106</td> <td>   -0.120</td> <td>    1.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emerges</th>         <td>    0.2440</td> <td>    0.288</td> <td>    0.847</td> <td> 0.397</td> <td>   -0.321</td> <td>    0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engaging</th>        <td>    0.1689</td> <td>    0.291</td> <td>    0.581</td> <td> 0.562</td> <td>   -0.402</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enveloped</th>       <td>    0.4742</td> <td>    0.291</td> <td>    1.630</td> <td> 0.103</td> <td>   -0.096</td> <td>    1.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enveloping</th>      <td>    0.3838</td> <td>    0.340</td> <td>    1.127</td> <td> 0.260</td> <td>   -0.284</td> <td>    1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>especially</th>      <td>    1.0488</td> <td>    0.436</td> <td>    2.404</td> <td> 0.016</td> <td>    0.193</td> <td>    1.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>espresso</th>        <td>    0.4950</td> <td>    0.430</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.348</td> <td>    1.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ethan</th>           <td>    1.0449</td> <td>    0.597</td> <td>    1.749</td> <td> 0.080</td> <td>   -0.126</td> <td>    2.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>evaluated</th>       <td>   -0.0297</td> <td>    0.286</td> <td>   -0.104</td> <td> 0.917</td> <td>   -0.591</td> <td>    0.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>excellent</th>       <td>    0.4174</td> <td>    0.310</td> <td>    1.347</td> <td> 0.178</td> <td>   -0.190</td> <td>    1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exhilarating</th>    <td>    0.1057</td> <td>    0.339</td> <td>    0.312</td> <td> 0.755</td> <td>   -0.558</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exhilaratingly</th>  <td>    0.7902</td> <td>    0.418</td> <td>    1.889</td> <td> 0.059</td> <td>   -0.030</td> <td>    1.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exotic</th>          <td>    0.4926</td> <td>    0.310</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.116</td> <td>    1.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>explicit</th>        <td>    0.9583</td> <td>    0.372</td> <td>    2.574</td> <td> 0.010</td> <td>    0.228</td> <td>    1.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expressed</th>       <td>    0.2489</td> <td>    0.257</td> <td>    0.969</td> <td> 0.333</td> <td>   -0.255</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fade</th>            <td>    0.3184</td> <td>    0.280</td> <td>    1.135</td> <td> 0.256</td> <td>   -0.231</td> <td>    0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fades</th>           <td>   -0.1337</td> <td>    0.225</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.575</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fading</th>          <td>    0.0500</td> <td>    0.401</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.736</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>faint</th>           <td>   -1.2791</td> <td>    0.290</td> <td>   -4.411</td> <td> 0.000</td> <td>   -1.848</td> <td>   -0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>faintly</th>         <td>    0.0751</td> <td>    0.525</td> <td>    0.143</td> <td> 0.886</td> <td>   -0.954</td> <td>    1.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fallen</th>          <td>   -0.7233</td> <td>    0.486</td> <td>   -1.487</td> <td> 0.137</td> <td>   -1.677</td> <td>    0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>far</th>             <td>    0.0943</td> <td>    0.270</td> <td>    0.349</td> <td> 0.727</td> <td>   -0.435</td> <td>    0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>felt</th>            <td>    0.3061</td> <td>    0.480</td> <td>    0.638</td> <td> 0.523</td> <td>   -0.634</td> <td>    1.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ferment</th>         <td>   -0.8534</td> <td>    0.312</td> <td>   -2.736</td> <td> 0.006</td> <td>   -1.465</td> <td>   -0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fermented</th>       <td>   -0.2066</td> <td>    0.354</td> <td>   -0.584</td> <td> 0.559</td> <td>   -0.900</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fermenty</th>        <td>    0.3884</td> <td>    0.379</td> <td>    1.026</td> <td> 0.305</td> <td>   -0.354</td> <td>    1.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig</th>             <td>    0.7245</td> <td>    0.345</td> <td>    2.098</td> <td> 0.036</td> <td>    0.047</td> <td>    1.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fine</th>            <td>    0.5534</td> <td>    0.243</td> <td>    2.280</td> <td> 0.023</td> <td>    0.078</td> <td>    1.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fir</th>             <td>    0.0346</td> <td>    0.192</td> <td>    0.180</td> <td> 0.857</td> <td>   -0.342</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flat</th>            <td>   -2.6054</td> <td>    0.434</td> <td>   -6.009</td> <td> 0.000</td> <td>   -3.455</td> <td>   -1.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavor.1</th>        <td>   -0.2849</td> <td>    0.147</td> <td>   -1.943</td> <td> 0.052</td> <td>   -0.572</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavors</th>         <td>   -0.1804</td> <td>    0.276</td> <td>   -0.655</td> <td> 0.513</td> <td>   -0.721</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floral</th>          <td>    0.6221</td> <td>    0.123</td> <td>    5.072</td> <td> 0.000</td> <td>    0.382</td> <td>    0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>florals</th>         <td>    0.0317</td> <td>    0.172</td> <td>    0.185</td> <td> 0.853</td> <td>   -0.305</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flower</th>          <td>    1.5822</td> <td>    0.344</td> <td>    4.606</td> <td> 0.000</td> <td>    0.909</td> <td>    2.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flowering</th>       <td>    1.1223</td> <td>    0.789</td> <td>    1.423</td> <td> 0.155</td> <td>   -0.424</td> <td>    2.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flowers</th>         <td>    0.5239</td> <td>    0.120</td> <td>    4.354</td> <td> 0.000</td> <td>    0.288</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>followed</th>        <td>   -0.1444</td> <td>    0.334</td> <td>   -0.432</td> <td> 0.665</td> <td>   -0.799</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>forward</th>         <td>   -0.1316</td> <td>    0.204</td> <td>   -0.644</td> <td> 0.520</td> <td>   -0.532</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fragrant</th>        <td>    1.0566</td> <td>    0.346</td> <td>    3.055</td> <td> 0.002</td> <td>    0.378</td> <td>    1.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>framed</th>          <td>   -0.1441</td> <td>    0.291</td> <td>   -0.496</td> <td> 0.620</td> <td>   -0.714</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frankincense</th>    <td>    0.4244</td> <td>    0.258</td> <td>    1.648</td> <td> 0.099</td> <td>   -0.081</td> <td>    0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freesia</th>         <td>    0.3285</td> <td>    0.197</td> <td>    1.669</td> <td> 0.095</td> <td>   -0.057</td> <td>    0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh</th>           <td>    0.1009</td> <td>    0.241</td> <td>    0.419</td> <td> 0.675</td> <td>   -0.371</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freshly</th>         <td>   -0.0470</td> <td>    0.362</td> <td>   -0.130</td> <td> 0.897</td> <td>   -0.757</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fruit</th>           <td>    0.5607</td> <td>    0.148</td> <td>    3.789</td> <td> 0.000</td> <td>    0.271</td> <td>    0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fruity</th>          <td>    0.2023</td> <td>    0.245</td> <td>    0.824</td> <td> 0.410</td> <td>   -0.279</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fudge</th>           <td>    0.4613</td> <td>    0.237</td> <td>    1.943</td> <td> 0.052</td> <td>   -0.004</td> <td>    0.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gardenia</th>        <td>    0.3074</td> <td>    0.238</td> <td>    1.289</td> <td> 0.197</td> <td>   -0.160</td> <td>    0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gentle</th>          <td>    0.2663</td> <td>    0.174</td> <td>    1.531</td> <td> 0.126</td> <td>   -0.075</td> <td>    0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gently</th>          <td>    0.3387</td> <td>    0.136</td> <td>    2.489</td> <td> 0.013</td> <td>    0.072</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ginger</th>          <td>    0.1469</td> <td>    0.302</td> <td>    0.486</td> <td> 0.627</td> <td>   -0.446</td> <td>    0.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>goji</th>            <td>    0.1246</td> <td>    0.462</td> <td>    0.270</td> <td> 0.787</td> <td>   -0.781</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>good</th>            <td>   -0.0898</td> <td>    0.292</td> <td>   -0.308</td> <td> 0.758</td> <td>   -0.662</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grace</th>           <td>   -1.0529</td> <td>    0.362</td> <td>   -2.909</td> <td> 0.004</td> <td>   -1.763</td> <td>   -0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grape</th>           <td>    0.4194</td> <td>    0.256</td> <td>    1.637</td> <td> 0.102</td> <td>   -0.083</td> <td>    0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grapefruit</th>      <td>    0.6447</td> <td>    0.188</td> <td>    3.428</td> <td> 0.001</td> <td>    0.276</td> <td>    1.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grappa</th>          <td>    0.7922</td> <td>    0.404</td> <td>    1.960</td> <td> 0.050</td> <td>   -0.000</td> <td>    1.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grass</th>           <td>   -0.4223</td> <td>    0.829</td> <td>   -0.509</td> <td> 0.610</td> <td>   -2.048</td> <td>    1.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>great</th>           <td>    0.5294</td> <td>    0.348</td> <td>    1.522</td> <td> 0.128</td> <td>   -0.152</td> <td>    1.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>green</th>           <td>    0.3106</td> <td>    0.291</td> <td>    1.068</td> <td> 0.285</td> <td>   -0.259</td> <td>    0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>guava</th>           <td>    0.4195</td> <td>    0.241</td> <td>    1.744</td> <td> 0.081</td> <td>   -0.052</td> <td>    0.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hard</th>            <td>   -3.6369</td> <td>    0.417</td> <td>   -8.722</td> <td> 0.000</td> <td>   -4.454</td> <td>   -2.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>harmonious</th>      <td>    0.0679</td> <td>    0.335</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.588</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hazelnut</th>        <td>    0.3668</td> <td>    0.147</td> <td>    2.493</td> <td> 0.013</td> <td>    0.078</td> <td>    0.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>heavy</th>           <td>   -0.2766</td> <td>    0.295</td> <td>   -0.937</td> <td> 0.349</td> <td>   -0.855</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herb</th>            <td>    0.9771</td> <td>    0.302</td> <td>    3.240</td> <td> 0.001</td> <td>    0.386</td> <td>    1.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herbaceous</th>      <td>    0.1150</td> <td>    0.250</td> <td>    0.461</td> <td> 0.645</td> <td>   -0.374</td> <td>    0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herbal</th>          <td>    0.4765</td> <td>    0.442</td> <td>    1.077</td> <td> 0.281</td> <td>   -0.391</td> <td>    1.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herbs</th>           <td>    0.2475</td> <td>    0.317</td> <td>    0.780</td> <td> 0.435</td> <td>   -0.375</td> <td>    0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herby</th>           <td>    0.4905</td> <td>    0.360</td> <td>    1.363</td> <td> 0.173</td> <td>   -0.215</td> <td>    1.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hibiscus</th>        <td>    0.1236</td> <td>    0.308</td> <td>    0.401</td> <td> 0.688</td> <td>   -0.481</td> <td>    0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>high</th>            <td>    0.6296</td> <td>    0.164</td> <td>    3.834</td> <td> 0.000</td> <td>    0.308</td> <td>    0.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hint</th>            <td>   -0.0992</td> <td>    0.189</td> <td>   -0.524</td> <td> 0.600</td> <td>   -0.470</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hints</th>           <td>    0.0529</td> <td>    0.171</td> <td>    0.309</td> <td> 0.757</td> <td>   -0.283</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honey</th>           <td>    0.6025</td> <td>    0.136</td> <td>    4.441</td> <td> 0.000</td> <td>    0.337</td> <td>    0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honeyish</th>        <td>    0.3963</td> <td>    0.358</td> <td>    1.108</td> <td> 0.268</td> <td>   -0.305</td> <td>    1.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honeysuckle</th>     <td>    0.4695</td> <td>    0.215</td> <td>    2.179</td> <td> 0.029</td> <td>    0.047</td> <td>    0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hop</th>             <td>    0.2209</td> <td>    0.270</td> <td>    0.817</td> <td> 0.414</td> <td>   -0.309</td> <td>    0.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hot</th>             <td>   -0.4106</td> <td>    0.397</td> <td>   -1.035</td> <td> 0.301</td> <td>   -1.188</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impression</th>      <td>    0.9435</td> <td>    0.375</td> <td>    2.516</td> <td> 0.012</td> <td>    0.208</td> <td>    1.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impressive</th>      <td>    0.1392</td> <td>    0.203</td> <td>    0.684</td> <td> 0.494</td> <td>   -0.260</td> <td>    0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impressively</th>    <td>    0.2740</td> <td>    0.262</td> <td>    1.045</td> <td> 0.296</td> <td>   -0.240</td> <td>    0.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>influenced</th>      <td>    0.5288</td> <td>    0.404</td> <td>    1.310</td> <td> 0.190</td> <td>   -0.263</td> <td>    1.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>integrated</th>      <td>    0.6842</td> <td>    0.303</td> <td>    2.261</td> <td> 0.024</td> <td>    0.091</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intense</th>         <td>    0.3847</td> <td>    0.219</td> <td>    1.757</td> <td> 0.079</td> <td>   -0.045</td> <td>    0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intensely</th>       <td>    0.0791</td> <td>    0.357</td> <td>    0.222</td> <td> 0.825</td> <td>   -0.621</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intensity</th>       <td>   -0.1755</td> <td>    0.404</td> <td>   -0.434</td> <td> 0.664</td> <td>   -0.968</td> <td>    0.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interesting</th>     <td>   -0.9121</td> <td>    0.356</td> <td>   -2.563</td> <td> 0.010</td> <td>   -1.610</td> <td>   -0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intricate</th>       <td>    0.3152</td> <td>    0.178</td> <td>    1.772</td> <td> 0.076</td> <td>   -0.034</td> <td>    0.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intricately</th>     <td>    0.2246</td> <td>    0.244</td> <td>    0.919</td> <td> 0.358</td> <td>   -0.254</td> <td>    0.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intriguing</th>      <td>    0.1726</td> <td>    0.422</td> <td>    0.409</td> <td> 0.683</td> <td>   -0.655</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jam</th>             <td>    0.4664</td> <td>    0.427</td> <td>    1.092</td> <td> 0.275</td> <td>   -0.371</td> <td>    1.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jasmine</th>         <td>    0.6034</td> <td>    0.206</td> <td>    2.922</td> <td> 0.003</td> <td>    0.199</td> <td>    1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>juicy</th>           <td>    0.2475</td> <td>    0.138</td> <td>    1.787</td> <td> 0.074</td> <td>   -0.024</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>juniper</th>         <td>    0.2895</td> <td>    0.436</td> <td>    0.665</td> <td> 0.506</td> <td>   -0.565</td> <td>    1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>just</th>            <td>   -0.3254</td> <td>    0.362</td> <td>   -0.899</td> <td> 0.369</td> <td>   -1.035</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ken</th>             <td>   -0.6055</td> <td>    0.384</td> <td>   -1.575</td> <td> 0.115</td> <td>   -1.359</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kenya</th>           <td>    2.2910</td> <td>    0.449</td> <td>    5.098</td> <td> 0.000</td> <td>    1.410</td> <td>    3.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>keurig</th>          <td>    1.2595</td> <td>    0.760</td> <td>    1.657</td> <td> 0.098</td> <td>   -0.231</td> <td>    2.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key</th>             <td>   -0.7433</td> <td>    0.358</td> <td>   -2.076</td> <td> 0.038</td> <td>   -1.445</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>laden</th>           <td>    0.3542</td> <td>    0.258</td> <td>    1.372</td> <td> 0.170</td> <td>   -0.152</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lasting</th>         <td>    0.5293</td> <td>    0.330</td> <td>    1.604</td> <td> 0.109</td> <td>   -0.118</td> <td>    1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lavender</th>        <td>    0.3571</td> <td>    0.178</td> <td>    2.006</td> <td> 0.045</td> <td>    0.008</td> <td>    0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>layered</th>         <td>    0.0435</td> <td>    0.204</td> <td>    0.213</td> <td> 0.831</td> <td>   -0.356</td> <td>    0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lead</th>            <td>   -0.0111</td> <td>    0.253</td> <td>   -0.044</td> <td> 0.965</td> <td>   -0.507</td> <td>    0.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leads</th>           <td>    0.0492</td> <td>    0.171</td> <td>    0.287</td> <td> 0.774</td> <td>   -0.287</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaf</th>            <td>    1.1526</td> <td>    0.489</td> <td>    2.355</td> <td> 0.019</td> <td>    0.193</td> <td>    2.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lean</th>            <td>   -1.1793</td> <td>    0.303</td> <td>   -3.894</td> <td> 0.000</td> <td>   -1.773</td> <td>   -0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaning</th>         <td>    0.3809</td> <td>    0.210</td> <td>    1.813</td> <td> 0.070</td> <td>   -0.031</td> <td>    0.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leanish</th>         <td>   -1.1019</td> <td>    0.325</td> <td>   -3.391</td> <td> 0.001</td> <td>   -1.739</td> <td>   -0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leather</th>         <td>    0.2356</td> <td>    0.278</td> <td>    0.849</td> <td> 0.396</td> <td>   -0.309</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaves</th>          <td>    1.2911</td> <td>    0.433</td> <td>    2.983</td> <td> 0.003</td> <td>    0.442</td> <td>    2.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lemon</th>           <td>    0.3826</td> <td>    0.162</td> <td>    2.367</td> <td> 0.018</td> <td>    0.066</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lemony</th>          <td>    0.3911</td> <td>    0.268</td> <td>    1.459</td> <td> 0.145</td> <td>   -0.134</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>light</th>           <td>   -0.1102</td> <td>    0.165</td> <td>   -0.668</td> <td> 0.504</td> <td>   -0.434</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lightly</th>         <td>   -0.2770</td> <td>    0.151</td> <td>   -1.840</td> <td> 0.066</td> <td>   -0.572</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>like</th>            <td>   -0.3350</td> <td>    0.131</td> <td>   -2.553</td> <td> 0.011</td> <td>   -0.592</td> <td>   -0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liked</th>           <td>    0.0420</td> <td>    0.392</td> <td>    0.107</td> <td> 0.915</td> <td>   -0.727</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lilac</th>           <td>    0.3400</td> <td>    0.196</td> <td>    1.735</td> <td> 0.083</td> <td>   -0.044</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lily</th>            <td>    0.3070</td> <td>    0.179</td> <td>    1.715</td> <td> 0.086</td> <td>   -0.044</td> <td>    0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lime</th>            <td>    0.7220</td> <td>    0.250</td> <td>    2.887</td> <td> 0.004</td> <td>    0.232</td> <td>    1.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>limited</th>         <td>    0.1630</td> <td>    0.543</td> <td>    0.300</td> <td> 0.764</td> <td>   -0.901</td> <td>    1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>linger</th>          <td>    0.2980</td> <td>    0.265</td> <td>    1.127</td> <td> 0.260</td> <td>   -0.221</td> <td>    0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lingering</th>       <td>    0.1332</td> <td>    0.202</td> <td>    0.658</td> <td> 0.510</td> <td>   -0.263</td> <td>    0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lingers</th>         <td>    0.5825</td> <td>    0.254</td> <td>    2.289</td> <td> 0.022</td> <td>    0.084</td> <td>    1.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>little</th>          <td>   -0.0157</td> <td>    0.244</td> <td>   -0.065</td> <td> 0.949</td> <td>   -0.494</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lively</th>          <td>   -0.0996</td> <td>    0.156</td> <td>   -0.637</td> <td> 0.524</td> <td>   -0.406</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>long</th>            <td>    0.5870</td> <td>    0.130</td> <td>    4.514</td> <td> 0.000</td> <td>    0.332</td> <td>    0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lovely</th>          <td>   -0.4870</td> <td>    0.381</td> <td>   -1.278</td> <td> 0.201</td> <td>   -1.234</td> <td>    0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low</th>             <td>    0.8532</td> <td>    0.220</td> <td>    3.870</td> <td> 0.000</td> <td>    0.421</td> <td>    1.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lush</th>            <td>    0.3388</td> <td>    0.160</td> <td>    2.120</td> <td> 0.034</td> <td>    0.025</td> <td>    0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lushly</th>          <td>    0.5999</td> <td>    0.230</td> <td>    2.605</td> <td> 0.009</td> <td>    0.148</td> <td>    1.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lychee</th>          <td>    0.7091</td> <td>    0.272</td> <td>    2.611</td> <td> 0.009</td> <td>    0.177</td> <td>    1.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lyric</th>           <td>    0.9682</td> <td>    0.341</td> <td>    2.840</td> <td> 0.005</td> <td>    0.300</td> <td>    1.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lyrically</th>       <td>    0.9467</td> <td>    0.307</td> <td>    3.088</td> <td> 0.002</td> <td>    0.346</td> <td>    1.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>macadamia</th>       <td>    0.2220</td> <td>    0.473</td> <td>    0.469</td> <td> 0.639</td> <td>   -0.706</td> <td>    1.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>magnolia</th>        <td>    0.3334</td> <td>    0.173</td> <td>    1.930</td> <td> 0.054</td> <td>   -0.005</td> <td>    0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>maintains</th>       <td>    0.0648</td> <td>    0.300</td> <td>    0.216</td> <td> 0.829</td> <td>   -0.523</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>malt</th>            <td>   -0.0923</td> <td>    0.444</td> <td>   -0.208</td> <td> 0.835</td> <td>   -0.963</td> <td>    0.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>malty</th>           <td>    1.9427</td> <td>    0.386</td> <td>    5.039</td> <td> 0.000</td> <td>    1.187</td> <td>    2.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mango</th>           <td>    0.4305</td> <td>    0.212</td> <td>    2.028</td> <td> 0.043</td> <td>    0.014</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>maple</th>           <td>    0.4485</td> <td>    0.701</td> <td>    0.640</td> <td> 0.522</td> <td>   -0.926</td> <td>    1.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marjoram</th>        <td>    0.4390</td> <td>    0.238</td> <td>    1.844</td> <td> 0.065</td> <td>   -0.028</td> <td>    0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>medium</th>          <td>    0.4806</td> <td>    0.173</td> <td>    2.778</td> <td> 0.006</td> <td>    0.141</td> <td>    0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>melon</th>           <td>    0.5800</td> <td>    0.347</td> <td>    1.673</td> <td> 0.094</td> <td>   -0.100</td> <td>    1.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mesquite</th>        <td>    0.3670</td> <td>    0.380</td> <td>    0.965</td> <td> 0.335</td> <td>   -0.379</td> <td>    1.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>meyer</th>           <td>    0.4000</td> <td>    0.324</td> <td>    1.235</td> <td> 0.217</td> <td>   -0.235</td> <td>    1.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mid</th>             <td>   -0.0525</td> <td>    0.401</td> <td>   -0.131</td> <td> 0.896</td> <td>   -0.839</td> <td>    0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>miguel</th>          <td>    1.4165</td> <td>    0.535</td> <td>    2.649</td> <td> 0.008</td> <td>    0.368</td> <td>    2.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mild</th>            <td>    0.2018</td> <td>    0.272</td> <td>    0.743</td> <td> 0.458</td> <td>   -0.331</td> <td>    0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mildly</th>          <td>   -0.3632</td> <td>    0.205</td> <td>   -1.771</td> <td> 0.077</td> <td>   -0.765</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>milk</th>            <td>    0.6098</td> <td>    0.216</td> <td>    2.826</td> <td> 0.005</td> <td>    0.187</td> <td>    1.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mint</th>            <td>    0.4797</td> <td>    0.279</td> <td>    1.718</td> <td> 0.086</td> <td>   -0.068</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minty</th>           <td>    0.5104</td> <td>    0.336</td> <td>    1.519</td> <td> 0.129</td> <td>   -0.148</td> <td>    1.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>moist</th>           <td>    0.0958</td> <td>    0.331</td> <td>    0.290</td> <td> 0.772</td> <td>   -0.553</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>molasses</th>        <td>    0.5300</td> <td>    0.195</td> <td>    2.721</td> <td> 0.007</td> <td>    0.148</td> <td>    0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mulberry</th>        <td>    0.4921</td> <td>    0.274</td> <td>    1.796</td> <td> 0.073</td> <td>   -0.045</td> <td>    1.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>multi</th>           <td>    0.3313</td> <td>    0.240</td> <td>    1.383</td> <td> 0.167</td> <td>   -0.139</td> <td>    0.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mushroom</th>        <td>    0.6579</td> <td>    0.316</td> <td>    2.082</td> <td> 0.037</td> <td>    0.038</td> <td>    1.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musk</th>            <td>    0.1790</td> <td>    0.287</td> <td>    0.623</td> <td> 0.533</td> <td>   -0.384</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musky</th>           <td>    0.3677</td> <td>    0.448</td> <td>    0.820</td> <td> 0.412</td> <td>   -0.511</td> <td>    1.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mustiness</th>       <td>   -0.8241</td> <td>    0.428</td> <td>   -1.927</td> <td> 0.054</td> <td>   -1.663</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musty</th>           <td>   -1.3749</td> <td>    0.380</td> <td>   -3.618</td> <td> 0.000</td> <td>   -2.120</td> <td>   -0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>muted</th>           <td>    0.1078</td> <td>    0.223</td> <td>    0.484</td> <td> 0.629</td> <td>   -0.329</td> <td>    0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>myrrh</th>           <td>    0.4817</td> <td>    0.266</td> <td>    1.811</td> <td> 0.070</td> <td>   -0.040</td> <td>    1.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>narcissus</th>       <td>    0.5444</td> <td>    0.177</td> <td>    3.071</td> <td> 0.002</td> <td>    0.197</td> <td>    0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nectar</th>          <td>    0.8900</td> <td>    0.335</td> <td>    2.657</td> <td> 0.008</td> <td>    0.233</td> <td>    1.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nectarine</th>       <td>    0.3852</td> <td>    0.291</td> <td>    1.325</td> <td> 0.185</td> <td>   -0.185</td> <td>    0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nib</th>             <td>    0.0014</td> <td>    0.170</td> <td>    0.008</td> <td> 0.993</td> <td>   -0.331</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nice</th>            <td>   -2.5408</td> <td>    0.562</td> <td>   -4.518</td> <td> 0.000</td> <td>   -3.643</td> <td>   -1.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nicely</th>          <td>   -0.3050</td> <td>    0.242</td> <td>   -1.259</td> <td> 0.208</td> <td>   -0.780</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night</th>           <td>    0.1310</td> <td>    0.281</td> <td>    0.466</td> <td> 0.641</td> <td>   -0.420</td> <td>    0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nominated</th>       <td>   -0.3140</td> <td>    0.410</td> <td>   -0.765</td> <td> 0.444</td> <td>   -1.118</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nose</th>            <td>   -0.8594</td> <td>    0.265</td> <td>   -3.248</td> <td> 0.001</td> <td>   -1.378</td> <td>   -0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>note</th>            <td>   -0.1580</td> <td>    0.181</td> <td>   -0.874</td> <td> 0.382</td> <td>   -0.513</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>notes</th>           <td>    0.3148</td> <td>    0.137</td> <td>    2.294</td> <td> 0.022</td> <td>    0.046</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nougat</th>          <td>    0.3772</td> <td>    0.236</td> <td>    1.599</td> <td> 0.110</td> <td>   -0.085</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuance</th>          <td>   -0.0681</td> <td>    0.238</td> <td>   -0.286</td> <td> 0.775</td> <td>   -0.535</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuanced</th>         <td>    0.2940</td> <td>    0.200</td> <td>    1.474</td> <td> 0.141</td> <td>   -0.097</td> <td>    0.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nut</th>             <td>    0.1173</td> <td>    0.131</td> <td>    0.896</td> <td> 0.370</td> <td>   -0.139</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutella</th>         <td>    0.9562</td> <td>    0.394</td> <td>    2.426</td> <td> 0.015</td> <td>    0.183</td> <td>    1.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutmeg</th>          <td>    0.7075</td> <td>    0.353</td> <td>    2.005</td> <td> 0.045</td> <td>    0.016</td> <td>    1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuts</th>            <td>   -1.3967</td> <td>    0.426</td> <td>   -3.278</td> <td> 0.001</td> <td>   -2.232</td> <td>   -0.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutty</th>           <td>    0.1719</td> <td>    0.241</td> <td>    0.712</td> <td> 0.476</td> <td>   -0.301</td> <td>    0.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oak</th>             <td>    0.3107</td> <td>    0.167</td> <td>    1.862</td> <td> 0.063</td> <td>   -0.016</td> <td>    0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opulent</th>         <td>    0.2880</td> <td>    0.279</td> <td>    1.033</td> <td> 0.302</td> <td>   -0.259</td> <td>    0.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opulently</th>       <td>    0.0963</td> <td>    0.378</td> <td>    0.255</td> <td> 0.799</td> <td>   -0.644</td> <td>    0.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orange</th>          <td>    0.8932</td> <td>    0.166</td> <td>    5.393</td> <td> 0.000</td> <td>    0.568</td> <td>    1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orangy</th>          <td>    0.2584</td> <td>    0.242</td> <td>    1.068</td> <td> 0.286</td> <td>   -0.216</td> <td>    0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orchid</th>          <td>    0.4828</td> <td>    0.376</td> <td>    1.285</td> <td> 0.199</td> <td>   -0.254</td> <td>    1.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>original</th>        <td>    0.0337</td> <td>    0.252</td> <td>    0.134</td> <td> 0.894</td> <td>   -0.461</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ounce</th>           <td>    0.3367</td> <td>    1.238</td> <td>    0.272</td> <td> 0.786</td> <td>   -2.090</td> <td>    2.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ounces</th>          <td>   -0.3915</td> <td>    0.858</td> <td>   -0.456</td> <td> 0.648</td> <td>   -2.074</td> <td>    1.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>owing</th>           <td>    0.3272</td> <td>    0.484</td> <td>    0.676</td> <td> 0.499</td> <td>   -0.622</td> <td>    1.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>panelists</th>       <td>   -0.2913</td> <td>    0.502</td> <td>   -0.580</td> <td> 0.562</td> <td>   -1.276</td> <td>    0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>papaya</th>          <td>    0.2452</td> <td>    0.333</td> <td>    0.737</td> <td> 0.461</td> <td>   -0.407</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>particular</th>      <td>   -0.0055</td> <td>    0.194</td> <td>   -0.028</td> <td> 0.978</td> <td>   -0.386</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>particularly</th>    <td>    0.0040</td> <td>    0.263</td> <td>    0.015</td> <td> 0.988</td> <td>   -0.511</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parts</th>           <td>    0.2197</td> <td>    0.322</td> <td>    0.682</td> <td> 0.496</td> <td>   -0.412</td> <td>    0.852</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passion</th>         <td>    0.2080</td> <td>    0.346</td> <td>    0.601</td> <td> 0.548</td> <td>   -0.470</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passionfruit</th>    <td>    0.7130</td> <td>    0.447</td> <td>    1.596</td> <td> 0.111</td> <td>   -0.163</td> <td>    1.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peach</th>           <td>    0.5126</td> <td>    0.167</td> <td>    3.068</td> <td> 0.002</td> <td>    0.185</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pear</th>            <td>    0.5879</td> <td>    0.198</td> <td>    2.962</td> <td> 0.003</td> <td>    0.199</td> <td>    0.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pecan</th>           <td>   -0.0139</td> <td>    0.331</td> <td>   -0.042</td> <td> 0.967</td> <td>   -0.663</td> <td>    0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peel</th>            <td>    0.7025</td> <td>    0.550</td> <td>    1.277</td> <td> 0.202</td> <td>   -0.376</td> <td>    1.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peppercorn</th>      <td>    0.5076</td> <td>    0.258</td> <td>    1.969</td> <td> 0.049</td> <td>    0.002</td> <td>    1.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perfectly</th>       <td>    0.2675</td> <td>    0.383</td> <td>    0.698</td> <td> 0.485</td> <td>   -0.484</td> <td>    1.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persimmon</th>       <td>    0.8104</td> <td>    0.278</td> <td>    2.911</td> <td> 0.004</td> <td>    0.265</td> <td>    1.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persist</th>         <td>    0.1784</td> <td>    0.226</td> <td>    0.789</td> <td> 0.430</td> <td>   -0.265</td> <td>    0.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persistence</th>     <td>    0.8437</td> <td>    0.377</td> <td>    2.240</td> <td> 0.025</td> <td>    0.105</td> <td>    1.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persistent</th>      <td>    0.7215</td> <td>    0.320</td> <td>    2.253</td> <td> 0.024</td> <td>    0.094</td> <td>    1.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persists</th>        <td>    0.1141</td> <td>    0.182</td> <td>    0.627</td> <td> 0.531</td> <td>   -0.243</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pert</th>            <td>    0.0640</td> <td>    0.235</td> <td>    0.272</td> <td> 0.785</td> <td>   -0.397</td> <td>    0.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pie</th>             <td>    0.8611</td> <td>    0.359</td> <td>    2.396</td> <td> 0.017</td> <td>    0.157</td> <td>    1.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pine</th>            <td>    0.7234</td> <td>    0.363</td> <td>    1.993</td> <td> 0.046</td> <td>    0.012</td> <td>    1.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pineapple</th>       <td>    0.4833</td> <td>    0.244</td> <td>    1.979</td> <td> 0.048</td> <td>    0.004</td> <td>    0.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pink</th>            <td>    0.0863</td> <td>    0.226</td> <td>    0.382</td> <td> 0.703</td> <td>   -0.357</td> <td>    0.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pipe</th>            <td>    0.1987</td> <td>    0.384</td> <td>    0.518</td> <td> 0.605</td> <td>   -0.554</td> <td>    0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pistachio</th>       <td>    0.3227</td> <td>    0.267</td> <td>    1.207</td> <td> 0.228</td> <td>   -0.202</td> <td>    0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>platinum</th>        <td>    0.3861</td> <td>    0.875</td> <td>    0.441</td> <td> 0.659</td> <td>   -1.330</td> <td>    2.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasant</th>        <td>    0.6169</td> <td>    0.352</td> <td>    1.752</td> <td> 0.080</td> <td>   -0.073</td> <td>    1.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasantly</th>      <td>    0.2906</td> <td>    0.206</td> <td>    1.411</td> <td> 0.158</td> <td>   -0.113</td> <td>    0.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasing</th>        <td>    0.1207</td> <td>    0.180</td> <td>    0.669</td> <td> 0.503</td> <td>   -0.233</td> <td>    0.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasingly</th>      <td>   -0.0444</td> <td>    0.240</td> <td>   -0.185</td> <td> 0.853</td> <td>   -0.515</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plum</th>            <td>    0.2940</td> <td>    0.169</td> <td>    1.736</td> <td> 0.083</td> <td>   -0.038</td> <td>    0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plumeria</th>        <td>    0.8430</td> <td>    0.386</td> <td>    2.184</td> <td> 0.029</td> <td>    0.086</td> <td>    1.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plump</th>           <td>    0.0599</td> <td>    0.201</td> <td>    0.298</td> <td> 0.766</td> <td>   -0.334</td> <td>    0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plush</th>           <td>    0.0348</td> <td>    0.103</td> <td>    0.337</td> <td> 0.736</td> <td>   -0.168</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pod</th>             <td>   -1.6808</td> <td>    0.819</td> <td>   -2.053</td> <td> 0.040</td> <td>   -3.286</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pomegranate</th>     <td>    0.6051</td> <td>    0.223</td> <td>    2.712</td> <td> 0.007</td> <td>    0.168</td> <td>    1.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>port</th>            <td>    0.5198</td> <td>    0.464</td> <td>    1.121</td> <td> 0.262</td> <td>   -0.389</td> <td>    1.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>powder</th>          <td>   -0.0869</td> <td>    0.257</td> <td>   -0.338</td> <td> 0.735</td> <td>   -0.591</td> <td>    0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>power</th>           <td>    0.7043</td> <td>    0.390</td> <td>    1.805</td> <td> 0.071</td> <td>   -0.061</td> <td>    1.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>powerful</th>        <td>    0.8498</td> <td>    0.335</td> <td>    2.540</td> <td> 0.011</td> <td>    0.194</td> <td>    1.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>presence</th>        <td>   -0.1116</td> <td>    0.293</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.687</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>probably</th>        <td>    0.8924</td> <td>    0.425</td> <td>    2.101</td> <td> 0.036</td> <td>    0.059</td> <td>    1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>produce</th>         <td>    0.8127</td> <td>    0.744</td> <td>    1.092</td> <td> 0.275</td> <td>   -0.646</td> <td>    2.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>produced</th>        <td>    0.0909</td> <td>    0.594</td> <td>    0.153</td> <td> 0.878</td> <td>   -1.073</td> <td>    1.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>profile</th>         <td>    0.2989</td> <td>    0.224</td> <td>    1.333</td> <td> 0.183</td> <td>   -0.141</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>promise</th>         <td>    0.0711</td> <td>    0.315</td> <td>    0.226</td> <td> 0.821</td> <td>   -0.546</td> <td>    0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pronounced</th>      <td>    0.5608</td> <td>    0.271</td> <td>    2.067</td> <td> 0.039</td> <td>    0.029</td> <td>    1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prune</th>           <td>   -0.0996</td> <td>    0.331</td> <td>   -0.301</td> <td> 0.764</td> <td>   -0.748</td> <td>    0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pruny</th>           <td>   -1.4509</td> <td>    0.371</td> <td>   -3.909</td> <td> 0.000</td> <td>   -2.179</td> <td>   -0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungency</th>        <td>   -0.2384</td> <td>    0.255</td> <td>   -0.937</td> <td> 0.349</td> <td>   -0.738</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungent</th>         <td>    0.2775</td> <td>    0.155</td> <td>    1.787</td> <td> 0.074</td> <td>   -0.027</td> <td>    0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungently</th>       <td>    0.2094</td> <td>    0.241</td> <td>    0.868</td> <td> 0.385</td> <td>   -0.263</td> <td>    0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pure</th>            <td>    0.9066</td> <td>    0.237</td> <td>    3.823</td> <td> 0.000</td> <td>    0.442</td> <td>    1.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quickly</th>         <td>    0.2194</td> <td>    0.395</td> <td>    0.556</td> <td> 0.578</td> <td>   -0.555</td> <td>    0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiet</th>           <td>    0.3831</td> <td>    0.160</td> <td>    2.390</td> <td> 0.017</td> <td>    0.069</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quietly</th>         <td>    0.4195</td> <td>    0.168</td> <td>    2.493</td> <td> 0.013</td> <td>    0.090</td> <td>    0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quite</th>           <td>   -0.5770</td> <td>    0.256</td> <td>   -2.258</td> <td> 0.024</td> <td>   -1.078</td> <td>   -0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raisin</th>          <td>    0.2369</td> <td>    0.209</td> <td>    1.131</td> <td> 0.258</td> <td>   -0.174</td> <td>    0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raisiny</th>         <td>    0.7766</td> <td>    0.375</td> <td>    2.071</td> <td> 0.038</td> <td>    0.041</td> <td>    1.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>range</th>           <td>    0.0990</td> <td>    0.242</td> <td>    0.409</td> <td> 0.682</td> <td>   -0.375</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raspberry</th>       <td>    0.6292</td> <td>    0.217</td> <td>    2.895</td> <td> 0.004</td> <td>    0.203</td> <td>    1.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>          <td>   -0.5098</td> <td>    0.346</td> <td>   -1.475</td> <td> 0.140</td> <td>   -1.187</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raw</th>             <td>   -0.2741</td> <td>    0.520</td> <td>   -0.527</td> <td> 0.598</td> <td>   -1.293</td> <td>    0.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>read</th>            <td>    0.2281</td> <td>    0.283</td> <td>    0.806</td> <td> 0.420</td> <td>   -0.327</td> <td>    0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reader</th>          <td>    0.0957</td> <td>    0.354</td> <td>    0.270</td> <td> 0.787</td> <td>   -0.598</td> <td>    0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reads</th>           <td>   -0.0967</td> <td>    0.276</td> <td>   -0.350</td> <td> 0.726</td> <td>   -0.638</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ready</th>           <td>    1.0860</td> <td>    0.964</td> <td>    1.126</td> <td> 0.260</td> <td>   -0.804</td> <td>    2.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red</th>             <td>    0.3264</td> <td>    0.219</td> <td>    1.490</td> <td> 0.136</td> <td>   -0.103</td> <td>    0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>redolent</th>        <td>    0.2441</td> <td>    0.305</td> <td>    0.799</td> <td> 0.424</td> <td>   -0.355</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>redwood</th>         <td>    0.6364</td> <td>    0.486</td> <td>    1.310</td> <td> 0.190</td> <td>   -0.316</td> <td>    1.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refreshing</th>      <td>    0.4796</td> <td>    0.358</td> <td>    1.338</td> <td> 0.181</td> <td>   -0.223</td> <td>    1.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relatively</th>      <td>   -0.0272</td> <td>    0.338</td> <td>   -0.080</td> <td> 0.936</td> <td>   -0.690</td> <td>    0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>remains</th>         <td>   -0.1365</td> <td>    0.287</td> <td>   -0.475</td> <td> 0.635</td> <td>   -0.699</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonance</th>       <td>   -0.1685</td> <td>    0.352</td> <td>   -0.479</td> <td> 0.632</td> <td>   -0.858</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonant</th>        <td>    0.2293</td> <td>    0.110</td> <td>    2.091</td> <td> 0.037</td> <td>    0.014</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonantly</th>      <td>    0.4106</td> <td>    0.308</td> <td>    1.333</td> <td> 0.183</td> <td>   -0.193</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonate</th>        <td>    0.2929</td> <td>    0.353</td> <td>    0.829</td> <td> 0.407</td> <td>   -0.400</td> <td>    0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonates</th>       <td>    0.2085</td> <td>    0.323</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.426</td> <td>    0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resurface</th>       <td>    0.2513</td> <td>    0.310</td> <td>    0.810</td> <td> 0.418</td> <td>   -0.357</td> <td>    0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resurfacing</th>     <td>    0.2804</td> <td>    0.327</td> <td>    0.857</td> <td> 0.392</td> <td>   -0.361</td> <td>    0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rhododendron</th>    <td>    0.4572</td> <td>    0.274</td> <td>    1.670</td> <td> 0.095</td> <td>   -0.079</td> <td>    0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rich</th>            <td>    0.4363</td> <td>    0.122</td> <td>    3.585</td> <td> 0.000</td> <td>    0.198</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>richly</th>          <td>    0.5415</td> <td>    0.127</td> <td>    4.276</td> <td> 0.000</td> <td>    0.293</td> <td>    0.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>richness</th>        <td>    0.3228</td> <td>    0.297</td> <td>    1.087</td> <td> 0.277</td> <td>   -0.259</td> <td>    0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rings</th>           <td>    0.2998</td> <td>    0.271</td> <td>    1.105</td> <td> 0.269</td> <td>   -0.232</td> <td>    0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ripe</th>            <td>    0.5420</td> <td>    0.162</td> <td>    3.344</td> <td> 0.001</td> <td>    0.224</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roast</th>           <td>   -0.0856</td> <td>    0.211</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.499</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roasted</th>         <td>    0.1138</td> <td>    0.179</td> <td>    0.636</td> <td> 0.525</td> <td>   -0.237</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roastiness</th>      <td>   -0.1713</td> <td>    0.402</td> <td>   -0.426</td> <td> 0.670</td> <td>   -0.960</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roasty</th>          <td>    0.4150</td> <td>    0.222</td> <td>    1.869</td> <td> 0.062</td> <td>   -0.020</td> <td>    0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rose</th>            <td>    0.4732</td> <td>    0.185</td> <td>    2.559</td> <td> 0.011</td> <td>    0.111</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rough</th>           <td>   -0.0922</td> <td>    0.266</td> <td>   -0.347</td> <td> 0.729</td> <td>   -0.613</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>round</th>           <td>   -0.0142</td> <td>    0.144</td> <td>   -0.099</td> <td> 0.921</td> <td>   -0.296</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounded</th>         <td>    0.3155</td> <td>    0.210</td> <td>    1.502</td> <td> 0.133</td> <td>   -0.096</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounding</th>        <td>    0.0969</td> <td>    0.194</td> <td>    0.500</td> <td> 0.617</td> <td>   -0.283</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roundly</th>         <td>    0.1960</td> <td>    0.166</td> <td>    1.181</td> <td> 0.238</td> <td>   -0.129</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounds</th>          <td>    0.1466</td> <td>    0.222</td> <td>    0.662</td> <td> 0.508</td> <td>   -0.288</td> <td>    0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rum</th>             <td>    1.0017</td> <td>    0.380</td> <td>    2.633</td> <td> 0.008</td> <td>    0.256</td> <td>    1.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rye</th>             <td>    0.0581</td> <td>    0.507</td> <td>    0.114</td> <td> 0.909</td> <td>   -0.936</td> <td>    1.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sage</th>            <td>    0.3860</td> <td>    0.298</td> <td>    1.295</td> <td> 0.195</td> <td>   -0.198</td> <td>    0.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salted</th>          <td>   -0.4306</td> <td>    0.390</td> <td>   -1.105</td> <td> 0.269</td> <td>   -1.195</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salty</th>           <td>    0.0006</td> <td>    0.298</td> <td>    0.002</td> <td> 0.998</td> <td>   -0.583</td> <td>    0.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sample</th>          <td>   -1.3822</td> <td>    0.574</td> <td>   -2.409</td> <td> 0.016</td> <td>   -2.507</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sandalwood</th>      <td>    0.4057</td> <td>    0.143</td> <td>    2.845</td> <td> 0.004</td> <td>    0.126</td> <td>    0.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sassafras</th>       <td>    0.5654</td> <td>    0.492</td> <td>    1.149</td> <td> 0.251</td> <td>   -0.400</td> <td>    1.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satiny</th>          <td>   -0.1335</td> <td>    0.111</td> <td>   -1.208</td> <td> 0.227</td> <td>   -0.350</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfying</th>      <td>    0.0410</td> <td>    0.304</td> <td>    0.135</td> <td> 0.893</td> <td>   -0.554</td> <td>    0.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saturated</th>       <td>    0.5965</td> <td>    0.196</td> <td>    3.042</td> <td> 0.002</td> <td>    0.212</td> <td>    0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saturates</th>       <td>    0.4341</td> <td>    0.287</td> <td>    1.511</td> <td> 0.131</td> <td>   -0.129</td> <td>    0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>savory</th>          <td>    0.0997</td> <td>    0.134</td> <td>    0.741</td> <td> 0.459</td> <td>   -0.164</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scaled</th>          <td>   -0.1267</td> <td>    0.587</td> <td>   -0.216</td> <td> 0.829</td> <td>   -1.278</td> <td>    1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scorched</th>        <td>   -0.1017</td> <td>    0.223</td> <td>   -0.457</td> <td> 0.648</td> <td>   -0.538</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>semi</th>            <td>    0.3569</td> <td>    0.253</td> <td>    1.408</td> <td> 0.159</td> <td>   -0.140</td> <td>    0.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sensation</th>       <td>    0.4374</td> <td>    0.294</td> <td>    1.488</td> <td> 0.137</td> <td>   -0.139</td> <td>    1.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>serve</th>           <td>    1.3079</td> <td>    1.333</td> <td>    0.981</td> <td> 0.327</td> <td>   -1.306</td> <td>    3.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>serving</th>         <td>    0.2872</td> <td>    0.961</td> <td>    0.299</td> <td> 0.765</td> <td>   -1.597</td> <td>    2.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shadow</th>          <td>   -2.9243</td> <td>    0.516</td> <td>   -5.668</td> <td> 0.000</td> <td>   -3.936</td> <td>   -1.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shallow</th>         <td>   -0.5068</td> <td>    0.410</td> <td>   -1.237</td> <td> 0.216</td> <td>   -1.310</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sharp</th>           <td>   -1.8431</td> <td>    0.322</td> <td>   -5.730</td> <td> 0.000</td> <td>   -2.474</td> <td>   -1.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sharpness</th>       <td>   -0.8867</td> <td>    0.398</td> <td>   -2.230</td> <td> 0.026</td> <td>   -1.666</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shifting</th>        <td>    0.3880</td> <td>    0.312</td> <td>    1.243</td> <td> 0.214</td> <td>   -0.224</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shimmer</th>         <td>    1.0275</td> <td>    0.260</td> <td>    3.955</td> <td> 0.000</td> <td>    0.518</td> <td>    1.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>short</th>           <td>   -0.3577</td> <td>    0.123</td> <td>   -2.908</td> <td> 0.004</td> <td>   -0.599</td> <td>   -0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shot</th>            <td>    0.0104</td> <td>    0.385</td> <td>    0.027</td> <td> 0.979</td> <td>   -0.744</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>silky</th>           <td>    0.0163</td> <td>    0.122</td> <td>    0.133</td> <td> 0.894</td> <td>   -0.223</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simple</th>          <td>   -0.4172</td> <td>    0.200</td> <td>   -2.088</td> <td> 0.037</td> <td>   -0.809</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simplifies</th>      <td>   -0.0077</td> <td>    0.236</td> <td>   -0.033</td> <td> 0.974</td> <td>   -0.471</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simplify</th>        <td>   -0.5671</td> <td>    0.373</td> <td>   -1.521</td> <td> 0.128</td> <td>   -1.298</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>singed</th>          <td>   -0.2035</td> <td>    0.434</td> <td>   -0.469</td> <td> 0.639</td> <td>   -1.054</td> <td>    0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single</th>          <td>   -2.2073</td> <td>    0.988</td> <td>   -2.234</td> <td> 0.026</td> <td>   -4.145</td> <td>   -0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>            <td>   -0.0566</td> <td>    0.570</td> <td>   -0.099</td> <td> 0.921</td> <td>   -1.174</td> <td>    1.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slight</th>          <td>    0.8145</td> <td>    0.224</td> <td>    3.636</td> <td> 0.000</td> <td>    0.375</td> <td>    1.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slightly</th>        <td>    0.0897</td> <td>    0.167</td> <td>    0.536</td> <td> 0.592</td> <td>   -0.238</td> <td>    0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>small</th>           <td>    0.0378</td> <td>    0.243</td> <td>    0.155</td> <td> 0.877</td> <td>   -0.440</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoke</th>           <td>    0.1274</td> <td>    0.367</td> <td>    0.348</td> <td> 0.728</td> <td>   -0.591</td> <td>    0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoky</th>           <td>    0.3731</td> <td>    0.242</td> <td>    1.541</td> <td> 0.123</td> <td>   -0.102</td> <td>    0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smooth</th>          <td>    0.1050</td> <td>    0.100</td> <td>    1.047</td> <td> 0.295</td> <td>   -0.092</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoothly</th>        <td>    0.3995</td> <td>    0.250</td> <td>    1.596</td> <td> 0.111</td> <td>   -0.091</td> <td>    0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soft</th>            <td>    0.4904</td> <td>    0.202</td> <td>    2.428</td> <td> 0.015</td> <td>    0.094</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soften</th>          <td>   -0.2755</td> <td>    0.279</td> <td>   -0.987</td> <td> 0.324</td> <td>   -0.823</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softened</th>        <td>    0.4637</td> <td>    0.334</td> <td>    1.389</td> <td> 0.165</td> <td>   -0.191</td> <td>    1.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softening</th>       <td>   -0.0456</td> <td>    0.360</td> <td>   -0.127</td> <td> 0.899</td> <td>   -0.752</td> <td>    0.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softens</th>         <td>   -0.2304</td> <td>    0.205</td> <td>   -1.125</td> <td> 0.261</td> <td>   -0.632</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softly</th>          <td>    0.4227</td> <td>    0.247</td> <td>    1.708</td> <td> 0.088</td> <td>   -0.062</td> <td>    0.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>solid</th>           <td>   -0.9886</td> <td>    0.306</td> <td>   -3.235</td> <td> 0.001</td> <td>   -1.588</td> <td>   -0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sort</th>            <td>   -0.2810</td> <td>    0.295</td> <td>   -0.952</td> <td> 0.341</td> <td>   -0.860</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spearmint</th>       <td>    0.4503</td> <td>    0.359</td> <td>    1.256</td> <td> 0.209</td> <td>   -0.253</td> <td>    1.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spice</th>           <td>    0.4745</td> <td>    0.229</td> <td>    2.075</td> <td> 0.038</td> <td>    0.026</td> <td>    0.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spices</th>          <td>    0.2130</td> <td>    0.354</td> <td>    0.601</td> <td> 0.548</td> <td>   -0.482</td> <td>    0.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spicy</th>           <td>    0.1464</td> <td>    0.224</td> <td>    0.652</td> <td> 0.514</td> <td>   -0.293</td> <td>    0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>star</th>            <td>    0.3112</td> <td>    0.238</td> <td>    1.305</td> <td> 0.192</td> <td>   -0.156</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stone</th>           <td>    0.0538</td> <td>    0.265</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.466</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>straight</th>        <td>    0.1464</td> <td>    0.355</td> <td>    0.413</td> <td> 0.680</td> <td>   -0.549</td> <td>    0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>straightforward</th> <td>    0.0352</td> <td>    0.249</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.453</td> <td>    0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>strawberry</th>      <td>    0.4936</td> <td>    0.198</td> <td>    2.488</td> <td> 0.013</td> <td>    0.105</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>structure</th>       <td>   -0.0862</td> <td>    0.141</td> <td>   -0.613</td> <td> 0.540</td> <td>   -0.362</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>style</th>           <td>    0.2327</td> <td>    0.408</td> <td>    0.570</td> <td> 0.568</td> <td>   -0.567</td> <td>    1.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subdued</th>         <td>    0.0621</td> <td>    0.260</td> <td>    0.239</td> <td> 0.811</td> <td>   -0.447</td> <td>    0.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>substantial</th>     <td>   -1.0050</td> <td>    0.386</td> <td>   -2.601</td> <td> 0.009</td> <td>   -1.763</td> <td>   -0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subtle</th>          <td>    0.9313</td> <td>    0.286</td> <td>    3.260</td> <td> 0.001</td> <td>    0.371</td> <td>    1.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subtly</th>          <td>   -0.0546</td> <td>    0.198</td> <td>   -0.276</td> <td> 0.783</td> <td>   -0.443</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sugar</th>           <td>   -0.5629</td> <td>    0.682</td> <td>   -0.826</td> <td> 0.409</td> <td>   -1.900</td> <td>    0.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sugary</th>          <td>    0.8631</td> <td>    0.348</td> <td>    2.482</td> <td> 0.013</td> <td>    0.181</td> <td>    1.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggest</th>         <td>    0.9508</td> <td>    0.366</td> <td>    2.601</td> <td> 0.009</td> <td>    0.234</td> <td>    1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggesting</th>      <td>    0.0926</td> <td>    0.291</td> <td>    0.319</td> <td> 0.750</td> <td>   -0.478</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggestion</th>      <td>   -0.1274</td> <td>    0.206</td> <td>   -0.617</td> <td> 0.537</td> <td>   -0.532</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggestions</th>     <td>   -0.1474</td> <td>    0.174</td> <td>   -0.846</td> <td> 0.398</td> <td>   -0.489</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggests</th>        <td>    0.5596</td> <td>    0.284</td> <td>    1.973</td> <td> 0.049</td> <td>    0.004</td> <td>    1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sumatra</th>         <td>   -0.4284</td> <td>    0.435</td> <td>   -0.986</td> <td> 0.324</td> <td>   -1.280</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>superb</th>          <td>    1.3626</td> <td>    0.310</td> <td>    4.399</td> <td> 0.000</td> <td>    0.755</td> <td>    1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>support</th>         <td>   -0.3264</td> <td>    0.383</td> <td>   -0.852</td> <td> 0.394</td> <td>   -1.078</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>supported</th>       <td>    0.3194</td> <td>    0.214</td> <td>    1.493</td> <td> 0.136</td> <td>   -0.100</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>supporting</th>      <td>    0.5505</td> <td>    0.367</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.170</td> <td>    1.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surfaces</th>        <td>   -0.4043</td> <td>    0.305</td> <td>   -1.324</td> <td> 0.186</td> <td>   -1.003</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surprising</th>      <td>    0.9747</td> <td>    0.404</td> <td>    2.410</td> <td> 0.016</td> <td>    0.182</td> <td>    1.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surprisingly</th>    <td>    0.0698</td> <td>    0.245</td> <td>    0.284</td> <td> 0.776</td> <td>   -0.412</td> <td>    0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sustained</th>       <td>   -0.1633</td> <td>    0.341</td> <td>   -0.480</td> <td> 0.632</td> <td>   -0.831</td> <td>    0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweet</th>           <td>    0.3366</td> <td>    0.125</td> <td>    2.684</td> <td> 0.007</td> <td>    0.091</td> <td>    0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetens</th>        <td>    0.6252</td> <td>    0.245</td> <td>    2.549</td> <td> 0.011</td> <td>    0.144</td> <td>    1.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetly</th>         <td>    0.1696</td> <td>    0.123</td> <td>    1.377</td> <td> 0.169</td> <td>   -0.072</td> <td>    0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetness</th>       <td>    0.7661</td> <td>    0.273</td> <td>    2.807</td> <td> 0.005</td> <td>    0.231</td> <td>    1.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syrup</th>           <td>   -0.0428</td> <td>    0.695</td> <td>   -0.062</td> <td> 0.951</td> <td>   -1.405</td> <td>    1.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syrupy</th>          <td>   -0.0411</td> <td>    0.159</td> <td>   -0.258</td> <td> 0.796</td> <td>   -0.353</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tamarind</th>        <td>    0.5955</td> <td>    0.218</td> <td>    2.731</td> <td> 0.006</td> <td>    0.168</td> <td>    1.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tangerine</th>       <td>    0.4454</td> <td>    0.165</td> <td>    2.707</td> <td> 0.007</td> <td>    0.123</td> <td>    0.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tangy</th>           <td>    0.3301</td> <td>    0.394</td> <td>    0.838</td> <td> 0.402</td> <td>   -0.442</td> <td>    1.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tart</th>            <td>    0.0943</td> <td>    0.135</td> <td>    0.700</td> <td> 0.484</td> <td>   -0.170</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tartly</th>          <td>    0.3410</td> <td>    0.256</td> <td>    1.334</td> <td> 0.182</td> <td>   -0.160</td> <td>    0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taste</th>           <td>   -2.1545</td> <td>    0.380</td> <td>   -5.670</td> <td> 0.000</td> <td>   -2.899</td> <td>   -1.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taster</th>          <td>    0.2340</td> <td>    0.557</td> <td>    0.420</td> <td> 0.675</td> <td>   -0.859</td> <td>    1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tea</th>             <td>   -0.1541</td> <td>    0.268</td> <td>   -0.576</td> <td> 0.565</td> <td>   -0.679</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ted</th>             <td>    1.7536</td> <td>    0.466</td> <td>    3.760</td> <td> 0.000</td> <td>    0.839</td> <td>    2.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tested</th>          <td>   -1.8313</td> <td>    0.857</td> <td>   -2.137</td> <td> 0.033</td> <td>   -3.511</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>think</th>           <td>    0.0366</td> <td>    0.328</td> <td>    0.112</td> <td> 0.911</td> <td>   -0.606</td> <td>    0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>throughline</th>     <td>    0.0009</td> <td>    0.304</td> <td>    0.003</td> <td> 0.998</td> <td>   -0.595</td> <td>    0.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thyme</th>           <td>    0.2394</td> <td>    0.217</td> <td>    1.103</td> <td> 0.270</td> <td>   -0.186</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tickle</th>          <td>    0.9535</td> <td>    0.352</td> <td>    2.709</td> <td> 0.007</td> <td>    0.263</td> <td>    1.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tight</th>           <td>   -0.0088</td> <td>    0.392</td> <td>   -0.023</td> <td> 0.982</td> <td>   -0.777</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toast</th>           <td>    0.1524</td> <td>    0.286</td> <td>    0.533</td> <td> 0.594</td> <td>   -0.408</td> <td>    0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toasted</th>         <td>   -0.0184</td> <td>    0.401</td> <td>   -0.046</td> <td> 0.963</td> <td>   -0.805</td> <td>    0.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toasty</th>          <td>    0.6420</td> <td>    0.449</td> <td>    1.430</td> <td> 0.153</td> <td>   -0.238</td> <td>    1.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tobacco</th>         <td>    0.5252</td> <td>    0.411</td> <td>    1.278</td> <td> 0.202</td> <td>   -0.281</td> <td>    1.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toffee</th>          <td>    0.3176</td> <td>    0.257</td> <td>    1.235</td> <td> 0.217</td> <td>   -0.187</td> <td>    0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tomato</th>          <td>   -0.4110</td> <td>    0.314</td> <td>   -1.308</td> <td> 0.191</td> <td>   -1.027</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toned</th>           <td>   -0.1233</td> <td>    0.136</td> <td>   -0.908</td> <td> 0.364</td> <td>   -0.390</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tones</th>           <td>   -0.5558</td> <td>    0.157</td> <td>   -3.535</td> <td> 0.000</td> <td>   -0.864</td> <td>   -0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>touch</th>           <td>    0.3781</td> <td>    0.253</td> <td>    1.492</td> <td> 0.136</td> <td>   -0.119</td> <td>    0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tropical</th>        <td>    0.4527</td> <td>    0.316</td> <td>    1.431</td> <td> 0.152</td> <td>   -0.167</td> <td>    1.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turn</th>            <td>    0.3266</td> <td>    0.231</td> <td>    1.413</td> <td> 0.158</td> <td>   -0.126</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turned</th>          <td>    0.2654</td> <td>    0.421</td> <td>    0.631</td> <td> 0.528</td> <td>   -0.560</td> <td>    1.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turning</th>         <td>    0.0188</td> <td>    0.351</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.670</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turns</th>           <td>   -0.4584</td> <td>    0.190</td> <td>   -2.416</td> <td> 0.016</td> <td>   -0.831</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>underlying</th>      <td>-2.877e-05</td> <td>    0.389</td> <td>-7.39e-05</td> <td> 1.000</td> <td>   -0.763</td> <td>    0.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>understated</th>     <td>    1.5134</td> <td>    0.316</td> <td>    4.793</td> <td> 0.000</td> <td>    0.894</td> <td>    2.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>undertones</th>      <td>    0.1229</td> <td>    0.132</td> <td>    0.929</td> <td> 0.353</td> <td>   -0.137</td> <td>    0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unusual</th>         <td>    0.7068</td> <td>    0.304</td> <td>    2.328</td> <td> 0.020</td> <td>    0.112</td> <td>    1.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>using</th>           <td>   -0.3374</td> <td>    0.698</td> <td>   -0.483</td> <td> 0.629</td> <td>   -1.706</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vanilla</th>         <td>    0.0380</td> <td>    0.209</td> <td>    0.182</td> <td> 0.856</td> <td>   -0.372</td> <td>    0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velvety</th>         <td>   -0.1540</td> <td>    0.143</td> <td>   -1.074</td> <td> 0.283</td> <td>   -0.435</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>verbena</th>         <td>    0.2881</td> <td>    0.210</td> <td>    1.369</td> <td> 0.171</td> <td>   -0.124</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vibrant</th>         <td>    0.4685</td> <td>    0.210</td> <td>    2.228</td> <td> 0.026</td> <td>    0.056</td> <td>    0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vibrantly</th>       <td>    0.3980</td> <td>    0.239</td> <td>    1.666</td> <td> 0.096</td> <td>   -0.070</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>violet</th>          <td>    0.3649</td> <td>    0.237</td> <td>    1.539</td> <td> 0.124</td> <td>   -0.100</td> <td>    0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>viscous</th>         <td>    0.3337</td> <td>    0.165</td> <td>    2.025</td> <td> 0.043</td> <td>    0.011</td> <td>    0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vivacious</th>       <td>    0.4175</td> <td>    0.294</td> <td>    1.421</td> <td> 0.155</td> <td>   -0.158</td> <td>    0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volume</th>          <td>   -0.3009</td> <td>    1.033</td> <td>   -0.291</td> <td> 0.771</td> <td>   -2.326</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>walnut</th>          <td>    0.2629</td> <td>    0.228</td> <td>    1.154</td> <td> 0.249</td> <td>   -0.184</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>water</th>           <td>   -0.9964</td> <td>    0.566</td> <td>   -1.760</td> <td> 0.079</td> <td>   -2.107</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>watermelon</th>      <td>    0.3648</td> <td>    0.365</td> <td>    1.000</td> <td> 0.317</td> <td>   -0.350</td> <td>    1.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>way</th>             <td>    1.0337</td> <td>    0.390</td> <td>    2.651</td> <td> 0.008</td> <td>    0.269</td> <td>    1.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wendy</th>           <td>    0.8480</td> <td>    0.599</td> <td>    1.415</td> <td> 0.157</td> <td>   -0.327</td> <td>    2.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>whisky</th>          <td>    0.5334</td> <td>    0.463</td> <td>    1.153</td> <td> 0.249</td> <td>   -0.373</td> <td>    1.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>           <td>    0.2750</td> <td>    0.291</td> <td>    0.944</td> <td> 0.345</td> <td>   -0.296</td> <td>    0.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wild</th>            <td>    0.1417</td> <td>    0.290</td> <td>    0.489</td> <td> 0.625</td> <td>   -0.426</td> <td>    0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>willem</th>          <td>   -0.2038</td> <td>    0.479</td> <td>   -0.425</td> <td> 0.671</td> <td>   -1.143</td> <td>    0.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wine</th>            <td>    1.5786</td> <td>    0.240</td> <td>    6.588</td> <td> 0.000</td> <td>    1.109</td> <td>    2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>winey</th>           <td>    0.1379</td> <td>    0.426</td> <td>    0.324</td> <td> 0.746</td> <td>   -0.697</td> <td>    0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>winy</th>            <td>    1.1590</td> <td>    0.335</td> <td>    3.461</td> <td> 0.001</td> <td>    0.503</td> <td>    1.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wisteria</th>        <td>    0.4820</td> <td>    0.249</td> <td>    1.936</td> <td> 0.053</td> <td>   -0.006</td> <td>    0.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wood</th>            <td>    0.2504</td> <td>    0.263</td> <td>    0.950</td> <td> 0.342</td> <td>   -0.266</td> <td>    0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>woody</th>           <td>   -1.2461</td> <td>    0.338</td> <td>   -3.683</td> <td> 0.000</td> <td>   -1.909</td> <td>   -0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zest</th>            <td>    0.0124</td> <td>    0.139</td> <td>    0.090</td> <td> 0.929</td> <td>   -0.260</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zesty</th>           <td>    0.0050</td> <td>    0.280</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.544</td> <td>    0.554</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>701.284</td> <th>  Durbin-Watson:     </th> <td>   1.977</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>14313.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.062</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.049</td>  <th>  Cond. No.          </th> <td>    290.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          overall_score   R-squared:                       0.943\n",
       "Model:                            OLS   Adj. R-squared:                  0.933\n",
       "Method:                 Least Squares   F-statistic:                     93.19\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        16:24:46   Log-Likelihood:                -5852.1\n",
       "No. Observations:                4194   AIC:                         1.297e+04\n",
       "Df Residuals:                    3563   BIC:                         1.697e+04\n",
       "Df Model:                         630                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              65.4234      0.407    160.702      0.000      64.625      66.222\n",
       "month               0.0990      0.060      1.654      0.098      -0.018       0.216\n",
       "year               -0.1549      0.263     -0.590      0.555      -0.670       0.360\n",
       "bean_agtron        -1.2737      0.361     -3.525      0.000      -1.982      -0.565\n",
       "ground_agtron       1.6821      0.298      5.639      0.000       1.097       2.267\n",
       "aroma               8.7087      0.279     31.232      0.000       8.162       9.255\n",
       "acidity             5.0138      0.351     14.286      0.000       4.326       5.702\n",
       "body                4.3515      0.220     19.745      0.000       3.919       4.784\n",
       "flavor              5.8711      0.418     14.057      0.000       5.052       6.690\n",
       "aftertaste          6.1386      0.334     18.382      0.000       5.484       6.793\n",
       "roaster_lat         0.5999      0.247      2.430      0.015       0.116       1.084\n",
       "roaster_lon         0.1462      0.091      1.607      0.108      -0.032       0.325\n",
       "origin_lat         -0.6565      0.165     -3.974      0.000      -0.980      -0.333\n",
       "origin_lon         -0.0785      0.089     -0.884      0.377      -0.252       0.095\n",
       "acid               -0.5576      0.580     -0.961      0.336      -1.695       0.580\n",
       "acidity.1          -0.2319      0.154     -1.503      0.133      -0.534       0.071\n",
       "acidy               1.2276      0.226      5.422      0.000       0.784       1.672\n",
       "admired             0.5630      0.409      1.376      0.169      -0.239       1.365\n",
       "aftertaste.1        0.5086      0.277      1.839      0.066      -0.034       1.051\n",
       "agave               0.3993      0.633      0.630      0.528      -0.843       1.641\n",
       "aged               -0.2333      0.504     -0.463      0.643      -1.221       0.755\n",
       "agreeable          -0.3362      0.411     -0.818      0.413      -1.142       0.470\n",
       "agreeably           0.6268      0.353      1.775      0.076      -0.066       1.319\n",
       "alive               0.4844      0.348      1.390      0.165      -0.199       1.168\n",
       "almond              0.2447      0.153      1.596      0.111      -0.056       0.545\n",
       "amber               0.4064      0.326      1.246      0.213      -0.233       1.046\n",
       "amplified           0.0657      0.312      0.211      0.833      -0.546       0.678\n",
       "anise               0.4332      0.439      0.987      0.324      -0.427       1.294\n",
       "apple               0.6837      0.214      3.198      0.001       0.265       1.103\n",
       "apricot             0.3363      0.144      2.328      0.020       0.053       0.620\n",
       "aromatic            0.0120      0.216      0.056      0.956      -0.411       0.435\n",
       "aromatically        0.7165      0.349      2.051      0.040       0.032       1.402\n",
       "aromatics          -0.0641      0.231     -0.278      0.781      -0.517       0.389\n",
       "astringency        -0.3130      0.229     -1.368      0.171      -0.762       0.136\n",
       "astringent         -0.5952      0.211     -2.815      0.005      -1.010      -0.181\n",
       "attractive         -0.6140      0.303     -2.025      0.043      -1.208      -0.020\n",
       "authority           0.3561      0.314      1.135      0.256      -0.259       0.971\n",
       "b60                 0.7348      0.699      1.051      0.293      -0.636       2.106\n",
       "b70                -0.2954      0.930     -0.318      0.751      -2.118       1.527\n",
       "backgrounded       -0.1173      0.204     -0.575      0.565      -0.517       0.282\n",
       "baker              -0.1056      0.189     -0.560      0.576      -0.475       0.264\n",
       "baking              0.2415      0.214      1.127      0.260      -0.179       0.662\n",
       "balance             0.6366      0.238      2.672      0.008       0.169       1.104\n",
       "balanced            0.2262      0.105      2.146      0.032       0.020       0.433\n",
       "balancing           0.3344      0.367      0.911      0.363      -0.386       1.054\n",
       "banana              0.1291      0.260      0.497      0.619      -0.380       0.639\n",
       "barrel             -0.1806      0.321     -0.563      0.573      -0.810       0.448\n",
       "bay                -0.6429      0.587     -1.096      0.273      -1.793       0.507\n",
       "bean                0.0773      0.397      0.195      0.845      -0.700       0.855\n",
       "bergamot            0.5193      0.262      1.985      0.047       0.006       1.032\n",
       "berries             0.6369      0.319      1.996      0.046       0.011       1.263\n",
       "berry               1.1736      0.185      6.346      0.000       0.811       1.536\n",
       "best                1.4252      0.447      3.188      0.001       0.549       2.302\n",
       "big                 0.3047      0.250      1.217      0.224      -0.186       0.796\n",
       "bing                0.2843      0.398      0.715      0.475      -0.495       1.064\n",
       "bit                -0.3650      0.244     -1.498      0.134      -0.843       0.113\n",
       "bitter             -1.4749      0.375     -3.938      0.000      -2.209      -0.741\n",
       "bitterish          -0.6420      0.452     -1.420      0.156      -1.528       0.244\n",
       "bitterness          0.7163      0.383      1.870      0.062      -0.035       1.467\n",
       "bittersweet        -0.1348      0.158     -0.854      0.393      -0.444       0.175\n",
       "black               0.3972      0.188      2.115      0.035       0.029       0.765\n",
       "blackberry          0.2717      0.215      1.266      0.206      -0.149       0.693\n",
       "blend              -0.3347      0.288     -1.160      0.246      -0.900       0.231\n",
       "blood               0.0850      0.238      0.357      0.721      -0.382       0.552\n",
       "bloom               0.1320      0.360      0.367      0.714      -0.573       0.837\n",
       "blooming            0.0798      0.264      0.302      0.763      -0.438       0.598\n",
       "blooms              1.4819      0.444      3.334      0.001       0.611       2.353\n",
       "blossom             0.0889      0.233      0.382      0.703      -0.368       0.545\n",
       "blueberry           0.4626      0.212      2.186      0.029       0.048       0.877\n",
       "bodied              0.8341      0.237      3.514      0.000       0.369       1.300\n",
       "body.1              0.1124      0.182      0.618      0.537      -0.244       0.469\n",
       "brandy              0.4870      0.275      1.771      0.077      -0.052       1.026\n",
       "brazil              0.3351      0.423      0.792      0.428      -0.494       1.164\n",
       "brewed              0.0293      0.722      0.041      0.968      -1.387       1.446\n",
       "brewer              1.0069      0.939      1.073      0.284      -0.834       2.847\n",
       "brewing             0.0094      1.062      0.009      0.993      -2.074       2.092\n",
       "bright              0.3768      0.137      2.761      0.006       0.109       0.644\n",
       "brightly            0.1126      0.218      0.517      0.605      -0.314       0.539\n",
       "brightness         -0.2129      0.464     -0.459      0.647      -1.123       0.697\n",
       "brisk              -0.0625      0.156     -0.399      0.690      -0.369       0.244\n",
       "briskly             0.2116      0.320      0.660      0.509      -0.417       0.840\n",
       "brittle             0.5067      0.260      1.951      0.051      -0.002       1.016\n",
       "brown               1.2040      0.699      1.723      0.085      -0.166       2.574\n",
       "buoyant             0.0678      0.135      0.501      0.616      -0.198       0.333\n",
       "buoyantly           0.4608      0.342      1.347      0.178      -0.210       1.132\n",
       "burned             -0.6700      0.366     -1.831      0.067      -1.387       0.047\n",
       "butter              0.3722      0.158      2.352      0.019       0.062       0.682\n",
       "butterscotch        0.7473      0.249      3.004      0.003       0.260       1.235\n",
       "buttery             0.3204      0.228      1.405      0.160      -0.127       0.768\n",
       "byron               1.7443      0.570      3.059      0.002       0.626       2.862\n",
       "cacao               0.2333      0.216      1.082      0.279      -0.189       0.656\n",
       "called             -0.9198      0.409     -2.248      0.025      -1.722      -0.118\n",
       "candied             0.4412      0.225      1.960      0.050   -7.41e-05       0.883\n",
       "candy               0.6059      0.411      1.474      0.141      -0.200       1.412\n",
       "cane                0.6055      0.700      0.865      0.387      -0.767       1.978\n",
       "cappuccino          0.5358      0.561      0.954      0.340      -0.565       1.636\n",
       "capsule            -1.4669      1.156     -1.269      0.205      -3.733       0.800\n",
       "caramel             0.3637      0.181      2.012      0.044       0.009       0.718\n",
       "caramelly           0.6595      0.274      2.409      0.016       0.123       1.196\n",
       "carbon             -1.1016      0.455     -2.419      0.016      -1.995      -0.209\n",
       "cardamom            0.1037      0.451      0.230      0.818      -0.780       0.987\n",
       "carob               0.3286      0.391      0.841      0.401      -0.438       1.095\n",
       "carried            -0.3843      0.374     -1.027      0.304      -1.118       0.349\n",
       "carries             0.2158      0.175      1.233      0.218      -0.127       0.559\n",
       "carry               0.0799      0.129      0.618      0.537      -0.174       0.334\n",
       "carrying           -0.0271      0.307     -0.088      0.930      -0.629       0.575\n",
       "cashew              0.2880      0.201      1.434      0.152      -0.106       0.682\n",
       "cedar               0.2356      0.117      2.020      0.043       0.007       0.464\n",
       "cedary              0.3418      0.269      1.270      0.204      -0.186       0.870\n",
       "center              0.4055      0.398      1.019      0.308      -0.375       1.185\n",
       "centered           -0.0436      0.198     -0.220      0.826      -0.433       0.346\n",
       "centers            -0.0097      0.128     -0.076      0.939      -0.261       0.241\n",
       "character           0.2321      0.226      1.028      0.304      -0.210       0.675\n",
       "charred             0.1236      0.357      0.346      0.729      -0.577       0.824\n",
       "cherry              0.5093      0.162      3.151      0.002       0.192       0.826\n",
       "cherryish           1.0127      0.248      4.080      0.000       0.526       1.499\n",
       "chocolate           0.5726      0.125      4.565      0.000       0.327       0.819\n",
       "chocolaty           0.4168      0.169      2.462      0.014       0.085       0.749\n",
       "cinnamon            0.5553      0.241      2.306      0.021       0.083       1.027\n",
       "cited              -0.3593      0.491     -0.732      0.464      -1.321       0.602\n",
       "citrus              0.2562      0.171      1.498      0.134      -0.079       0.591\n",
       "citrusy             0.1491      0.231      0.645      0.519      -0.304       0.603\n",
       "classic             0.9703      0.324      2.991      0.003       0.334       1.606\n",
       "clean               0.8857      0.199      4.449      0.000       0.495       1.276\n",
       "cleanly             0.2428      0.185      1.315      0.189      -0.119       0.605\n",
       "clear               0.3539      0.349      1.014      0.311      -0.330       1.038\n",
       "clove               0.4161      0.278      1.499      0.134      -0.128       0.960\n",
       "cocoa               0.7480      0.159      4.704      0.000       0.436       1.060\n",
       "cocoaish            0.1194      0.230      0.518      0.604      -0.332       0.571\n",
       "coconut             0.7503      0.269      2.789      0.005       0.223       1.278\n",
       "coffee              0.0670      0.198      0.338      0.735      -0.322       0.456\n",
       "coffees             0.7512      0.379      1.981      0.048       0.008       1.495\n",
       "cold                1.2898      0.687      1.877      0.061      -0.057       2.637\n",
       "complete            0.4530      0.241      1.877      0.061      -0.020       0.926\n",
       "complex             0.4363      0.104      4.184      0.000       0.232       0.641\n",
       "complexity          0.9136      0.234      3.897      0.000       0.454       1.373\n",
       "complexly           0.2302      0.217      1.060      0.289      -0.195       0.656\n",
       "complicate          0.0598      0.356      0.168      0.867      -0.638       0.758\n",
       "complicated        -0.2081      0.164     -1.271      0.204      -0.529       0.113\n",
       "complicates         0.8059      0.330      2.441      0.015       0.158       1.453\n",
       "complicating        0.2048      0.313      0.655      0.513      -0.408       0.818\n",
       "complication       -0.1532      0.267     -0.573      0.567      -0.677       0.371\n",
       "complications      -0.1966      0.302     -0.652      0.515      -0.788       0.395\n",
       "concord             0.6140      0.421      1.458      0.145      -0.212       1.440\n",
       "consolidates        0.0527      0.105      0.504      0.614      -0.152       0.258\n",
       "consolidating      -0.1281      0.319     -0.402      0.688      -0.754       0.497\n",
       "continued           0.1901      0.159      1.192      0.233      -0.123       0.503\n",
       "continuing         -0.3295      0.222     -1.487      0.137      -0.764       0.105\n",
       "cools              -0.3730      0.223     -1.676      0.094      -0.809       0.063\n",
       "creamy             -0.0316      0.153     -0.207      0.836      -0.331       0.268\n",
       "crisp               0.3751      0.108      3.463      0.001       0.163       0.587\n",
       "crisply             0.7626      0.243      3.135      0.002       0.286       1.240\n",
       "cupper              0.3957      0.337      1.176      0.240      -0.264       1.056\n",
       "cupping             0.6082      0.344      1.767      0.077      -0.066       1.283\n",
       "cups               -2.1897      0.493     -4.438      0.000      -3.157      -1.222\n",
       "currant             0.3675      0.203      1.809      0.071      -0.031       0.766\n",
       "cut                 0.0528      0.211      0.250      0.803      -0.362       0.467\n",
       "dark                0.0264      0.128      0.207      0.836      -0.224       0.276\n",
       "date                0.6587      0.188      3.495      0.000       0.289       1.028\n",
       "deep                0.3174      0.133      2.379      0.017       0.056       0.579\n",
       "deepen             -0.2034      0.296     -0.687      0.492      -0.784       0.377\n",
       "deepening           1.0644      0.309      3.443      0.001       0.458       1.671\n",
       "deepens             1.0057      0.334      3.013      0.003       0.351       1.660\n",
       "deeply              0.3527      0.133      2.659      0.008       0.093       0.613\n",
       "delicate            0.4190      0.167      2.502      0.012       0.091       0.747\n",
       "delicately          0.2512      0.154      1.634      0.102      -0.050       0.553\n",
       "depth               0.2959      0.362      0.817      0.414      -0.414       1.006\n",
       "described           0.3180      0.506      0.628      0.530      -0.674       1.310\n",
       "device              0.0558      1.438      0.039      0.969      -2.763       2.874\n",
       "dimension          -1.2144      0.280     -4.343      0.000      -1.763      -0.666\n",
       "dimensioned         1.0323      0.387      2.671      0.008       0.275       1.790\n",
       "displayed           0.3927      0.449      0.874      0.382      -0.488       1.274\n",
       "displays            0.1814      0.323      0.561      0.575      -0.453       0.816\n",
       "distinct            0.3327      0.224      1.485      0.138      -0.107       0.772\n",
       "distinctive         0.5034      0.388      1.298      0.194      -0.257       1.264\n",
       "distinctly         -0.1672      0.245     -0.684      0.494      -0.647       0.312\n",
       "dominate            0.0262      0.184      0.142      0.887      -0.334       0.387\n",
       "dominated          -0.5164      0.219     -2.362      0.018      -0.945      -0.088\n",
       "dominates           0.0451      0.204      0.221      0.825      -0.354       0.445\n",
       "dominating          0.1279      0.359      0.356      0.722      -0.576       0.832\n",
       "dried               0.2410      0.152      1.588      0.112      -0.057       0.538\n",
       "drink               0.2971      0.703      0.422      0.673      -1.082       1.676\n",
       "driven              0.1544      0.259      0.597      0.551      -0.353       0.662\n",
       "dry                -0.1590      0.147     -1.085      0.278      -0.447       0.128\n",
       "drying             -0.3129      0.131     -2.382      0.017      -0.570      -0.055\n",
       "dusk                0.2131      0.348      0.612      0.540      -0.469       0.895\n",
       "earth               0.5620      0.302      1.859      0.063      -0.031       1.155\n",
       "earthy              0.1387      0.328      0.423      0.673      -0.505       0.782\n",
       "edge                0.4164      0.219      1.903      0.057      -0.013       0.845\n",
       "edged               0.1679      0.342      0.491      0.623      -0.502       0.838\n",
       "effervescent        0.3038      0.354      0.859      0.391      -0.390       0.998\n",
       "elegant             0.5923      0.247      2.396      0.017       0.108       1.077\n",
       "elegantly           0.7455      0.239      3.122      0.002       0.277       1.214\n",
       "emerge              0.5664      0.350      1.618      0.106      -0.120       1.253\n",
       "emerges             0.2440      0.288      0.847      0.397      -0.321       0.809\n",
       "engaging            0.1689      0.291      0.581      0.562      -0.402       0.739\n",
       "enveloped           0.4742      0.291      1.630      0.103      -0.096       1.044\n",
       "enveloping          0.3838      0.340      1.127      0.260      -0.284       1.051\n",
       "especially          1.0488      0.436      2.404      0.016       0.193       1.904\n",
       "espresso            0.4950      0.430      1.152      0.250      -0.348       1.338\n",
       "ethan               1.0449      0.597      1.749      0.080      -0.126       2.216\n",
       "evaluated          -0.0297      0.286     -0.104      0.917      -0.591       0.532\n",
       "excellent           0.4174      0.310      1.347      0.178      -0.190       1.025\n",
       "exhilarating        0.1057      0.339      0.312      0.755      -0.558       0.769\n",
       "exhilaratingly      0.7902      0.418      1.889      0.059      -0.030       1.610\n",
       "exotic              0.4926      0.310      1.588      0.112      -0.116       1.101\n",
       "explicit            0.9583      0.372      2.574      0.010       0.228       1.688\n",
       "expressed           0.2489      0.257      0.969      0.333      -0.255       0.752\n",
       "fade                0.3184      0.280      1.135      0.256      -0.231       0.868\n",
       "fades              -0.1337      0.225     -0.593      0.553      -0.575       0.308\n",
       "fading              0.0500      0.401      0.125      0.901      -0.736       0.836\n",
       "faint              -1.2791      0.290     -4.411      0.000      -1.848      -0.710\n",
       "faintly             0.0751      0.525      0.143      0.886      -0.954       1.104\n",
       "fallen             -0.7233      0.486     -1.487      0.137      -1.677       0.230\n",
       "far                 0.0943      0.270      0.349      0.727      -0.435       0.624\n",
       "felt                0.3061      0.480      0.638      0.523      -0.634       1.246\n",
       "ferment            -0.8534      0.312     -2.736      0.006      -1.465      -0.242\n",
       "fermented          -0.2066      0.354     -0.584      0.559      -0.900       0.487\n",
       "fermenty            0.3884      0.379      1.026      0.305      -0.354       1.131\n",
       "fig                 0.7245      0.345      2.098      0.036       0.047       1.402\n",
       "fine                0.5534      0.243      2.280      0.023       0.078       1.029\n",
       "fir                 0.0346      0.192      0.180      0.857      -0.342       0.412\n",
       "flat               -2.6054      0.434     -6.009      0.000      -3.455      -1.755\n",
       "flavor.1           -0.2849      0.147     -1.943      0.052      -0.572       0.003\n",
       "flavors            -0.1804      0.276     -0.655      0.513      -0.721       0.360\n",
       "floral              0.6221      0.123      5.072      0.000       0.382       0.863\n",
       "florals             0.0317      0.172      0.185      0.853      -0.305       0.368\n",
       "flower              1.5822      0.344      4.606      0.000       0.909       2.256\n",
       "flowering           1.1223      0.789      1.423      0.155      -0.424       2.668\n",
       "flowers             0.5239      0.120      4.354      0.000       0.288       0.760\n",
       "followed           -0.1444      0.334     -0.432      0.665      -0.799       0.510\n",
       "forward            -0.1316      0.204     -0.644      0.520      -0.532       0.269\n",
       "fragrant            1.0566      0.346      3.055      0.002       0.378       1.735\n",
       "framed             -0.1441      0.291     -0.496      0.620      -0.714       0.426\n",
       "frankincense        0.4244      0.258      1.648      0.099      -0.081       0.929\n",
       "freesia             0.3285      0.197      1.669      0.095      -0.057       0.715\n",
       "fresh               0.1009      0.241      0.419      0.675      -0.371       0.573\n",
       "freshly            -0.0470      0.362     -0.130      0.897      -0.757       0.663\n",
       "fruit               0.5607      0.148      3.789      0.000       0.271       0.851\n",
       "fruity              0.2023      0.245      0.824      0.410      -0.279       0.684\n",
       "fudge               0.4613      0.237      1.943      0.052      -0.004       0.927\n",
       "gardenia            0.3074      0.238      1.289      0.197      -0.160       0.775\n",
       "gentle              0.2663      0.174      1.531      0.126      -0.075       0.607\n",
       "gently              0.3387      0.136      2.489      0.013       0.072       0.605\n",
       "ginger              0.1469      0.302      0.486      0.627      -0.446       0.740\n",
       "goji                0.1246      0.462      0.270      0.787      -0.781       1.031\n",
       "good               -0.0898      0.292     -0.308      0.758      -0.662       0.482\n",
       "grace              -1.0529      0.362     -2.909      0.004      -1.763      -0.343\n",
       "grape               0.4194      0.256      1.637      0.102      -0.083       0.922\n",
       "grapefruit          0.6447      0.188      3.428      0.001       0.276       1.013\n",
       "grappa              0.7922      0.404      1.960      0.050      -0.000       1.585\n",
       "grass              -0.4223      0.829     -0.509      0.610      -2.048       1.203\n",
       "great               0.5294      0.348      1.522      0.128      -0.152       1.211\n",
       "green               0.3106      0.291      1.068      0.285      -0.259       0.881\n",
       "guava               0.4195      0.241      1.744      0.081      -0.052       0.891\n",
       "hard               -3.6369      0.417     -8.722      0.000      -4.454      -2.819\n",
       "harmonious          0.0679      0.335      0.203      0.839      -0.588       0.724\n",
       "hazelnut            0.3668      0.147      2.493      0.013       0.078       0.655\n",
       "heavy              -0.2766      0.295     -0.937      0.349      -0.855       0.302\n",
       "herb                0.9771      0.302      3.240      0.001       0.386       1.568\n",
       "herbaceous          0.1150      0.250      0.461      0.645      -0.374       0.604\n",
       "herbal              0.4765      0.442      1.077      0.281      -0.391       1.344\n",
       "herbs               0.2475      0.317      0.780      0.435      -0.375       0.870\n",
       "herby               0.4905      0.360      1.363      0.173      -0.215       1.196\n",
       "hibiscus            0.1236      0.308      0.401      0.688      -0.481       0.728\n",
       "high                0.6296      0.164      3.834      0.000       0.308       0.952\n",
       "hint               -0.0992      0.189     -0.524      0.600      -0.470       0.272\n",
       "hints               0.0529      0.171      0.309      0.757      -0.283       0.389\n",
       "honey               0.6025      0.136      4.441      0.000       0.337       0.868\n",
       "honeyish            0.3963      0.358      1.108      0.268      -0.305       1.098\n",
       "honeysuckle         0.4695      0.215      2.179      0.029       0.047       0.892\n",
       "hop                 0.2209      0.270      0.817      0.414      -0.309       0.751\n",
       "hot                -0.4106      0.397     -1.035      0.301      -1.188       0.367\n",
       "impression          0.9435      0.375      2.516      0.012       0.208       1.679\n",
       "impressive          0.1392      0.203      0.684      0.494      -0.260       0.538\n",
       "impressively        0.2740      0.262      1.045      0.296      -0.240       0.788\n",
       "influenced          0.5288      0.404      1.310      0.190      -0.263       1.320\n",
       "integrated          0.6842      0.303      2.261      0.024       0.091       1.278\n",
       "intense             0.3847      0.219      1.757      0.079      -0.045       0.814\n",
       "intensely           0.0791      0.357      0.222      0.825      -0.621       0.779\n",
       "intensity          -0.1755      0.404     -0.434      0.664      -0.968       0.617\n",
       "interesting        -0.9121      0.356     -2.563      0.010      -1.610      -0.214\n",
       "intricate           0.3152      0.178      1.772      0.076      -0.034       0.664\n",
       "intricately         0.2246      0.244      0.919      0.358      -0.254       0.704\n",
       "intriguing          0.1726      0.422      0.409      0.683      -0.655       1.000\n",
       "jam                 0.4664      0.427      1.092      0.275      -0.371       1.304\n",
       "jasmine             0.6034      0.206      2.922      0.003       0.199       1.008\n",
       "juicy               0.2475      0.138      1.787      0.074      -0.024       0.519\n",
       "juniper             0.2895      0.436      0.665      0.506      -0.565       1.144\n",
       "just               -0.3254      0.362     -0.899      0.369      -1.035       0.385\n",
       "ken                -0.6055      0.384     -1.575      0.115      -1.359       0.148\n",
       "kenya               2.2910      0.449      5.098      0.000       1.410       3.172\n",
       "keurig              1.2595      0.760      1.657      0.098      -0.231       2.750\n",
       "key                -0.7433      0.358     -2.076      0.038      -1.445      -0.041\n",
       "laden               0.3542      0.258      1.372      0.170      -0.152       0.860\n",
       "lasting             0.5293      0.330      1.604      0.109      -0.118       1.176\n",
       "lavender            0.3571      0.178      2.006      0.045       0.008       0.706\n",
       "layered             0.0435      0.204      0.213      0.831      -0.356       0.443\n",
       "lead               -0.0111      0.253     -0.044      0.965      -0.507       0.485\n",
       "leads               0.0492      0.171      0.287      0.774      -0.287       0.385\n",
       "leaf                1.1526      0.489      2.355      0.019       0.193       2.112\n",
       "lean               -1.1793      0.303     -3.894      0.000      -1.773      -0.586\n",
       "leaning             0.3809      0.210      1.813      0.070      -0.031       0.793\n",
       "leanish            -1.1019      0.325     -3.391      0.001      -1.739      -0.465\n",
       "leather             0.2356      0.278      0.849      0.396      -0.309       0.780\n",
       "leaves              1.2911      0.433      2.983      0.003       0.442       2.140\n",
       "lemon               0.3826      0.162      2.367      0.018       0.066       0.700\n",
       "lemony              0.3911      0.268      1.459      0.145      -0.134       0.917\n",
       "light              -0.1102      0.165     -0.668      0.504      -0.434       0.213\n",
       "lightly            -0.2770      0.151     -1.840      0.066      -0.572       0.018\n",
       "like               -0.3350      0.131     -2.553      0.011      -0.592      -0.078\n",
       "liked               0.0420      0.392      0.107      0.915      -0.727       0.811\n",
       "lilac               0.3400      0.196      1.735      0.083      -0.044       0.724\n",
       "lily                0.3070      0.179      1.715      0.086      -0.044       0.658\n",
       "lime                0.7220      0.250      2.887      0.004       0.232       1.212\n",
       "limited             0.1630      0.543      0.300      0.764      -0.901       1.227\n",
       "linger              0.2980      0.265      1.127      0.260      -0.221       0.817\n",
       "lingering           0.1332      0.202      0.658      0.510      -0.263       0.530\n",
       "lingers             0.5825      0.254      2.289      0.022       0.084       1.082\n",
       "little             -0.0157      0.244     -0.065      0.949      -0.494       0.462\n",
       "lively             -0.0996      0.156     -0.637      0.524      -0.406       0.207\n",
       "long                0.5870      0.130      4.514      0.000       0.332       0.842\n",
       "lovely             -0.4870      0.381     -1.278      0.201      -1.234       0.260\n",
       "low                 0.8532      0.220      3.870      0.000       0.421       1.285\n",
       "lush                0.3388      0.160      2.120      0.034       0.025       0.652\n",
       "lushly              0.5999      0.230      2.605      0.009       0.148       1.051\n",
       "lychee              0.7091      0.272      2.611      0.009       0.177       1.241\n",
       "lyric               0.9682      0.341      2.840      0.005       0.300       1.637\n",
       "lyrically           0.9467      0.307      3.088      0.002       0.346       1.548\n",
       "macadamia           0.2220      0.473      0.469      0.639      -0.706       1.150\n",
       "magnolia            0.3334      0.173      1.930      0.054      -0.005       0.672\n",
       "maintains           0.0648      0.300      0.216      0.829      -0.523       0.653\n",
       "malt               -0.0923      0.444     -0.208      0.835      -0.963       0.778\n",
       "malty               1.9427      0.386      5.039      0.000       1.187       2.699\n",
       "mango               0.4305      0.212      2.028      0.043       0.014       0.847\n",
       "maple               0.4485      0.701      0.640      0.522      -0.926       1.823\n",
       "marjoram            0.4390      0.238      1.844      0.065      -0.028       0.906\n",
       "medium              0.4806      0.173      2.778      0.006       0.141       0.820\n",
       "melon               0.5800      0.347      1.673      0.094      -0.100       1.260\n",
       "mesquite            0.3670      0.380      0.965      0.335      -0.379       1.113\n",
       "meyer               0.4000      0.324      1.235      0.217      -0.235       1.035\n",
       "mid                -0.0525      0.401     -0.131      0.896      -0.839       0.734\n",
       "miguel              1.4165      0.535      2.649      0.008       0.368       2.465\n",
       "mild                0.2018      0.272      0.743      0.458      -0.331       0.735\n",
       "mildly             -0.3632      0.205     -1.771      0.077      -0.765       0.039\n",
       "milk                0.6098      0.216      2.826      0.005       0.187       1.033\n",
       "mint                0.4797      0.279      1.718      0.086      -0.068       1.027\n",
       "minty               0.5104      0.336      1.519      0.129      -0.148       1.169\n",
       "moist               0.0958      0.331      0.290      0.772      -0.553       0.744\n",
       "molasses            0.5300      0.195      2.721      0.007       0.148       0.912\n",
       "mulberry            0.4921      0.274      1.796      0.073      -0.045       1.029\n",
       "multi               0.3313      0.240      1.383      0.167      -0.139       0.801\n",
       "mushroom            0.6579      0.316      2.082      0.037       0.038       1.277\n",
       "musk                0.1790      0.287      0.623      0.533      -0.384       0.742\n",
       "musky               0.3677      0.448      0.820      0.412      -0.511       1.246\n",
       "mustiness          -0.8241      0.428     -1.927      0.054      -1.663       0.015\n",
       "musty              -1.3749      0.380     -3.618      0.000      -2.120      -0.630\n",
       "muted               0.1078      0.223      0.484      0.629      -0.329       0.545\n",
       "myrrh               0.4817      0.266      1.811      0.070      -0.040       1.003\n",
       "narcissus           0.5444      0.177      3.071      0.002       0.197       0.892\n",
       "nectar              0.8900      0.335      2.657      0.008       0.233       1.547\n",
       "nectarine           0.3852      0.291      1.325      0.185      -0.185       0.955\n",
       "nib                 0.0014      0.170      0.008      0.993      -0.331       0.334\n",
       "nice               -2.5408      0.562     -4.518      0.000      -3.643      -1.438\n",
       "nicely             -0.3050      0.242     -1.259      0.208      -0.780       0.170\n",
       "night               0.1310      0.281      0.466      0.641      -0.420       0.682\n",
       "nominated          -0.3140      0.410     -0.765      0.444      -1.118       0.490\n",
       "nose               -0.8594      0.265     -3.248      0.001      -1.378      -0.341\n",
       "note               -0.1580      0.181     -0.874      0.382      -0.513       0.197\n",
       "notes               0.3148      0.137      2.294      0.022       0.046       0.584\n",
       "nougat              0.3772      0.236      1.599      0.110      -0.085       0.840\n",
       "nuance             -0.0681      0.238     -0.286      0.775      -0.535       0.398\n",
       "nuanced             0.2940      0.200      1.474      0.141      -0.097       0.685\n",
       "nut                 0.1173      0.131      0.896      0.370      -0.139       0.374\n",
       "nutella             0.9562      0.394      2.426      0.015       0.183       1.729\n",
       "nutmeg              0.7075      0.353      2.005      0.045       0.016       1.399\n",
       "nuts               -1.3967      0.426     -3.278      0.001      -2.232      -0.561\n",
       "nutty               0.1719      0.241      0.712      0.476      -0.301       0.645\n",
       "oak                 0.3107      0.167      1.862      0.063      -0.016       0.638\n",
       "opulent             0.2880      0.279      1.033      0.302      -0.259       0.835\n",
       "opulently           0.0963      0.378      0.255      0.799      -0.644       0.837\n",
       "orange              0.8932      0.166      5.393      0.000       0.568       1.218\n",
       "orangy              0.2584      0.242      1.068      0.286      -0.216       0.733\n",
       "orchid              0.4828      0.376      1.285      0.199      -0.254       1.220\n",
       "original            0.0337      0.252      0.134      0.894      -0.461       0.528\n",
       "ounce               0.3367      1.238      0.272      0.786      -2.090       2.764\n",
       "ounces             -0.3915      0.858     -0.456      0.648      -2.074       1.291\n",
       "owing               0.3272      0.484      0.676      0.499      -0.622       1.276\n",
       "panelists          -0.2913      0.502     -0.580      0.562      -1.276       0.693\n",
       "papaya              0.2452      0.333      0.737      0.461      -0.407       0.898\n",
       "particular         -0.0055      0.194     -0.028      0.978      -0.386       0.375\n",
       "particularly        0.0040      0.263      0.015      0.988      -0.511       0.519\n",
       "parts               0.2197      0.322      0.682      0.496      -0.412       0.852\n",
       "passion             0.2080      0.346      0.601      0.548      -0.470       0.886\n",
       "passionfruit        0.7130      0.447      1.596      0.111      -0.163       1.589\n",
       "peach               0.5126      0.167      3.068      0.002       0.185       0.840\n",
       "pear                0.5879      0.198      2.962      0.003       0.199       0.977\n",
       "pecan              -0.0139      0.331     -0.042      0.967      -0.663       0.636\n",
       "peel                0.7025      0.550      1.277      0.202      -0.376       1.781\n",
       "peppercorn          0.5076      0.258      1.969      0.049       0.002       1.013\n",
       "perfectly           0.2675      0.383      0.698      0.485      -0.484       1.019\n",
       "persimmon           0.8104      0.278      2.911      0.004       0.265       1.356\n",
       "persist             0.1784      0.226      0.789      0.430      -0.265       0.622\n",
       "persistence         0.8437      0.377      2.240      0.025       0.105       1.582\n",
       "persistent          0.7215      0.320      2.253      0.024       0.094       1.349\n",
       "persists            0.1141      0.182      0.627      0.531      -0.243       0.471\n",
       "pert                0.0640      0.235      0.272      0.785      -0.397       0.525\n",
       "pie                 0.8611      0.359      2.396      0.017       0.157       1.566\n",
       "pine                0.7234      0.363      1.993      0.046       0.012       1.435\n",
       "pineapple           0.4833      0.244      1.979      0.048       0.004       0.962\n",
       "pink                0.0863      0.226      0.382      0.703      -0.357       0.530\n",
       "pipe                0.1987      0.384      0.518      0.605      -0.554       0.951\n",
       "pistachio           0.3227      0.267      1.207      0.228      -0.202       0.847\n",
       "platinum            0.3861      0.875      0.441      0.659      -1.330       2.102\n",
       "pleasant            0.6169      0.352      1.752      0.080      -0.073       1.307\n",
       "pleasantly          0.2906      0.206      1.411      0.158      -0.113       0.694\n",
       "pleasing            0.1207      0.180      0.669      0.503      -0.233       0.474\n",
       "pleasingly         -0.0444      0.240     -0.185      0.853      -0.515       0.426\n",
       "plum                0.2940      0.169      1.736      0.083      -0.038       0.626\n",
       "plumeria            0.8430      0.386      2.184      0.029       0.086       1.600\n",
       "plump               0.0599      0.201      0.298      0.766      -0.334       0.454\n",
       "plush               0.0348      0.103      0.337      0.736      -0.168       0.237\n",
       "pod                -1.6808      0.819     -2.053      0.040      -3.286      -0.076\n",
       "pomegranate         0.6051      0.223      2.712      0.007       0.168       1.043\n",
       "port                0.5198      0.464      1.121      0.262      -0.389       1.429\n",
       "powder             -0.0869      0.257     -0.338      0.735      -0.591       0.417\n",
       "power               0.7043      0.390      1.805      0.071      -0.061       1.469\n",
       "powerful            0.8498      0.335      2.540      0.011       0.194       1.506\n",
       "presence           -0.1116      0.293     -0.380      0.704      -0.687       0.464\n",
       "probably            0.8924      0.425      2.101      0.036       0.059       1.725\n",
       "produce             0.8127      0.744      1.092      0.275      -0.646       2.271\n",
       "produced            0.0909      0.594      0.153      0.878      -1.073       1.255\n",
       "profile             0.2989      0.224      1.333      0.183      -0.141       0.739\n",
       "promise             0.0711      0.315      0.226      0.821      -0.546       0.688\n",
       "pronounced          0.5608      0.271      2.067      0.039       0.029       1.093\n",
       "prune              -0.0996      0.331     -0.301      0.764      -0.748       0.549\n",
       "pruny              -1.4509      0.371     -3.909      0.000      -2.179      -0.723\n",
       "pungency           -0.2384      0.255     -0.937      0.349      -0.738       0.261\n",
       "pungent             0.2775      0.155      1.787      0.074      -0.027       0.582\n",
       "pungently           0.2094      0.241      0.868      0.385      -0.263       0.682\n",
       "pure                0.9066      0.237      3.823      0.000       0.442       1.372\n",
       "quickly             0.2194      0.395      0.556      0.578      -0.555       0.993\n",
       "quiet               0.3831      0.160      2.390      0.017       0.069       0.697\n",
       "quietly             0.4195      0.168      2.493      0.013       0.090       0.749\n",
       "quite              -0.5770      0.256     -2.258      0.024      -1.078      -0.076\n",
       "raisin              0.2369      0.209      1.131      0.258      -0.174       0.648\n",
       "raisiny             0.7766      0.375      2.071      0.038       0.041       1.512\n",
       "range               0.0990      0.242      0.409      0.682      -0.375       0.573\n",
       "raspberry           0.6292      0.217      2.895      0.004       0.203       1.055\n",
       "rating             -0.5098      0.346     -1.475      0.140      -1.187       0.168\n",
       "raw                -0.2741      0.520     -0.527      0.598      -1.293       0.745\n",
       "read                0.2281      0.283      0.806      0.420      -0.327       0.783\n",
       "reader              0.0957      0.354      0.270      0.787      -0.598       0.789\n",
       "reads              -0.0967      0.276     -0.350      0.726      -0.638       0.444\n",
       "ready               1.0860      0.964      1.126      0.260      -0.804       2.976\n",
       "red                 0.3264      0.219      1.490      0.136      -0.103       0.756\n",
       "redolent            0.2441      0.305      0.799      0.424      -0.355       0.843\n",
       "redwood             0.6364      0.486      1.310      0.190      -0.316       1.589\n",
       "refreshing          0.4796      0.358      1.338      0.181      -0.223       1.182\n",
       "relatively         -0.0272      0.338     -0.080      0.936      -0.690       0.636\n",
       "remains            -0.1365      0.287     -0.475      0.635      -0.699       0.427\n",
       "resonance          -0.1685      0.352     -0.479      0.632      -0.858       0.521\n",
       "resonant            0.2293      0.110      2.091      0.037       0.014       0.444\n",
       "resonantly          0.4106      0.308      1.333      0.183      -0.193       1.015\n",
       "resonate            0.2929      0.353      0.829      0.407      -0.400       0.985\n",
       "resonates           0.2085      0.323      0.645      0.519      -0.426       0.843\n",
       "resurface           0.2513      0.310      0.810      0.418      -0.357       0.859\n",
       "resurfacing         0.2804      0.327      0.857      0.392      -0.361       0.922\n",
       "rhododendron        0.4572      0.274      1.670      0.095      -0.079       0.994\n",
       "rich                0.4363      0.122      3.585      0.000       0.198       0.675\n",
       "richly              0.5415      0.127      4.276      0.000       0.293       0.790\n",
       "richness            0.3228      0.297      1.087      0.277      -0.259       0.905\n",
       "rings               0.2998      0.271      1.105      0.269      -0.232       0.832\n",
       "ripe                0.5420      0.162      3.344      0.001       0.224       0.860\n",
       "roast              -0.0856      0.211     -0.406      0.685      -0.499       0.327\n",
       "roasted             0.1138      0.179      0.636      0.525      -0.237       0.464\n",
       "roastiness         -0.1713      0.402     -0.426      0.670      -0.960       0.618\n",
       "roasty              0.4150      0.222      1.869      0.062      -0.020       0.850\n",
       "rose                0.4732      0.185      2.559      0.011       0.111       0.836\n",
       "rough              -0.0922      0.266     -0.347      0.729      -0.613       0.429\n",
       "round              -0.0142      0.144     -0.099      0.921      -0.296       0.267\n",
       "rounded             0.3155      0.210      1.502      0.133      -0.096       0.727\n",
       "rounding            0.0969      0.194      0.500      0.617      -0.283       0.477\n",
       "roundly             0.1960      0.166      1.181      0.238      -0.129       0.521\n",
       "rounds              0.1466      0.222      0.662      0.508      -0.288       0.581\n",
       "rum                 1.0017      0.380      2.633      0.008       0.256       1.748\n",
       "rye                 0.0581      0.507      0.114      0.909      -0.936       1.053\n",
       "sage                0.3860      0.298      1.295      0.195      -0.198       0.970\n",
       "salted             -0.4306      0.390     -1.105      0.269      -1.195       0.333\n",
       "salty               0.0006      0.298      0.002      0.998      -0.583       0.585\n",
       "sample             -1.3822      0.574     -2.409      0.016      -2.507      -0.257\n",
       "sandalwood          0.4057      0.143      2.845      0.004       0.126       0.685\n",
       "sassafras           0.5654      0.492      1.149      0.251      -0.400       1.530\n",
       "satiny             -0.1335      0.111     -1.208      0.227      -0.350       0.083\n",
       "satisfying          0.0410      0.304      0.135      0.893      -0.554       0.636\n",
       "saturated           0.5965      0.196      3.042      0.002       0.212       0.981\n",
       "saturates           0.4341      0.287      1.511      0.131      -0.129       0.997\n",
       "savory              0.0997      0.134      0.741      0.459      -0.164       0.363\n",
       "scaled             -0.1267      0.587     -0.216      0.829      -1.278       1.024\n",
       "scorched           -0.1017      0.223     -0.457      0.648      -0.538       0.335\n",
       "semi                0.3569      0.253      1.408      0.159      -0.140       0.854\n",
       "sensation           0.4374      0.294      1.488      0.137      -0.139       1.014\n",
       "serve               1.3079      1.333      0.981      0.327      -1.306       3.921\n",
       "serving             0.2872      0.961      0.299      0.765      -1.597       2.172\n",
       "shadow             -2.9243      0.516     -5.668      0.000      -3.936      -1.913\n",
       "shallow            -0.5068      0.410     -1.237      0.216      -1.310       0.297\n",
       "sharp              -1.8431      0.322     -5.730      0.000      -2.474      -1.212\n",
       "sharpness          -0.8867      0.398     -2.230      0.026      -1.666      -0.107\n",
       "shifting            0.3880      0.312      1.243      0.214      -0.224       1.000\n",
       "shimmer             1.0275      0.260      3.955      0.000       0.518       1.537\n",
       "short              -0.3577      0.123     -2.908      0.004      -0.599      -0.116\n",
       "shot                0.0104      0.385      0.027      0.979      -0.744       0.765\n",
       "silky               0.0163      0.122      0.133      0.894      -0.223       0.255\n",
       "simple             -0.4172      0.200     -2.088      0.037      -0.809      -0.025\n",
       "simplifies         -0.0077      0.236     -0.033      0.974      -0.471       0.455\n",
       "simplify           -0.5671      0.373     -1.521      0.128      -1.298       0.164\n",
       "singed             -0.2035      0.434     -0.469      0.639      -1.054       0.647\n",
       "single             -2.2073      0.988     -2.234      0.026      -4.145      -0.270\n",
       "size               -0.0566      0.570     -0.099      0.921      -1.174       1.061\n",
       "slight              0.8145      0.224      3.636      0.000       0.375       1.254\n",
       "slightly            0.0897      0.167      0.536      0.592      -0.238       0.417\n",
       "small               0.0378      0.243      0.155      0.877      -0.440       0.515\n",
       "smoke               0.1274      0.367      0.348      0.728      -0.591       0.846\n",
       "smoky               0.3731      0.242      1.541      0.123      -0.102       0.848\n",
       "smooth              0.1050      0.100      1.047      0.295      -0.092       0.302\n",
       "smoothly            0.3995      0.250      1.596      0.111      -0.091       0.890\n",
       "soft                0.4904      0.202      2.428      0.015       0.094       0.886\n",
       "soften             -0.2755      0.279     -0.987      0.324      -0.823       0.272\n",
       "softened            0.4637      0.334      1.389      0.165      -0.191       1.119\n",
       "softening          -0.0456      0.360     -0.127      0.899      -0.752       0.660\n",
       "softens            -0.2304      0.205     -1.125      0.261      -0.632       0.171\n",
       "softly              0.4227      0.247      1.708      0.088      -0.062       0.908\n",
       "solid              -0.9886      0.306     -3.235      0.001      -1.588      -0.389\n",
       "sort               -0.2810      0.295     -0.952      0.341      -0.860       0.298\n",
       "spearmint           0.4503      0.359      1.256      0.209      -0.253       1.153\n",
       "spice               0.4745      0.229      2.075      0.038       0.026       0.923\n",
       "spices              0.2130      0.354      0.601      0.548      -0.482       0.908\n",
       "spicy               0.1464      0.224      0.652      0.514      -0.293       0.586\n",
       "star                0.3112      0.238      1.305      0.192      -0.156       0.779\n",
       "stone               0.0538      0.265      0.203      0.839      -0.466       0.573\n",
       "straight            0.1464      0.355      0.413      0.680      -0.549       0.842\n",
       "straightforward     0.0352      0.249      0.142      0.887      -0.453       0.523\n",
       "strawberry          0.4936      0.198      2.488      0.013       0.105       0.883\n",
       "structure          -0.0862      0.141     -0.613      0.540      -0.362       0.190\n",
       "style               0.2327      0.408      0.570      0.568      -0.567       1.032\n",
       "subdued             0.0621      0.260      0.239      0.811      -0.447       0.572\n",
       "substantial        -1.0050      0.386     -2.601      0.009      -1.763      -0.247\n",
       "subtle              0.9313      0.286      3.260      0.001       0.371       1.491\n",
       "subtly             -0.0546      0.198     -0.276      0.783      -0.443       0.334\n",
       "sugar              -0.5629      0.682     -0.826      0.409      -1.900       0.774\n",
       "sugary              0.8631      0.348      2.482      0.013       0.181       1.545\n",
       "suggest             0.9508      0.366      2.601      0.009       0.234       1.667\n",
       "suggesting          0.0926      0.291      0.319      0.750      -0.478       0.663\n",
       "suggestion         -0.1274      0.206     -0.617      0.537      -0.532       0.277\n",
       "suggestions        -0.1474      0.174     -0.846      0.398      -0.489       0.194\n",
       "suggests            0.5596      0.284      1.973      0.049       0.004       1.116\n",
       "sumatra            -0.4284      0.435     -0.986      0.324      -1.280       0.424\n",
       "superb              1.3626      0.310      4.399      0.000       0.755       1.970\n",
       "support            -0.3264      0.383     -0.852      0.394      -1.078       0.425\n",
       "supported           0.3194      0.214      1.493      0.136      -0.100       0.739\n",
       "supporting          0.5505      0.367      1.499      0.134      -0.170       1.271\n",
       "surfaces           -0.4043      0.305     -1.324      0.186      -1.003       0.195\n",
       "surprising          0.9747      0.404      2.410      0.016       0.182       1.768\n",
       "surprisingly        0.0698      0.245      0.284      0.776      -0.412       0.551\n",
       "sustained          -0.1633      0.341     -0.480      0.632      -0.831       0.504\n",
       "sweet               0.3366      0.125      2.684      0.007       0.091       0.582\n",
       "sweetens            0.6252      0.245      2.549      0.011       0.144       1.106\n",
       "sweetly             0.1696      0.123      1.377      0.169      -0.072       0.411\n",
       "sweetness           0.7661      0.273      2.807      0.005       0.231       1.301\n",
       "syrup              -0.0428      0.695     -0.062      0.951      -1.405       1.319\n",
       "syrupy             -0.0411      0.159     -0.258      0.796      -0.353       0.271\n",
       "tamarind            0.5955      0.218      2.731      0.006       0.168       1.023\n",
       "tangerine           0.4454      0.165      2.707      0.007       0.123       0.768\n",
       "tangy               0.3301      0.394      0.838      0.402      -0.442       1.102\n",
       "tart                0.0943      0.135      0.700      0.484      -0.170       0.359\n",
       "tartly              0.3410      0.256      1.334      0.182      -0.160       0.842\n",
       "taste              -2.1545      0.380     -5.670      0.000      -2.899      -1.409\n",
       "taster              0.2340      0.557      0.420      0.675      -0.859       1.327\n",
       "tea                -0.1541      0.268     -0.576      0.565      -0.679       0.370\n",
       "ted                 1.7536      0.466      3.760      0.000       0.839       2.668\n",
       "tested             -1.8313      0.857     -2.137      0.033      -3.511      -0.151\n",
       "think               0.0366      0.328      0.112      0.911      -0.606       0.680\n",
       "throughline         0.0009      0.304      0.003      0.998      -0.595       0.597\n",
       "thyme               0.2394      0.217      1.103      0.270      -0.186       0.665\n",
       "tickle              0.9535      0.352      2.709      0.007       0.263       1.644\n",
       "tight              -0.0088      0.392     -0.023      0.982      -0.777       0.759\n",
       "toast               0.1524      0.286      0.533      0.594      -0.408       0.713\n",
       "toasted            -0.0184      0.401     -0.046      0.963      -0.805       0.768\n",
       "toasty              0.6420      0.449      1.430      0.153      -0.238       1.522\n",
       "tobacco             0.5252      0.411      1.278      0.202      -0.281       1.331\n",
       "toffee              0.3176      0.257      1.235      0.217      -0.187       0.822\n",
       "tomato             -0.4110      0.314     -1.308      0.191      -1.027       0.205\n",
       "toned              -0.1233      0.136     -0.908      0.364      -0.390       0.143\n",
       "tones              -0.5558      0.157     -3.535      0.000      -0.864      -0.248\n",
       "touch               0.3781      0.253      1.492      0.136      -0.119       0.875\n",
       "tropical            0.4527      0.316      1.431      0.152      -0.167       1.073\n",
       "turn                0.3266      0.231      1.413      0.158      -0.126       0.780\n",
       "turned              0.2654      0.421      0.631      0.528      -0.560       1.090\n",
       "turning             0.0188      0.351      0.054      0.957      -0.670       0.708\n",
       "turns              -0.4584      0.190     -2.416      0.016      -0.831      -0.086\n",
       "underlying      -2.877e-05      0.389  -7.39e-05      1.000      -0.763       0.763\n",
       "understated         1.5134      0.316      4.793      0.000       0.894       2.132\n",
       "undertones          0.1229      0.132      0.929      0.353      -0.137       0.382\n",
       "unusual             0.7068      0.304      2.328      0.020       0.112       1.302\n",
       "using              -0.3374      0.698     -0.483      0.629      -1.706       1.031\n",
       "vanilla             0.0380      0.209      0.182      0.856      -0.372       0.448\n",
       "velvety            -0.1540      0.143     -1.074      0.283      -0.435       0.127\n",
       "verbena             0.2881      0.210      1.369      0.171      -0.124       0.701\n",
       "vibrant             0.4685      0.210      2.228      0.026       0.056       0.881\n",
       "vibrantly           0.3980      0.239      1.666      0.096      -0.070       0.866\n",
       "violet              0.3649      0.237      1.539      0.124      -0.100       0.830\n",
       "viscous             0.3337      0.165      2.025      0.043       0.011       0.657\n",
       "vivacious           0.4175      0.294      1.421      0.155      -0.158       0.993\n",
       "volume             -0.3009      1.033     -0.291      0.771      -2.326       1.724\n",
       "walnut              0.2629      0.228      1.154      0.249      -0.184       0.710\n",
       "water              -0.9964      0.566     -1.760      0.079      -2.107       0.114\n",
       "watermelon          0.3648      0.365      1.000      0.317      -0.350       1.080\n",
       "way                 1.0337      0.390      2.651      0.008       0.269       1.798\n",
       "wendy               0.8480      0.599      1.415      0.157      -0.327       2.023\n",
       "whisky              0.5334      0.463      1.153      0.249      -0.373       1.440\n",
       "white               0.2750      0.291      0.944      0.345      -0.296       0.846\n",
       "wild                0.1417      0.290      0.489      0.625      -0.426       0.709\n",
       "willem             -0.2038      0.479     -0.425      0.671      -1.143       0.736\n",
       "wine                1.5786      0.240      6.588      0.000       1.109       2.048\n",
       "winey               0.1379      0.426      0.324      0.746      -0.697       0.973\n",
       "winy                1.1590      0.335      3.461      0.001       0.503       1.816\n",
       "wisteria            0.4820      0.249      1.936      0.053      -0.006       0.970\n",
       "wood                0.2504      0.263      0.950      0.342      -0.266       0.767\n",
       "woody              -1.2461      0.338     -3.683      0.000      -1.909      -0.583\n",
       "zest                0.0124      0.139      0.090      0.929      -0.260       0.285\n",
       "zesty               0.0050      0.280      0.018      0.986      -0.544       0.554\n",
       "==============================================================================\n",
       "Omnibus:                      701.284   Durbin-Watson:                   1.977\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14313.121\n",
       "Skew:                          -0.062   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.049   Cond. No.                         290.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate Model\n",
    "final_model = sm.OLS(y_remain, X_mm_remain_constant)\n",
    "\n",
    "# 2. Fit Model (this returns a seperate object with the parameters)\n",
    "final_model_results = final_model.fit()\n",
    "\n",
    "# Looking at the summary\n",
    "final_model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b89e79",
   "metadata": {},
   "source": [
    "This basic version has a pretty strong R2 value as is. \n",
    "\n",
    "Given the number of variables, it will be useful to sort the coef and p values. This will highlight which coefficients are strongest, and which have the strongest p-value, indicating that there is a real relationship there and its very unlikely that the finding is just due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a97c23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the pvalues and coefficients\n",
    "pvalues = final_model_results.pvalues\n",
    "coeff = final_model_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a768686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe using the pvales and coeff for easier sorting\n",
    "results_df = pd.DataFrame({'pvals': pvalues, 'coeff': coeff})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb56f6",
   "metadata": {},
   "source": [
    "Looking at coefficients first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "301de1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hard          -3.636910\n",
       "shadow        -2.924256\n",
       "flat          -2.605377\n",
       "nice          -2.540766\n",
       "single        -2.207284\n",
       "cups          -2.189681\n",
       "taste         -2.154472\n",
       "sharp         -1.843138\n",
       "tested        -1.831253\n",
       "pod           -1.680764\n",
       "bitter        -1.474950\n",
       "capsule       -1.466924\n",
       "pruny         -1.450876\n",
       "nuts          -1.396667\n",
       "sample        -1.382201\n",
       "musty         -1.374905\n",
       "faint         -1.279075\n",
       "bean_agtron   -1.273737\n",
       "woody         -1.246075\n",
       "dimension     -1.214421\n",
       "lean          -1.179287\n",
       "leanish       -1.101886\n",
       "carbon        -1.101617\n",
       "grace         -1.052883\n",
       "substantial   -1.004988\n",
       "water         -0.996420\n",
       "solid         -0.988622\n",
       "called        -0.919792\n",
       "interesting   -0.912091\n",
       "sharpness     -0.886726\n",
       "nose          -0.859408\n",
       "ferment       -0.853366\n",
       "mustiness     -0.824091\n",
       "key           -0.743318\n",
       "fallen        -0.723292\n",
       "burned        -0.670038\n",
       "origin_lat    -0.656468\n",
       "bay           -0.642872\n",
       "bitterish     -0.642027\n",
       "attractive    -0.614003\n",
       "ken           -0.605461\n",
       "astringent    -0.595191\n",
       "quite         -0.577004\n",
       "simplify      -0.567105\n",
       "sugar         -0.562928\n",
       "acid          -0.557562\n",
       "tones         -0.555838\n",
       "dominated     -0.516362\n",
       "rating        -0.509811\n",
       "shallow       -0.506789\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the 50 strongest negative coefficients\n",
    "results_df['coeff'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44bdccb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const            65.423442\n",
       "aroma             8.708658\n",
       "aftertaste        6.138584\n",
       "flavor            5.871105\n",
       "acidity           5.013760\n",
       "body              4.351545\n",
       "kenya             2.291016\n",
       "malty             1.942738\n",
       "ted               1.753575\n",
       "byron             1.744289\n",
       "ground_agtron     1.682064\n",
       "flower            1.582224\n",
       "wine              1.578629\n",
       "understated       1.513380\n",
       "blooms            1.481906\n",
       "best              1.425150\n",
       "miguel            1.416512\n",
       "superb            1.362618\n",
       "serve             1.307893\n",
       "leaves            1.291068\n",
       "cold              1.289755\n",
       "keurig            1.259523\n",
       "acidy             1.227601\n",
       "brown             1.204013\n",
       "berry             1.173601\n",
       "winy              1.159030\n",
       "leaf              1.152578\n",
       "flowering         1.122301\n",
       "ready             1.085979\n",
       "deepening         1.064350\n",
       "fragrant          1.056600\n",
       "especially        1.048805\n",
       "ethan             1.044863\n",
       "way               1.033733\n",
       "dimensioned       1.032348\n",
       "shimmer           1.027525\n",
       "cherryish         1.012664\n",
       "brewer            1.006863\n",
       "deepens           1.005686\n",
       "rum               1.001725\n",
       "herb              0.977119\n",
       "surprising        0.974738\n",
       "classic           0.970284\n",
       "lyric             0.968210\n",
       "explicit          0.958327\n",
       "nutella           0.956152\n",
       "tickle            0.953462\n",
       "suggest           0.950751\n",
       "lyrically         0.946718\n",
       "impression        0.943539\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#narrowing down to top 50 positie coefficients\n",
    "results_df['coeff'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaba7a2",
   "metadata": {},
   "source": [
    "Looking at p-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a03ffeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const             0.000000e+00\n",
       "aroma            1.728116e-189\n",
       "body              1.931333e-82\n",
       "aftertaste        3.574319e-72\n",
       "acidity           4.577116e-45\n",
       "flavor            1.009842e-43\n",
       "hard              4.115328e-18\n",
       "wine              5.098205e-11\n",
       "berry             2.485614e-10\n",
       "flat              2.052284e-09\n",
       "sharp             1.086212e-08\n",
       "taste             1.541735e-08\n",
       "shadow            1.560907e-08\n",
       "ground_agtron     1.846499e-08\n",
       "acidy             6.293852e-08\n",
       "orange            7.384449e-08\n",
       "kenya             3.612057e-07\n",
       "floral            4.145186e-07\n",
       "malty             4.905591e-07\n",
       "understated       1.711198e-06\n",
       "cocoa             2.653913e-06\n",
       "flower            4.252826e-06\n",
       "chocolate         5.162893e-06\n",
       "nice              6.460172e-06\n",
       "long              6.576506e-06\n",
       "clean             8.907306e-06\n",
       "honey             9.221251e-06\n",
       "cups              9.346409e-06\n",
       "faint             1.061656e-05\n",
       "superb            1.117158e-05\n",
       "flowers           1.373589e-05\n",
       "dimension         1.442235e-05\n",
       "richly            1.948564e-05\n",
       "complex           2.939013e-05\n",
       "cherryish         4.599608e-05\n",
       "origin_lat        7.220066e-05\n",
       "shimmer           7.799315e-05\n",
       "bitter            8.373882e-05\n",
       "pruny             9.440342e-05\n",
       "complexity        9.930833e-05\n",
       "lean              1.003524e-04\n",
       "low               1.107293e-04\n",
       "high              1.284316e-04\n",
       "pure              1.340769e-04\n",
       "fruit             1.536348e-04\n",
       "ted               1.723802e-04\n",
       "woody             2.336288e-04\n",
       "slight            2.806165e-04\n",
       "musty             3.006553e-04\n",
       "rich              3.416492e-04\n",
       "Name: pvals, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have lowest pvalues\n",
    "results_df['pvals'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77918bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underlying         0.999941\n",
       "salty              0.998292\n",
       "throughline        0.997745\n",
       "nib                0.993386\n",
       "brewing            0.992947\n",
       "particularly       0.987922\n",
       "zesty              0.985821\n",
       "tight              0.982015\n",
       "shot               0.978526\n",
       "particular         0.977564\n",
       "simplifies         0.973948\n",
       "device             0.969061\n",
       "brewed             0.967686\n",
       "pecan              0.966520\n",
       "lead               0.965155\n",
       "toasted            0.963430\n",
       "turning            0.957313\n",
       "aromatic           0.955735\n",
       "syrup              0.950809\n",
       "little             0.948572\n",
       "centers            0.939440\n",
       "relatively         0.935932\n",
       "carrying           0.929579\n",
       "zest               0.928656\n",
       "round              0.921084\n",
       "size               0.920972\n",
       "evaluated          0.917444\n",
       "liked              0.914752\n",
       "think              0.911055\n",
       "rye                0.908868\n",
       "fading             0.900722\n",
       "softening          0.899193\n",
       "freshly            0.896761\n",
       "mid                0.895762\n",
       "silky              0.893880\n",
       "original           0.893681\n",
       "satisfying         0.892573\n",
       "straightforward    0.887474\n",
       "dominate           0.886740\n",
       "faintly            0.886210\n",
       "produced           0.878353\n",
       "small              0.876768\n",
       "complicate         0.866567\n",
       "fir                0.857296\n",
       "vanilla            0.855903\n",
       "florals            0.853452\n",
       "pleasingly         0.852995\n",
       "bean               0.845413\n",
       "harmonious         0.839324\n",
       "stone              0.839250\n",
       "Name: pvals, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have highest pvalues\n",
    "results_df['pvals'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15356419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvals</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>65.423442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_agtron</th>\n",
       "      <td>4.289270e-04</td>\n",
       "      <td>-1.273737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ground_agtron</th>\n",
       "      <td>1.846499e-08</td>\n",
       "      <td>1.682064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aroma</th>\n",
       "      <td>1.728116e-189</td>\n",
       "      <td>8.708658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acidity</th>\n",
       "      <td>4.577116e-45</td>\n",
       "      <td>5.013760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viscous</th>\n",
       "      <td>4.296123e-02</td>\n",
       "      <td>0.333725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>8.051757e-03</td>\n",
       "      <td>1.033733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>5.098205e-11</td>\n",
       "      <td>1.578629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winy</th>\n",
       "      <td>5.434969e-04</td>\n",
       "      <td>1.159030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woody</th>\n",
       "      <td>2.336288e-04</td>\n",
       "      <td>-1.246075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pvals      coeff\n",
       "const           0.000000e+00  65.423442\n",
       "bean_agtron     4.289270e-04  -1.273737\n",
       "ground_agtron   1.846499e-08   1.682064\n",
       "aroma          1.728116e-189   8.708658\n",
       "acidity         4.577116e-45   5.013760\n",
       "...                      ...        ...\n",
       "viscous         4.296123e-02   0.333725\n",
       "way             8.051757e-03   1.033733\n",
       "wine            5.098205e-11   1.578629\n",
       "winy            5.434969e-04   1.159030\n",
       "woody           2.336288e-04  -1.246075\n",
       "\n",
       "[193 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating filtered dataframe that only includes coefficients that have significant p-values\n",
    "sig_results_df = results_df.loc[results_df['pvals'] <= 0.05]\n",
    "sig_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b49e886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvals</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bean_agtron</th>\n",
       "      <td>4.289270e-04</td>\n",
       "      <td>-1.273737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_lat</th>\n",
       "      <td>7.220066e-05</td>\n",
       "      <td>-0.656468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astringent</th>\n",
       "      <td>4.897715e-03</td>\n",
       "      <td>-0.595191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attractive</th>\n",
       "      <td>4.293996e-02</td>\n",
       "      <td>-0.614003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitter</th>\n",
       "      <td>8.373882e-05</td>\n",
       "      <td>-1.474950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>called</th>\n",
       "      <td>2.463395e-02</td>\n",
       "      <td>-0.919792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbon</th>\n",
       "      <td>1.562305e-02</td>\n",
       "      <td>-1.101617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cups</th>\n",
       "      <td>9.346409e-06</td>\n",
       "      <td>-2.189681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <td>1.442235e-05</td>\n",
       "      <td>-1.214421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominated</th>\n",
       "      <td>1.823310e-02</td>\n",
       "      <td>-0.516362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drying</th>\n",
       "      <td>1.726113e-02</td>\n",
       "      <td>-0.312918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faint</th>\n",
       "      <td>1.061656e-05</td>\n",
       "      <td>-1.279075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ferment</th>\n",
       "      <td>6.251818e-03</td>\n",
       "      <td>-0.853366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flat</th>\n",
       "      <td>2.052284e-09</td>\n",
       "      <td>-2.605377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grace</th>\n",
       "      <td>3.648638e-03</td>\n",
       "      <td>-1.052883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard</th>\n",
       "      <td>4.115328e-18</td>\n",
       "      <td>-3.636910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesting</th>\n",
       "      <td>1.041513e-02</td>\n",
       "      <td>-0.912091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>3.800845e-02</td>\n",
       "      <td>-0.743318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lean</th>\n",
       "      <td>1.003524e-04</td>\n",
       "      <td>-1.179287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leanish</th>\n",
       "      <td>7.039198e-04</td>\n",
       "      <td>-1.101886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1.070665e-02</td>\n",
       "      <td>-0.334987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musty</th>\n",
       "      <td>3.006553e-04</td>\n",
       "      <td>-1.374905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>6.460172e-06</td>\n",
       "      <td>-2.540766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nose</th>\n",
       "      <td>1.173579e-03</td>\n",
       "      <td>-0.859408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuts</th>\n",
       "      <td>1.056368e-03</td>\n",
       "      <td>-1.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pod</th>\n",
       "      <td>4.015748e-02</td>\n",
       "      <td>-1.680764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruny</th>\n",
       "      <td>9.440342e-05</td>\n",
       "      <td>-1.450876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quite</th>\n",
       "      <td>2.401313e-02</td>\n",
       "      <td>-0.577004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <td>1.604772e-02</td>\n",
       "      <td>-1.382201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shadow</th>\n",
       "      <td>1.560907e-08</td>\n",
       "      <td>-2.924256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharp</th>\n",
       "      <td>1.086212e-08</td>\n",
       "      <td>-1.843138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharpness</th>\n",
       "      <td>2.582678e-02</td>\n",
       "      <td>-0.886726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>3.662803e-03</td>\n",
       "      <td>-0.357663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>3.685383e-02</td>\n",
       "      <td>-0.417165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>2.555604e-02</td>\n",
       "      <td>-2.207284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solid</th>\n",
       "      <td>1.228266e-03</td>\n",
       "      <td>-0.988622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substantial</th>\n",
       "      <td>9.330837e-03</td>\n",
       "      <td>-1.004988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taste</th>\n",
       "      <td>1.541735e-08</td>\n",
       "      <td>-2.154472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tested</th>\n",
       "      <td>3.263258e-02</td>\n",
       "      <td>-1.831253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tones</th>\n",
       "      <td>4.135714e-04</td>\n",
       "      <td>-0.555838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turns</th>\n",
       "      <td>1.575233e-02</td>\n",
       "      <td>-0.458443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woody</th>\n",
       "      <td>2.336288e-04</td>\n",
       "      <td>-1.246075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pvals     coeff\n",
       "bean_agtron  4.289270e-04 -1.273737\n",
       "origin_lat   7.220066e-05 -0.656468\n",
       "astringent   4.897715e-03 -0.595191\n",
       "attractive   4.293996e-02 -0.614003\n",
       "bitter       8.373882e-05 -1.474950\n",
       "called       2.463395e-02 -0.919792\n",
       "carbon       1.562305e-02 -1.101617\n",
       "cups         9.346409e-06 -2.189681\n",
       "dimension    1.442235e-05 -1.214421\n",
       "dominated    1.823310e-02 -0.516362\n",
       "drying       1.726113e-02 -0.312918\n",
       "faint        1.061656e-05 -1.279075\n",
       "ferment      6.251818e-03 -0.853366\n",
       "flat         2.052284e-09 -2.605377\n",
       "grace        3.648638e-03 -1.052883\n",
       "hard         4.115328e-18 -3.636910\n",
       "interesting  1.041513e-02 -0.912091\n",
       "key          3.800845e-02 -0.743318\n",
       "lean         1.003524e-04 -1.179287\n",
       "leanish      7.039198e-04 -1.101886\n",
       "like         1.070665e-02 -0.334987\n",
       "musty        3.006553e-04 -1.374905\n",
       "nice         6.460172e-06 -2.540766\n",
       "nose         1.173579e-03 -0.859408\n",
       "nuts         1.056368e-03 -1.396667\n",
       "pod          4.015748e-02 -1.680764\n",
       "pruny        9.440342e-05 -1.450876\n",
       "quite        2.401313e-02 -0.577004\n",
       "sample       1.604772e-02 -1.382201\n",
       "shadow       1.560907e-08 -2.924256\n",
       "sharp        1.086212e-08 -1.843138\n",
       "sharpness    2.582678e-02 -0.886726\n",
       "short        3.662803e-03 -0.357663\n",
       "simple       3.685383e-02 -0.417165\n",
       "single       2.555604e-02 -2.207284\n",
       "solid        1.228266e-03 -0.988622\n",
       "substantial  9.330837e-03 -1.004988\n",
       "taste        1.541735e-08 -2.154472\n",
       "tested       3.263258e-02 -1.831253\n",
       "tones        4.135714e-04 -0.555838\n",
       "turns        1.575233e-02 -0.458443\n",
       "woody        2.336288e-04 -1.246075"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolating significant, negative coefficients\n",
    "neg_sig_results_df = results_df.loc[(results_df['pvals'] <= 0.05)&(results_df['coeff']<0)]\n",
    "neg_sig_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd12fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hard          -3.636910\n",
       "shadow        -2.924256\n",
       "flat          -2.605377\n",
       "nice          -2.540766\n",
       "single        -2.207284\n",
       "cups          -2.189681\n",
       "taste         -2.154472\n",
       "sharp         -1.843138\n",
       "tested        -1.831253\n",
       "pod           -1.680764\n",
       "bitter        -1.474950\n",
       "pruny         -1.450876\n",
       "nuts          -1.396667\n",
       "sample        -1.382201\n",
       "musty         -1.374905\n",
       "faint         -1.279075\n",
       "bean_agtron   -1.273737\n",
       "woody         -1.246075\n",
       "dimension     -1.214421\n",
       "lean          -1.179287\n",
       "leanish       -1.101886\n",
       "carbon        -1.101617\n",
       "grace         -1.052883\n",
       "substantial   -1.004988\n",
       "solid         -0.988622\n",
       "called        -0.919792\n",
       "interesting   -0.912091\n",
       "sharpness     -0.886726\n",
       "nose          -0.859408\n",
       "ferment       -0.853366\n",
       "key           -0.743318\n",
       "origin_lat    -0.656468\n",
       "attractive    -0.614003\n",
       "astringent    -0.595191\n",
       "quite         -0.577004\n",
       "tones         -0.555838\n",
       "dominated     -0.516362\n",
       "turns         -0.458443\n",
       "simple        -0.417165\n",
       "short         -0.357663\n",
       "like          -0.334987\n",
       "drying        -0.312918\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which variables with significant pvalues have strongest neg coeff\n",
    "neg_visual = neg_sig_results_df['coeff'].sort_values()\n",
    "neg_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f51ac319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvals</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>65.423442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ground_agtron</th>\n",
       "      <td>1.846499e-08</td>\n",
       "      <td>1.682064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aroma</th>\n",
       "      <td>1.728116e-189</td>\n",
       "      <td>8.708658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acidity</th>\n",
       "      <td>4.577116e-45</td>\n",
       "      <td>5.013760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>1.931333e-82</td>\n",
       "      <td>4.351545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibrant</th>\n",
       "      <td>2.591547e-02</td>\n",
       "      <td>0.468497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viscous</th>\n",
       "      <td>4.296123e-02</td>\n",
       "      <td>0.333725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>8.051757e-03</td>\n",
       "      <td>1.033733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>5.098205e-11</td>\n",
       "      <td>1.578629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winy</th>\n",
       "      <td>5.434969e-04</td>\n",
       "      <td>1.159030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pvals      coeff\n",
       "const           0.000000e+00  65.423442\n",
       "ground_agtron   1.846499e-08   1.682064\n",
       "aroma          1.728116e-189   8.708658\n",
       "acidity         4.577116e-45   5.013760\n",
       "body            1.931333e-82   4.351545\n",
       "...                      ...        ...\n",
       "vibrant         2.591547e-02   0.468497\n",
       "viscous         4.296123e-02   0.333725\n",
       "way             8.051757e-03   1.033733\n",
       "wine            5.098205e-11   1.578629\n",
       "winy            5.434969e-04   1.159030\n",
       "\n",
       "[151 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolating significant, negative coefficients\n",
    "pos_sig_results_df = results_df.loc[(results_df['pvals'] <= 0.05)&(results_df['coeff']>=0)]\n",
    "pos_sig_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c809de2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const            65.423442\n",
       "aroma             8.708658\n",
       "aftertaste        6.138584\n",
       "flavor            5.871105\n",
       "acidity           5.013760\n",
       "body              4.351545\n",
       "kenya             2.291016\n",
       "malty             1.942738\n",
       "ted               1.753575\n",
       "byron             1.744289\n",
       "ground_agtron     1.682064\n",
       "flower            1.582224\n",
       "wine              1.578629\n",
       "understated       1.513380\n",
       "blooms            1.481906\n",
       "best              1.425150\n",
       "miguel            1.416512\n",
       "superb            1.362618\n",
       "leaves            1.291068\n",
       "acidy             1.227601\n",
       "berry             1.173601\n",
       "winy              1.159030\n",
       "leaf              1.152578\n",
       "deepening         1.064350\n",
       "fragrant          1.056600\n",
       "especially        1.048805\n",
       "way               1.033733\n",
       "dimensioned       1.032348\n",
       "shimmer           1.027525\n",
       "cherryish         1.012664\n",
       "deepens           1.005686\n",
       "rum               1.001725\n",
       "herb              0.977119\n",
       "surprising        0.974738\n",
       "classic           0.970284\n",
       "lyric             0.968210\n",
       "explicit          0.958327\n",
       "nutella           0.956152\n",
       "tickle            0.953462\n",
       "suggest           0.950751\n",
       "lyrically         0.946718\n",
       "impression        0.943539\n",
       "subtle            0.931253\n",
       "complexity        0.913630\n",
       "pure              0.906606\n",
       "orange            0.893154\n",
       "probably          0.892405\n",
       "nectar            0.889970\n",
       "clean             0.885667\n",
       "sugary            0.863118\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which variables with significant pvalues have strongest positive coeff\n",
    "pos_visual = pos_sig_results_df['coeff'].sort_values(ascending=False)[:50]\n",
    "pos_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ddd0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for easy reference to create visualizations\n",
    "neg_visual.to_csv('neg_visual_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21eae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save for easy reference to create visualizations\n",
    "pos_visual.to_csv('pos_visual_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ what does it mean? Narrate\n",
    "########## pull coef from elastic net model to compare - and maybe export the elastic net coeff insted\n",
    "###stas model just a sanity check\n",
    "##### other value Arad suggested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6907da",
   "metadata": {},
   "source": [
    "### 7.2 SKLearn Elastic Net Model Interpretation <a class=\"anchor\" id=\"subheader72\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7190d87",
   "metadata": {},
   "source": [
    "## 8. Conclusion <a class=\"anchor\" id=\"header8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f821b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
