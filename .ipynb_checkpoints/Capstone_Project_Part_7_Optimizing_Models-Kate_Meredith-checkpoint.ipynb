{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953ed9c0",
   "metadata": {},
   "source": [
    "# Capstone Project Part 7: Optimizing Models\n",
    "\n",
    "**Authur:** Kate Meredith \n",
    "\n",
    "**Date:** September-November 2022\n",
    "\n",
    "**Notebook #**: 7 of\n",
    "\n",
    "## Background\n",
    "\n",
    "**Source:** Data was collected from [CoffeeReview.com](https://www.coffeereview.com/). See prior notebooks for details on scraping, cleaning, compilation and text transformation. \n",
    "\n",
    "**Goal:** Optimize models on full data set (both text transformed and original numerical values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2d3d1",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Documentation on [Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- Documentation on [Lasso Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- Documentation on [ElasticNet Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)\n",
    "- [Differences](https://towardsdatascience.com/whats-the-difference-between-linear-regression-lasso-ridge-and-elasticnet-8f997c60cf29) between linear, ridge, lasso and elastic net regression\n",
    "- How to [add headers back after scaling data](https://stackoverflow.com/questions/29586323/how-to-retain-column-headers-of-data-frame-after-pre-processing-in-scikit-learn)\n",
    "- Getting model [results as a dataframe](https://stackoverflow.com/questions/51734180/converting-statsmodels-summary-object-to-pandas-dataframe)\n",
    "- Using first row as [column headers](https://stackoverflow.com/questions/31328861/python-pandas-replacing-header-with-top-row)\n",
    "- Filtering sorted array to [get top N values](https://stackoverflow.com/questions/6910641/how-do-i-get-indices-of-n-maximum-values-in-a-numpy-array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d4ee2",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Importing Libraries](#header1)\n",
    "* [2. Importing the Data and EDA](#header2)\n",
    "* [3. Scaling the Data](#header3)\n",
    "* [4. Principal Component Analysis](#header4)\n",
    "* [5. Optimizing the Models](#header5)\n",
    "    * [5.1 Linear Regression](#subheader51)\n",
    "    * [5.2 XGBoost Regressor](#subheader52)\n",
    "* [6. Comparing all Models](#header6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235584d",
   "metadata": {},
   "source": [
    "## Importing Libraries  <a class=\"anchor\" id=\"header1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3552bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tempfile import mkdtemp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95567a0a",
   "metadata": {},
   "source": [
    "## 2. Importing the Data and EDA <a class=\"anchor\" id=\"header2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113fe582",
   "metadata": {},
   "source": [
    "In the last notebook, the text was transformed using a few different methods. Given time limitations, this will move forward with the data transformation method that worked best: TFIDF Vectorization. The data has already been split into remain (training), validation, and test data. These datasets will be imported here to use.\n",
    "\n",
    "Importing the remain (training) data and exploring some initial info about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1884d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4194 entries, 0 to 4193\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(621), int64(9), object(2)\n",
      "memory usage: 20.2+ MB\n"
     ]
    }
   ],
   "source": [
    "Xremain_df_tfidf = pd.read_csv('tfidf_Xremain_combo_df.csv')\n",
    "Xremain_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed88598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 632)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d7791",
   "metadata": {},
   "source": [
    "The remain data set has 4,194 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13558f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Celebration Caffe</td>\n",
       "      <td>Allegro Coffee</td>\n",
       "      <td>11</td>\n",
       "      <td>1999</td>\n",
       "      <td>54</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>Starbucks Coffee</td>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colombia Tolima Cup of Excellence Presidential...</td>\n",
       "      <td>Terroir Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gesha Village 1931, Lot 86</td>\n",
       "      <td>Mudhouse Coffee Roasters</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya AA</td>\n",
       "      <td>Willoughby's Coffee &amp; Tea</td>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         coffee_name  \\\n",
       "0                                  Celebration Caffe   \n",
       "1                                              Kenya   \n",
       "2  Colombia Tolima Cup of Excellence Presidential...   \n",
       "3                         Gesha Village 1931, Lot 86   \n",
       "4                                           Kenya AA   \n",
       "\n",
       "                roaster_name  month  year  bean_agtron  ground_agtron  aroma  \\\n",
       "0             Allegro Coffee     11  1999           54             71      8   \n",
       "1           Starbucks Coffee      6  1999           33             35      7   \n",
       "2             Terroir Coffee      2  2007           56             68      8   \n",
       "3   Mudhouse Coffee Roasters      9  2017           54             78     10   \n",
       "4  Willoughby's Coffee & Tea      3  1997           46             49      8   \n",
       "\n",
       "   acidity  body  flavor  ...  white      wild  willem      wine      winy  \\\n",
       "0        8     7       8  ...    0.0  0.314372     0.0  0.248770  0.000000   \n",
       "1        8     7       8  ...    0.0  0.000000     0.0  0.403825  0.000000   \n",
       "2        7     8       7  ...    0.0  0.000000     0.0  0.000000  0.000000   \n",
       "3        9     9       9  ...    0.0  0.000000     0.0  0.000000  0.000000   \n",
       "4        8     8       8  ...    0.0  0.000000     0.0  0.000000  0.451704   \n",
       "\n",
       "   wisteria  wood  woody  zest  zesty  \n",
       "0       0.0   0.0    0.0   0.0    0.0  \n",
       "1       0.0   0.0    0.0   0.0    0.0  \n",
       "2       0.0   0.0    0.0   0.0    0.0  \n",
       "3       0.0   0.0    0.0   0.0    0.0  \n",
       "4       0.0   0.0    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8d9ea",
   "metadata": {},
   "source": [
    "Most of the columns come from the vectorized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8749f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1049 entries, 0 to 1048\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(618), int64(12), object(2)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#importing the validation data and checking out the info\n",
    "Xval_df_tfidf = pd.read_csv('tfidf_Xval_combo_df.csv')\n",
    "Xval_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313c5ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 632)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd1a98",
   "metadata": {},
   "source": [
    "The validation data set has 1,049 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069355df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hojas de Otono</td>\n",
       "      <td>Caribou Coffee</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colombia Supremo Pitalito Estate</td>\n",
       "      <td>The Roasterie</td>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Papua New Guinea Sero Bebes</td>\n",
       "      <td>Temple Coffee and Tea</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Gaucho Espresso</td>\n",
       "      <td>Manzanita Roasting Company</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jamaican Blue Mtn Dark Roast</td>\n",
       "      <td>Endless World Coffee</td>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        coffee_name                roaster_name  month  year  \\\n",
       "0                    Hojas de Otono              Caribou Coffee      8  2011   \n",
       "1  Colombia Supremo Pitalito Estate               The Roasterie     12  2004   \n",
       "2       Papua New Guinea Sero Bebes       Temple Coffee and Tea      3  2016   \n",
       "3                El Gaucho Espresso  Manzanita Roasting Company      3  2016   \n",
       "4      Jamaican Blue Mtn Dark Roast        Endless World Coffee      6  1999   \n",
       "\n",
       "   bean_agtron  ground_agtron  aroma  acidity  body  flavor  ...  white  wild  \\\n",
       "0           43             49      8        7     8       9  ...    0.0   0.0   \n",
       "1           61             68      8        8     8       8  ...    0.0   0.0   \n",
       "2           57             80      9        8     8       9  ...    0.0   0.0   \n",
       "3           60             72      9        8     8       8  ...    0.0   0.0   \n",
       "4           35             42      7        6     6       7  ...    0.0   0.0   \n",
       "\n",
       "   willem  wine  winy  wisteria      wood  woody      zest  zesty  \n",
       "0     0.0   0.0   0.0       0.0  0.186518    0.0  0.000000    0.0  \n",
       "1     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "2     0.0   0.0   0.0       0.0  0.000000    0.0  0.147089    0.0  \n",
       "3     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "4     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad82135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1311 entries, 0 to 1310\n",
      "Columns: 632 entries, coffee_name to zesty\n",
      "dtypes: float64(620), int64(10), object(2)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#importing the test data and checking out the info\n",
    "Xtest_df_tfidf = pd.read_csv('tfidf_Xtest_combo_df.csv')\n",
    "Xtest_df_tfidf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be65476a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 632)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b02b9a",
   "metadata": {},
   "source": [
    "The test dataframe has 1311 rows and 640 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619f35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coffee_name</th>\n",
       "      <th>roaster_name</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East Timor Maubesse Fair-Trade Organic</td>\n",
       "      <td>PT's Coffee Roasting Co.</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambrosia Espresso</td>\n",
       "      <td>Caffe Fresco</td>\n",
       "      <td>9</td>\n",
       "      <td>2005</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFCC House Blend Espresso Capsule</td>\n",
       "      <td>Gourmesso</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumatra Dark</td>\n",
       "      <td>Van Houtte Cafe</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>French Roast</td>\n",
       "      <td>Tully's Coffee</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              coffee_name              roaster_name  month  \\\n",
       "0  East Timor Maubesse Fair-Trade Organic  PT's Coffee Roasting Co.      4   \n",
       "1                       Ambrosia Espresso              Caffe Fresco      9   \n",
       "2       SFCC House Blend Espresso Capsule                 Gourmesso      7   \n",
       "3                            Sumatra Dark           Van Houtte Cafe      1   \n",
       "4                            French Roast            Tully's Coffee      1   \n",
       "\n",
       "   year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  ...  white  \\\n",
       "0  2007           51             68      8        7     8       7  ...    0.0   \n",
       "1  2005           37             47      8        7     7       7  ...    0.0   \n",
       "2  2016           58             58      7        8     8       8  ...    0.0   \n",
       "3  2006           46             57      8        8     7       8  ...    0.0   \n",
       "4  2012           25             28      6        7     8       7  ...    0.0   \n",
       "\n",
       "   wild  willem  wine  winy  wisteria      wood  woody      zest  zesty  \n",
       "0   0.0     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "1   0.0     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "2   0.0     0.0   0.0   0.0       0.0  0.000000    0.0  0.116112    0.0  \n",
       "3   0.0     0.0   0.0   0.0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "4   0.0     0.0   0.0   0.0       0.0  0.223662    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 632 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bc3c5",
   "metadata": {},
   "source": [
    "Importing the y values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9c15b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             89\n",
       "1             88\n",
       "2             93\n",
       "3             95\n",
       "4             93"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_remain_df = pd.read_csv('y_remain_df.csv')\n",
    "y_remain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8ea157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       89\n",
       "1       88\n",
       "2       93\n",
       "3       95\n",
       "4       93\n",
       "        ..\n",
       "4189    92\n",
       "4190    94\n",
       "4191    92\n",
       "4192    92\n",
       "4193    94\n",
       "Name: overall_score, Length: 4194, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_remain = y_remain_df['overall_score']\n",
    "y_remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4629e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             92\n",
       "1             90\n",
       "2             92\n",
       "3             91\n",
       "4             84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_df = pd.read_csv('y_val_df.csv')\n",
    "y_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f42d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92\n",
       "1       90\n",
       "2       92\n",
       "3       91\n",
       "4       84\n",
       "        ..\n",
       "1044    92\n",
       "1045    89\n",
       "1046    92\n",
       "1047    92\n",
       "1048    87\n",
       "Name: overall_score, Length: 1049, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_val = y_val_df['overall_score']\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4f5833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall_score\n",
       "0             92\n",
       "1             87\n",
       "2             87\n",
       "3             90\n",
       "4             85"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.read_csv('y_test_df.csv')\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7130df20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       92\n",
       "1       87\n",
       "2       87\n",
       "3       90\n",
       "4       85\n",
       "        ..\n",
       "1306    95\n",
       "1307    90\n",
       "1308    91\n",
       "1309    94\n",
       "1310    93\n",
       "Name: overall_score, Length: 1311, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting y to work for modeling later\n",
    "#note lengths match corresponding X dataframe\n",
    "y_test = y_test_df['overall_score']\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4966e262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying no null values introduced during vectorizing process\n",
    "Xremain_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e39c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1093d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c57fc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_remain.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d362a7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59014536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f722192",
   "metadata": {},
   "source": [
    "Dropping the remaining text columns `coffee_name` and `roaster_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3080792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xremain_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b89be237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1999</td>\n",
       "      <td>54</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.015416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>47.603832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>42.485093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>38.029306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>41.279541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0     11  1999           54             71      8        8     7       8   \n",
       "1      6  1999           33             35      7        8     7       8   \n",
       "2      2  2007           56             68      8        7     8       7   \n",
       "3      9  2017           54             78     10        9     9       9   \n",
       "4      3  1997           46             49      8        8     8       8   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  white      wild  willem      wine      winy  \\\n",
       "0           8    40.015416  ...    0.0  0.314372     0.0  0.248770  0.000000   \n",
       "1           8    47.603832  ...    0.0  0.000000     0.0  0.403825  0.000000   \n",
       "2           7    42.485093  ...    0.0  0.000000     0.0  0.000000  0.000000   \n",
       "3           8    38.029306  ...    0.0  0.000000     0.0  0.000000  0.000000   \n",
       "4           8    41.279541  ...    0.0  0.000000     0.0  0.000000  0.451704   \n",
       "\n",
       "   wisteria  wood  woody  zest  zesty  \n",
       "0       0.0   0.0    0.0   0.0    0.0  \n",
       "1       0.0   0.0    0.0   0.0    0.0  \n",
       "2       0.0   0.0    0.0   0.0    0.0  \n",
       "3       0.0   0.0    0.0   0.0    0.0  \n",
       "4       0.0   0.0    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xremain_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d51e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b86eeff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>44.977300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2004</td>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>39.100105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>38.581061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32.717420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>34.053691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0      8  2011           43             49      8        7     8       9   \n",
       "1     12  2004           61             68      8        8     8       8   \n",
       "2      3  2016           57             80      9        8     8       9   \n",
       "3      3  2016           60             72      9        8     8       8   \n",
       "4      6  1999           35             42      7        6     6       7   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  white  wild  willem  wine  winy  wisteria  \\\n",
       "0          10    44.977300  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "1           8    39.100105  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "2           8    38.581061  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "3           8    32.717420  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "4           7    34.053691  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "\n",
       "       wood  woody      zest  zesty  \n",
       "0  0.186518    0.0  0.000000    0.0  \n",
       "1  0.000000    0.0  0.000000    0.0  \n",
       "2  0.000000    0.0  0.147089    0.0  \n",
       "3  0.000000    0.0  0.000000    0.0  \n",
       "4  0.000000    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52ac45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_df_tfidf.drop(['coffee_name', 'roaster_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23af1cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>39.049011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2005</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>41.325913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>52.517037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116112</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>45.503182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>47.603832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  bean_agtron  ground_agtron  aroma  acidity  body  flavor  \\\n",
       "0      4  2007           51             68      8        7     8       7   \n",
       "1      9  2005           37             47      8        7     7       7   \n",
       "2      7  2016           58             58      7        8     8       8   \n",
       "3      1  2006           46             57      8        8     7       8   \n",
       "4      1  2012           25             28      6        7     8       7   \n",
       "\n",
       "   aftertaste  roaster_lat  ...  white  wild  willem  wine  winy  wisteria  \\\n",
       "0           7    39.049011  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "1           7    41.325913  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "2           7    52.517037  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "3           8    45.503182  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "4           7    47.603832  ...    0.0   0.0     0.0   0.0   0.0       0.0   \n",
       "\n",
       "       wood  woody      zest  zesty  \n",
       "0  0.000000    0.0  0.000000    0.0  \n",
       "1  0.000000    0.0  0.000000    0.0  \n",
       "2  0.000000    0.0  0.116112    0.0  \n",
       "3  0.000000    0.0  0.000000    0.0  \n",
       "4  0.223662    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36a60a",
   "metadata": {},
   "source": [
    "## 3. Scaling the Data <a class=\"anchor\" id=\"header3\"></a>\n",
    "\n",
    "While scaling isn't required for all the model types (like linear regression), we'll go ahead and scale now to simplify the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "347b51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting min max scaler on remain data\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(Xremain_df_tfidf)\n",
    "\n",
    "#transforming the all the X data\n",
    "X_mm_scaled_remain = mm_scaler.transform(Xremain_df_tfidf)\n",
    "X_mm_scaled_val = mm_scaler.transform(Xval_df_tfidf)\n",
    "X_mm_scaled_test = mm_scaler.transform(Xtest_df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fed3cae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90909091, 0.08      , 0.56756757, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.45454545, 0.08      , 0.28378378, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.09090909, 0.4       , 0.59459459, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.09090909, 0.76      , 0.31081081, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.72727273, 0.92      , 0.54054054, ..., 0.        , 0.41449663,\n",
       "        0.        ],\n",
       "       [0.81818182, 0.92      , 0.58108108, ..., 0.        , 0.4008192 ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview scaled date\n",
    "X_mm_scaled_remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cf71317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.758213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.832129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.782269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.738867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.909091  0.08     0.567568       0.678161  0.750  0.777778  0.500000   \n",
       "1  0.454545  0.08     0.283784       0.264368  0.625  0.777778  0.500000   \n",
       "2  0.090909  0.40     0.594595       0.643678  0.750  0.666667  0.666667   \n",
       "3  0.727273  0.80     0.567568       0.758621  1.000  0.888889  0.833333   \n",
       "4  0.181818  0.00     0.459459       0.425287  0.750  0.777778  0.666667   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  white     wild  willem      wine  \\\n",
       "0  0.714286       0.750     0.758213  ...    0.0  0.60698     0.0  0.408845   \n",
       "1  0.714286       0.750     0.832129  ...    0.0  0.00000     0.0  0.663671   \n",
       "2  0.571429       0.625     0.782269  ...    0.0  0.00000     0.0  0.000000   \n",
       "3  0.857143       0.750     0.738867  ...    0.0  0.00000     0.0  0.000000   \n",
       "4  0.714286       0.750     0.770526  ...    0.0  0.00000     0.0  0.000000   \n",
       "\n",
       "       winy  wisteria  wood  woody  zest  zesty  \n",
       "0  0.000000       0.0   0.0    0.0   0.0    0.0  \n",
       "1  0.000000       0.0   0.0    0.0   0.0    0.0  \n",
       "2  0.000000       0.0   0.0    0.0   0.0    0.0  \n",
       "3  0.000000       0.0   0.0    0.0   0.0    0.0  \n",
       "4  0.831939       0.0   0.0    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_remain = pd.DataFrame(X_mm_scaled_remain, columns = Xremain_df_tfidf.columns)\n",
    "\n",
    "#verify headers added back\n",
    "X_mm_scaled_remain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1557bca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63636364, 0.56      , 0.41891892, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.28      , 0.66216216, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.18181818, 0.76      , 0.60810811, ..., 0.        , 0.35079339,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.81818182, 0.68      , 0.71621622, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36363636, 0.76      , 0.62162162, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.27272727, 0.36      , 0.62162162, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm_scaled_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91639020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.425287</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.806545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.749297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.744241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350793</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.687125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.700142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.636364  0.56     0.418919       0.425287  0.750  0.666667  0.666667   \n",
       "1  1.000000  0.28     0.662162       0.643678  0.750  0.777778  0.666667   \n",
       "2  0.181818  0.76     0.608108       0.781609  0.875  0.777778  0.666667   \n",
       "3  0.181818  0.76     0.648649       0.689655  0.875  0.777778  0.666667   \n",
       "4  0.454545  0.08     0.310811       0.344828  0.625  0.555556  0.333333   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  white  wild  willem  wine  winy  \\\n",
       "0  0.857143       1.000     0.806545  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "1  0.714286       0.750     0.749297  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "2  0.857143       0.750     0.744241  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "3  0.714286       0.750     0.687125  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "4  0.571429       0.625     0.700142  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "\n",
       "   wisteria      wood  woody      zest  zesty  \n",
       "0       0.0  0.369527    0.0  0.000000    0.0  \n",
       "1       0.0  0.000000    0.0  0.000000    0.0  \n",
       "2       0.0  0.000000    0.0  0.350793    0.0  \n",
       "3       0.0  0.000000    0.0  0.000000    0.0  \n",
       "4       0.0  0.000000    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_val = pd.DataFrame(X_mm_scaled_val, columns = Xval_df_tfidf.columns)\n",
    "X_mm_scaled_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362fb5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27272727, 0.4       , 0.52702703, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.72727273, 0.32      , 0.33783784, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.54545455, 0.76      , 0.62162162, ..., 0.        , 0.27691744,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.81818182, 0.72      , 0.66216216, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.76      , 0.41891892, ..., 0.        , 0.34329853,\n",
       "        0.43415295],\n",
       "       [0.72727273, 0.96      , 0.59459459, ..., 0.        , 0.37247568,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mm_scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06b5f867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bean_agtron</th>\n",
       "      <th>ground_agtron</th>\n",
       "      <th>aroma</th>\n",
       "      <th>acidity</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>roaster_lat</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>willem</th>\n",
       "      <th>wine</th>\n",
       "      <th>winy</th>\n",
       "      <th>wisteria</th>\n",
       "      <th>wood</th>\n",
       "      <th>woody</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.748799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.770978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.879987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.811667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.832129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 630 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month  year  bean_agtron  ground_agtron  aroma   acidity      body  \\\n",
       "0  0.272727  0.40     0.527027       0.643678  0.750  0.666667  0.666667   \n",
       "1  0.727273  0.32     0.337838       0.402299  0.750  0.666667  0.500000   \n",
       "2  0.545455  0.76     0.621622       0.528736  0.625  0.777778  0.666667   \n",
       "3  0.000000  0.36     0.459459       0.517241  0.750  0.777778  0.500000   \n",
       "4  0.000000  0.60     0.175676       0.183908  0.500  0.666667  0.666667   \n",
       "\n",
       "     flavor  aftertaste  roaster_lat  ...  white  wild  willem  wine  winy  \\\n",
       "0  0.571429       0.625     0.748799  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "1  0.571429       0.625     0.770978  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "2  0.714286       0.625     0.879987  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "3  0.714286       0.750     0.811667  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "4  0.571429       0.625     0.832129  ...    0.0   0.0     0.0   0.0   0.0   \n",
       "\n",
       "   wisteria      wood  woody      zest  zesty  \n",
       "0       0.0  0.000000    0.0  0.000000    0.0  \n",
       "1       0.0  0.000000    0.0  0.000000    0.0  \n",
       "2       0.0  0.000000    0.0  0.276917    0.0  \n",
       "3       0.0  0.000000    0.0  0.000000    0.0  \n",
       "4       0.0  0.443116    0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 630 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add headers back to our scaled date for interpretability later \n",
    "X_mm_scaled_test = pd.DataFrame(X_mm_scaled_test, columns = Xtest_df_tfidf.columns)\n",
    "X_mm_scaled_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4ce64",
   "metadata": {},
   "source": [
    "## 4. Principal Component Analysis <a class=\"anchor\" id=\"header4\"></a>\n",
    "\n",
    "Given the number of dimensions in this dataset, simplifying our dimensions will may be beneficial. To do so, Pricipal Component Analysis (PCA) will be applied. However, we do lose interpretability with PCA. Therefore,  the models will be compared using PCA and the non-simplified data. If performance is similar, the non-simplified data can be used in order to retain interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "456f96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate and fit the PCA model\n",
    "my_PCA = PCA(n_components = 0.9) #retaining 90% of the variance\n",
    "my_PCA.fit(X_mm_scaled_val)\n",
    "\n",
    "# transform data \n",
    "X_remain_PCA = my_PCA.transform(X_mm_scaled_remain)\n",
    "X_val_PCA = my_PCA.transform(X_mm_scaled_val)\n",
    "X_test_PCA = my_PCA.transform(X_mm_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d187e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance captured by PC1:  0.252\n",
      "Variance captured by PC2:  0.167\n",
      "Proportion of variance captured by PC1:  0.049\n",
      "Proportion of variance captured by PC2:  0.033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Variance captured by PC1: {my_PCA.explained_variance_[0]: 0.3f}\")\n",
    "print(f\"Variance captured by PC2: {my_PCA.explained_variance_[1]: 0.3f}\")\n",
    "\n",
    "print(f\"Proportion of variance captured by PC1: {my_PCA.explained_variance_ratio_[0]: 0.3f}\")\n",
    "print(f\"Proportion of variance captured by PC2: {my_PCA.explained_variance_ratio_[1]: 0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4f7be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (4194, 630)\n",
      "PCA Transformed: (4194, 280)\n"
     ]
    }
   ],
   "source": [
    "print(f'Original: {Xremain_df_tfidf.shape}')\n",
    "print(f'PCA Transformed: {X_remain_PCA.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaee630",
   "metadata": {},
   "source": [
    "PCA is able to capture 90% of the variance while decreasing the number of features significantly to 280 (down from 630)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71290779",
   "metadata": {},
   "source": [
    "## 5. Fitting the Models <a class=\"anchor\" id=\"header5\"></a>\n",
    "\n",
    "Below will fit each of the models, trying both the 'full' dataset and the PCA dataset. In all of these, the data is scaled. At the end, R2 results will be compared across all models.\n",
    "\n",
    "### 5.1 Linear Regression <a class=\"anchor\" id=\"subheader51\"></a>\n",
    "\n",
    "**\"Vanilla\" Linear Regression** \n",
    "\n",
    "This first uses a basic, \"vanilla\" linear regression model. This is what we used in previous notebooks to check in on how our data transformations were performing.\n",
    "\n",
    "For reference:\n",
    "- The best validation data R2 from running Linear Regression on the text data alone was about 0.761.\n",
    "- The best validation data R2 from running Linear Regression on the numeric data alone (meaning no vectorized text) was about 0.898.\n",
    "\n",
    "**Linear Regression: Min Max, Full Dataset**\n",
    " \n",
    "Below runs the model on the full, scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2b29d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_full training data is: 0.9408817380239718\n",
      "The R2 score for lr_model_full validation data is: 0.9025842705674784\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "lr_model_full = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "lr_model_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_full training data is: {lr_model_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_full_val_r2 = lr_model_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_full validation data is: {lr_model_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747bbd0",
   "metadata": {},
   "source": [
    "**Linear Regression: Min Max, PCA Dataset**\n",
    " \n",
    "Below runs the model on the simplified, scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "af9a091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_pca training data is: 0.9201855216374213\n",
      "The R2 score for lr_model_pca validation data is: 0.8959728426048407\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "lr_model_pca = LinearRegression()\n",
    "\n",
    "# 2. Fit the model\n",
    "lr_model_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_pca training data is: {lr_model_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_pca_val_r2 = lr_model_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_pca validation data is: {lr_model_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb4194",
   "metadata": {},
   "source": [
    "Interestingly, the full dataset does slightly better than the PCA version. This may be because using PCA did trade some information for fewer dimensions (e.g. fewer columns). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f795c",
   "metadata": {},
   "source": [
    "**Ridge Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Ridge Regression model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a7f47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Ridge()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a9f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [6.2], \n",
    "    \"model__solver\": ['sag'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09a19adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 6.2, 'model__solver': 'sag'}\n",
      "Best score: 0.9120997478973498\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48932369",
   "metadata": {},
   "source": [
    "Below will see how these parameters do with our remain (training) and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d86cae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_ridge_full training data is: 0.9359693918542785\n",
      "The R2 score for lr_model_ridge_full validation data is: 0.9098745867302618\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_ridge_full = Ridge(alpha=6.2, solver='sag')\n",
    "lr_model_ridge_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_ridge_full training data is: {lr_model_ridge_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_ridge_full_val_r2 = lr_model_ridge_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_ridge_full validation data is: {lr_model_ridge_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaccdb2",
   "metadata": {},
   "source": [
    "**Ridge Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Ridge Regression model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "749def42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Ridge()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ef009b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [3.5], \n",
    "    \"model__solver\": ['sag'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ce030db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 3.5, 'model__solver': 'sag'}\n",
      "Best score: 0.9068516513539085\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262eb2dd",
   "metadata": {},
   "source": [
    "Ridge regression on the PCA data does slightly less well than the full dataset. The best parameters for it are shown above. Below will see how these do with the remain and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d6731068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_ridge_pca training data is: 0.9194928820732233\n",
      "The R2 score for lr_model_ridge_pca validation data is: 0.9011979701874846\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_ridge_pca = Ridge(alpha=3.5, solver='sag')\n",
    "lr_model_ridge_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_ridge_pca training data is: {lr_model_ridge_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_ridge_pca_val_r2 = lr_model_ridge_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_ridge_pca validation data is: {lr_model_ridge_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376d1c2",
   "metadata": {},
   "source": [
    "**Lasso Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Lasso Regression model using the full datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16b58c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Lasso()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65f76f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__positive\": [False],\n",
    "    \"model__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abb37dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9131574911589692\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1ae01",
   "metadata": {},
   "source": [
    "The optimal Lasso Regression model uses parameters are shown above. Below will see how the model does with training and validation data using these optimized paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6552a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_lasso_full training data is: 0.9270599542538364\n",
      "The R2 score for lr_model_lasso_full validation data is: 0.907597542099871\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_lasso_full = Lasso(alpha=0.002, positive=False, warm_start=True)\n",
    "lr_model_lasso_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_lasso_full training data is: {lr_model_lasso_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_lasso_full_val_r2 = lr_model_lasso_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_lasso_full validation data is: {lr_model_lasso_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db305a92",
   "metadata": {},
   "source": [
    "**Lasso Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal Lasso Regression model using the PCA datset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35f3fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", Lasso()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "667b7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__positive\": [False],\n",
    "    \"model__warm_start\": [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1f7aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9045196074779615\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a855433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_lasso_pca training data is: 0.9142017685228763\n",
      "The R2 score for lr_model_lasso_pca validation data is: 0.9033447450950415\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_lasso_pca = Lasso(alpha=0.002, positive=False, warm_start=True)\n",
    "lr_model_lasso_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_lasso_pca training data is: {lr_model_lasso_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_lasso_pca_val_r2 = lr_model_lasso_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_lasso_pca validation data is: {lr_model_lasso_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde2e83",
   "metadata": {},
   "source": [
    "**ElasticeNet Regression: Min Max, Full Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal ElasticNet Regression model on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30728ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", ElasticNet()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c0a46861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.002], \n",
    "    \"model__l1_ratio\": [0.4],\n",
    "    \"model__warm_start\": [True],\n",
    "    \"model__positive\": [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a7ffda66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.002, 'model__l1_ratio': 0.4, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9136891720109446\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc500db",
   "metadata": {},
   "source": [
    "Below will see how the optimized model does with the training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f10a5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_elastic_full training data is: 0.9319226114642285\n",
      "The R2 score for lr_model_elastic_full validation data is: 0.9101990891299294\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_elastic_full = ElasticNet(alpha=0.002, l1_ratio=0.4, positive=False, warm_start=True)\n",
    "lr_model_elastic_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_elastic_full training data is: {lr_model_elastic_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "lr_model_elastic_full_val_r2 = lr_model_elastic_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for lr_model_elastic_full validation data is: {lr_model_elastic_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101e491",
   "metadata": {},
   "source": [
    "**ElasticeNet Regression: Min Max, PCA Dataset**\n",
    "\n",
    "The pipeline below will look for the optimal ElasticNet Regression model on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46417187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", ElasticNet()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "377b9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__alpha\": [0.001], \n",
    "    \"model__l1_ratio\": [0.2],\n",
    "    \"model__warm_start\": [True],\n",
    "    \"model__positive\": [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0e43c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__alpha': 0.001, 'model__l1_ratio': 0.2, 'model__positive': False, 'model__warm_start': True}\n",
      "Best score: 0.9069016414322609\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "02763e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for lr_model_elastic_pca training data is: 0.9165220287609357\n",
      "The R2 score for lr_model_elastic_pca validation data is: 0.9041516740152954\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "lr_model_elastic_pca = ElasticNet(alpha=0.002, l1_ratio=0.4, positive=False, warm_start=True)\n",
    "lr_model_elastic_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for lr_model_elastic_pca training data is: {lr_model_elastic_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "lr_model_elastic_pca_val_r2 = lr_model_elastic_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for lr_model_elastic_pca validation data is: {lr_model_elastic_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4353908",
   "metadata": {},
   "source": [
    "Below will compare R2 values calculated on the validation data to see how these different regression models perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ae9fe1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the models\n",
    "R2_dictionary = {'Linear Full R2': lr_model_full_val_r2, 'Linear PCA R2' :lr_model_pca_val_r2, 'Ridge Full R2': lr_model_ridge_full_val_r2, 'Ridge PCA R2': lr_model_ridge_pca_val_r2, 'Lasso Full R2': lr_model_lasso_full_val_r2, 'Lasso PCA R2': lr_model_lasso_pca_val_r2, 'Elastic Full R2': lr_model_elastic_full_val_r2, 'Elastic PCA R2': lr_model_elastic_pca_val_r2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "efc5911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting scores\n",
    "R2_values_sorted = dict(sorted(R2_dictionary.items(), key = operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af761a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elastic Full R2': 0.9101990891299294,\n",
       " 'Ridge Full R2': 0.9098745867302618,\n",
       " 'Lasso Full R2': 0.907597542099871,\n",
       " 'Elastic PCA R2': 0.9041516740152954,\n",
       " 'Lasso PCA R2': 0.9033447450950415,\n",
       " 'Linear Full R2': 0.9025842705674784,\n",
       " 'Ridge PCA R2': 0.9011979701874846,\n",
       " 'Linear PCA R2': 0.8959728426048407}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_values_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931425a9",
   "metadata": {},
   "source": [
    "**Comparing model performance**\n",
    "\n",
    "Looking at the different regression models, ElasticNet using the full dataset performed best with the validation data. In general, using the full dataset provided better results than PCA, which is good because interpretability can be preserved then. \n",
    "\n",
    "All things considered, the models perform pretty similarly. \n",
    "\n",
    "Below will look at another model type before drawing digging further on the models and drawing conclusions about which performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4fdea0",
   "metadata": {},
   "source": [
    "### 5.2 XG Boost Regressor <a class=\"anchor\" id=\"subheader52\"></a>\n",
    "\n",
    "For reference, the best validation R2 from running the baseline XGBoost Regressor model on numeric data alone (no vectorized text) was about 91.8. XG Boost was not run on the text only data.\n",
    "\n",
    "**XG Boost Regressor: Min Max, Full Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4388ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model training data is: 0.9926375397608137\n",
      "The R2 score for XGBR_model validation data is: 0.9022804820873469\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the model\n",
    "XGBR_model = XGBRegressor()\n",
    "\n",
    "# 2. Fit the model\n",
    "XGBR_model.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model training data is: {XGBR_model.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "XGBR_model_val_r2 = XGBR_model.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for XGBR_model validation data is: {XGBR_model_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d048a2",
   "metadata": {},
   "source": [
    "Optimizing the XG Boost Model using the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ca21d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", XGBRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a6a9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__booster\": ['dart'], \n",
    "    \"model__eta\": [0.1],\n",
    "    \"model__gamma\": [1],\n",
    "    \"model__max_depth\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22165e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__booster': 'dart', 'model__eta': 0.1, 'model__gamma': 1, 'model__max_depth': 11}\n",
      "Best score: 0.9196504587392071\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ae500970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model_full training data is: 0.9921717669177883\n",
      "The R2 score for XGBR_model_full validation data is: 0.9157344141540313\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "XGBR_model_full = XGBRegressor(booster='dart', eta=0.1, gamma=1, max_depth=11)\n",
    "XGBR_model_full.fit(X_mm_scaled_remain, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model_full training data is: {XGBR_model_full.score(X_mm_scaled_remain, y_remain)}')\n",
    "\n",
    "XGBR_model_full_val_r2 = XGBR_model_full.score(X_mm_scaled_val, y_val)\n",
    "print(f'The R2 score for XGBR_model_full validation data is: {XGBR_model_full_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf79c9c",
   "metadata": {},
   "source": [
    "The optimized XG Boost Model does slightly better than Linear Regression, though it is quite overfit.\n",
    "\n",
    "Fitting the XGBoost Regressor model on the PCA data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1d7471e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our pipeline\n",
    "#the values listed here for vectorization are placeholders\n",
    "linreg = Pipeline(\n",
    "    [\n",
    "        (\"model\", XGBRegressor()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1f7b665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ran the grid search using a series of changes on these paramaters\n",
    "#started with more extreme options for each paramater and then narrowed down to these\n",
    "\n",
    "parameters = {\n",
    "    \"model__booster\": ['dart'], \n",
    "    \"model__eta\": [0.1],\n",
    "    \"model__gamma\": [1],\n",
    "    \"model__max_depth\": [5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c632a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__booster': 'dart', 'model__eta': 0.1, 'model__gamma': 1, 'model__max_depth': 5}\n",
      "Best score: 0.8519782429252418\n"
     ]
    }
   ],
   "source": [
    "#running the serach to find the best combination of these parameters\n",
    "grid_search = GridSearchCV(linreg, parameters)\n",
    "\n",
    "grid_search.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "#checking the R2\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c8c36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 score for XGBR_model_pca training data is: 0.9702665775242029\n",
      "The R2 score for XGBR_model_pca validation data is: 0.8466916761279962\n"
     ]
    }
   ],
   "source": [
    "#instatiate and fit best model\n",
    "XGBR_model_pca = XGBRegressor(booster='dart', eta=0.1, gamma=1, max_depth=5)\n",
    "XGBR_model_pca.fit(X_remain_PCA, y_remain)\n",
    "\n",
    "# 3. Scoring the models\n",
    "print(f'The R2 score for XGBR_model_pca training data is: {XGBR_model_pca.score(X_remain_PCA, y_remain)}')\n",
    "\n",
    "XGBR_model_pca_val_r2 = XGBR_model_pca.score(X_val_PCA, y_val)\n",
    "print(f'The R2 score for XGBR_model_pca validation data is: {XGBR_model_pca_val_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7809e",
   "metadata": {},
   "source": [
    "## 6. Comparing All Models <a class=\"anchor\" id=\"header6\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4caa4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the models\n",
    "R2_dictionary = {'Linear Full R2': lr_model_full_val_r2, 'Linear PCA R2' :lr_model_pca_val_r2, 'Ridge Full R2': lr_model_ridge_full_val_r2, 'Ridge PCA R2': lr_model_ridge_pca_val_r2, 'Lasso Full R2': lr_model_lasso_full_val_r2, 'Lasso PCA R2': lr_model_lasso_pca_val_r2, 'Elastic Full R2': lr_model_elastic_full_val_r2, 'Elastic PCA R2': lr_model_elastic_pca_val_r2, 'XGBR Full R2': XGBR_model_full_val_r2, 'XGBR PCA R2': XGBR_model_pca_val_r2} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba07d54",
   "metadata": {},
   "source": [
    "Below compares all the models run, listing the one with the highest R2 first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d236fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBR Full R2': 0.9157344141540313,\n",
       " 'Elastic Full R2': 0.9101990891299294,\n",
       " 'Ridge Full R2': 0.9098745867302618,\n",
       " 'Lasso Full R2': 0.907597542099871,\n",
       " 'Elastic PCA R2': 0.9041516740152954,\n",
       " 'Lasso PCA R2': 0.9033447450950415,\n",
       " 'Linear Full R2': 0.9025842705674784,\n",
       " 'Ridge PCA R2': 0.9011979701874846,\n",
       " 'Linear PCA R2': 0.8959728426048407,\n",
       " 'XGBR PCA R2': 0.8466916761279962}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting scores\n",
    "R2_values_sorted = dict(sorted(R2_dictionary.items(), key = operator.itemgetter(1), reverse=True))\n",
    "R2_values_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### come back and update############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c500fe",
   "metadata": {},
   "source": [
    "XGBR on the full dataset performs best, followed by ElasticNet on the full dataset. Overall, the PCA versions perform worse. XGBoost Regressor in particular takes a peformance hit when using the PCA data.\n",
    "\n",
    "Across the board, model performance is pretty similar, with the exception of the XGBR PCA version. At this stage, we'll pick one model to move forward with. We could use the XGBoost model on all the data, as it is the top model. However, interpretability is much more challenging. We could use a tool like SHAP to help with this. However, given how close the ElasticNet and other linear regression models are, we'll stick with the Linear Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374839d",
   "metadata": {},
   "source": [
    "## 7. Further Model Interpretation <a class=\"anchor\" id=\"header7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72475f",
   "metadata": {},
   "source": [
    "Unfortunately, SKLearn doesn't offer an easy way to way to get the p-values for the model. Instead, we'll dig into the model using stats models because of it's easier access to interpretable aspects like values. \n",
    "\n",
    "With stats models, we do have to add a constant to X before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "128b03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the constant before modeling\n",
    "X_mm_remain_constant = sm.add_constant(X_mm_scaled_remain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cbc05b",
   "metadata": {},
   "source": [
    "Running the model with stats models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1d81166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>overall_score</td>  <th>  R-squared:         </th> <td>   0.941</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   90.01</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:15:00</td>     <th>  Log-Likelihood:    </th> <td> -5943.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4194</td>      <th>  AIC:               </th> <td>1.315e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3563</td>      <th>  BIC:               </th> <td>1.715e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   630</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   66.8850</td> <td>    0.411</td> <td>  162.789</td> <td> 0.000</td> <td>   66.079</td> <td>   67.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>month</th>           <td>    0.0251</td> <td>    0.061</td> <td>    0.408</td> <td> 0.683</td> <td>   -0.095</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>            <td>    0.1609</td> <td>    0.271</td> <td>    0.594</td> <td> 0.552</td> <td>   -0.370</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bean_agtron</th>     <td>   -0.8571</td> <td>    0.373</td> <td>   -2.296</td> <td> 0.022</td> <td>   -1.589</td> <td>   -0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ground_agtron</th>   <td>    1.4394</td> <td>    0.313</td> <td>    4.605</td> <td> 0.000</td> <td>    0.827</td> <td>    2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aroma</th>           <td>    9.0722</td> <td>    0.283</td> <td>   32.017</td> <td> 0.000</td> <td>    8.517</td> <td>    9.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidity</th>         <td>    5.2718</td> <td>    0.356</td> <td>   14.822</td> <td> 0.000</td> <td>    4.574</td> <td>    5.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body</th>            <td>    4.5382</td> <td>    0.225</td> <td>   20.138</td> <td> 0.000</td> <td>    4.096</td> <td>    4.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavor</th>          <td>    4.4015</td> <td>    0.330</td> <td>   13.338</td> <td> 0.000</td> <td>    3.755</td> <td>    5.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aftertaste</th>      <td>    6.0364</td> <td>    0.343</td> <td>   17.617</td> <td> 0.000</td> <td>    5.365</td> <td>    6.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roaster_lat</th>     <td>    0.0449</td> <td>    0.247</td> <td>    0.182</td> <td> 0.856</td> <td>   -0.439</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roaster_lon</th>     <td>   -0.0015</td> <td>    0.091</td> <td>   -0.016</td> <td> 0.987</td> <td>   -0.180</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_lat</th>      <td>   -0.6637</td> <td>    0.168</td> <td>   -3.961</td> <td> 0.000</td> <td>   -0.992</td> <td>   -0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>origin_lon</th>      <td>   -0.0750</td> <td>    0.091</td> <td>   -0.824</td> <td> 0.410</td> <td>   -0.253</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acid</th>            <td>   -0.6022</td> <td>    0.547</td> <td>   -1.101</td> <td> 0.271</td> <td>   -1.674</td> <td>    0.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidity.1</th>       <td>   -0.0995</td> <td>    0.162</td> <td>   -0.614</td> <td> 0.539</td> <td>   -0.418</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acidy</th>           <td>    0.6202</td> <td>    0.249</td> <td>    2.493</td> <td> 0.013</td> <td>    0.132</td> <td>    1.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>admired</th>         <td>    0.5320</td> <td>    0.409</td> <td>    1.302</td> <td> 0.193</td> <td>   -0.269</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aftertaste.1</th>    <td>    0.8524</td> <td>    0.289</td> <td>    2.948</td> <td> 0.003</td> <td>    0.286</td> <td>    1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agave</th>           <td>    1.4111</td> <td>    0.595</td> <td>    2.370</td> <td> 0.018</td> <td>    0.244</td> <td>    2.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aged</th>            <td>   -0.2977</td> <td>    0.531</td> <td>   -0.560</td> <td> 0.575</td> <td>   -1.339</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agreeable</th>       <td>   -0.2906</td> <td>    0.450</td> <td>   -0.645</td> <td> 0.519</td> <td>   -1.174</td> <td>    0.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agreeably</th>       <td>    0.4098</td> <td>    0.349</td> <td>    1.174</td> <td> 0.240</td> <td>   -0.274</td> <td>    1.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alive</th>           <td>    0.1050</td> <td>    0.317</td> <td>    0.331</td> <td> 0.741</td> <td>   -0.517</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>almond</th>          <td>    0.1144</td> <td>    0.144</td> <td>    0.792</td> <td> 0.428</td> <td>   -0.169</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amber</th>           <td>    0.3853</td> <td>    0.361</td> <td>    1.067</td> <td> 0.286</td> <td>   -0.323</td> <td>    1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amplified</th>       <td>    0.0151</td> <td>    0.335</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.641</td> <td>    0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>anise</th>           <td>    0.3518</td> <td>    0.407</td> <td>    0.864</td> <td> 0.388</td> <td>   -0.447</td> <td>    1.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apple</th>           <td>    0.7312</td> <td>    0.220</td> <td>    3.321</td> <td> 0.001</td> <td>    0.300</td> <td>    1.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>apricot</th>         <td>    0.2994</td> <td>    0.144</td> <td>    2.078</td> <td> 0.038</td> <td>    0.017</td> <td>    0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatic</th>        <td>   -0.0502</td> <td>    0.221</td> <td>   -0.227</td> <td> 0.820</td> <td>   -0.483</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatically</th>    <td>    0.3928</td> <td>    0.400</td> <td>    0.981</td> <td> 0.327</td> <td>   -0.392</td> <td>    1.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aromatics</th>       <td>    0.1131</td> <td>    0.255</td> <td>    0.443</td> <td> 0.658</td> <td>   -0.387</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>astringency</th>     <td>   -1.0581</td> <td>    0.239</td> <td>   -4.424</td> <td> 0.000</td> <td>   -1.527</td> <td>   -0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>astringent</th>      <td>   -0.9194</td> <td>    0.219</td> <td>   -4.198</td> <td> 0.000</td> <td>   -1.349</td> <td>   -0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>attractive</th>      <td>   -0.7269</td> <td>    0.284</td> <td>   -2.558</td> <td> 0.011</td> <td>   -1.284</td> <td>   -0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>authority</th>       <td>    0.0458</td> <td>    0.320</td> <td>    0.143</td> <td> 0.886</td> <td>   -0.582</td> <td>    0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b60</th>             <td>    0.6211</td> <td>    0.653</td> <td>    0.952</td> <td> 0.341</td> <td>   -0.658</td> <td>    1.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b70</th>             <td>   -0.4283</td> <td>    1.072</td> <td>   -0.400</td> <td> 0.690</td> <td>   -2.530</td> <td>    1.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>backgrounded</th>    <td>   -0.0625</td> <td>    0.209</td> <td>   -0.300</td> <td> 0.764</td> <td>   -0.472</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>baker</th>           <td>   -0.1115</td> <td>    0.192</td> <td>   -0.581</td> <td> 0.562</td> <td>   -0.488</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>baking</th>          <td>    0.0024</td> <td>    0.198</td> <td>    0.012</td> <td> 0.990</td> <td>   -0.386</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>         <td>    1.4785</td> <td>    0.250</td> <td>    5.910</td> <td> 0.000</td> <td>    0.988</td> <td>    1.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balanced</th>        <td>    0.2373</td> <td>    0.104</td> <td>    2.284</td> <td> 0.022</td> <td>    0.034</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>banana</th>          <td>    0.3026</td> <td>    0.235</td> <td>    1.290</td> <td> 0.197</td> <td>   -0.157</td> <td>    0.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>barrel</th>          <td>   -0.3465</td> <td>    0.344</td> <td>   -1.007</td> <td> 0.314</td> <td>   -1.021</td> <td>    0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bean</th>            <td>   -0.3640</td> <td>    0.450</td> <td>   -0.808</td> <td> 0.419</td> <td>   -1.247</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bergamot</th>        <td>    0.4480</td> <td>    0.248</td> <td>    1.807</td> <td> 0.071</td> <td>   -0.038</td> <td>    0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>berries</th>         <td>    0.4101</td> <td>    0.400</td> <td>    1.026</td> <td> 0.305</td> <td>   -0.374</td> <td>    1.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>berry</th>           <td>    1.1547</td> <td>    0.183</td> <td>    6.294</td> <td> 0.000</td> <td>    0.795</td> <td>    1.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>best</th>            <td>    1.7546</td> <td>    0.449</td> <td>    3.907</td> <td> 0.000</td> <td>    0.874</td> <td>    2.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>big</th>             <td>    0.0408</td> <td>    0.184</td> <td>    0.222</td> <td> 0.824</td> <td>   -0.319</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bing</th>            <td>    0.2686</td> <td>    0.431</td> <td>    0.623</td> <td> 0.533</td> <td>   -0.576</td> <td>    1.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bit</th>             <td>   -0.4401</td> <td>    0.243</td> <td>   -1.812</td> <td> 0.070</td> <td>   -0.916</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitter</th>          <td>   -1.5936</td> <td>    0.375</td> <td>   -4.251</td> <td> 0.000</td> <td>   -2.328</td> <td>   -0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitterish</th>       <td>   -0.8191</td> <td>    0.295</td> <td>   -2.777</td> <td> 0.006</td> <td>   -1.398</td> <td>   -0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bitterness</th>      <td>    0.2898</td> <td>    0.416</td> <td>    0.696</td> <td> 0.486</td> <td>   -0.526</td> <td>    1.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bittersweet</th>     <td>   -0.2725</td> <td>    0.200</td> <td>   -1.361</td> <td> 0.174</td> <td>   -0.665</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>           <td>    0.4328</td> <td>    0.245</td> <td>    1.765</td> <td> 0.078</td> <td>   -0.048</td> <td>    0.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blackberry</th>      <td>    0.2889</td> <td>    0.221</td> <td>    1.310</td> <td> 0.190</td> <td>   -0.144</td> <td>    0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blend</th>           <td>   -0.0346</td> <td>    0.350</td> <td>   -0.099</td> <td> 0.921</td> <td>   -0.721</td> <td>    0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blood</th>           <td>    0.2485</td> <td>    0.253</td> <td>    0.983</td> <td> 0.326</td> <td>   -0.247</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bloom</th>           <td>    0.1975</td> <td>    0.389</td> <td>    0.508</td> <td> 0.612</td> <td>   -0.565</td> <td>    0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blooming</th>        <td>    0.0812</td> <td>    0.278</td> <td>    0.292</td> <td> 0.771</td> <td>   -0.465</td> <td>    0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blooms</th>          <td>   -0.0211</td> <td>    0.347</td> <td>   -0.061</td> <td> 0.951</td> <td>   -0.701</td> <td>    0.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blossom</th>         <td>    0.0340</td> <td>    0.248</td> <td>    0.137</td> <td> 0.891</td> <td>   -0.452</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blueberry</th>       <td>    0.3410</td> <td>    0.228</td> <td>    1.496</td> <td> 0.135</td> <td>   -0.106</td> <td>    0.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bodied</th>          <td>    0.8427</td> <td>    0.208</td> <td>    4.050</td> <td> 0.000</td> <td>    0.435</td> <td>    1.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>body.1</th>          <td>    0.4785</td> <td>    0.189</td> <td>    2.526</td> <td> 0.012</td> <td>    0.107</td> <td>    0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bracing</th>         <td>    0.8190</td> <td>    0.304</td> <td>    2.693</td> <td> 0.007</td> <td>    0.223</td> <td>    1.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brandy</th>          <td>    0.6242</td> <td>    0.285</td> <td>    2.193</td> <td> 0.028</td> <td>    0.066</td> <td>    1.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brandyish</th>       <td>    0.5980</td> <td>    0.354</td> <td>    1.691</td> <td> 0.091</td> <td>   -0.095</td> <td>    1.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brazil</th>          <td>   -0.0815</td> <td>    0.403</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.872</td> <td>    0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewed</th>          <td>    0.2239</td> <td>    1.044</td> <td>    0.214</td> <td> 0.830</td> <td>   -1.823</td> <td>    2.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewer</th>          <td>    1.7565</td> <td>    0.817</td> <td>    2.151</td> <td> 0.032</td> <td>    0.156</td> <td>    3.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brewing</th>         <td>   -1.6606</td> <td>    1.053</td> <td>   -1.578</td> <td> 0.115</td> <td>   -3.724</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bright</th>          <td>    0.2941</td> <td>    0.138</td> <td>    2.125</td> <td> 0.034</td> <td>    0.023</td> <td>    0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brightly</th>        <td>    0.1300</td> <td>    0.207</td> <td>    0.627</td> <td> 0.531</td> <td>   -0.277</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brightness</th>      <td>   -0.0383</td> <td>    0.440</td> <td>   -0.087</td> <td> 0.931</td> <td>   -0.900</td> <td>    0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brisk</th>           <td>   -0.0422</td> <td>    0.159</td> <td>   -0.265</td> <td> 0.791</td> <td>   -0.354</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>briskly</th>         <td>    0.1978</td> <td>    0.307</td> <td>    0.644</td> <td> 0.520</td> <td>   -0.405</td> <td>    0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brittle</th>         <td>    0.4597</td> <td>    0.287</td> <td>    1.601</td> <td> 0.109</td> <td>   -0.103</td> <td>    1.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brown</th>           <td>    1.5068</td> <td>    0.794</td> <td>    1.897</td> <td> 0.058</td> <td>   -0.051</td> <td>    3.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buoyant</th>         <td>   -0.0080</td> <td>    0.144</td> <td>   -0.055</td> <td> 0.956</td> <td>   -0.291</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buoyantly</th>       <td>    0.3691</td> <td>    0.339</td> <td>    1.087</td> <td> 0.277</td> <td>   -0.296</td> <td>    1.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>burned</th>          <td>   -1.5480</td> <td>    0.403</td> <td>   -3.845</td> <td> 0.000</td> <td>   -2.337</td> <td>   -0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>butter</th>          <td>    0.4950</td> <td>    0.165</td> <td>    3.005</td> <td> 0.003</td> <td>    0.172</td> <td>    0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>butterscotch</th>    <td>    0.8461</td> <td>    0.270</td> <td>    3.139</td> <td> 0.002</td> <td>    0.318</td> <td>    1.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>buttery</th>         <td>    0.4255</td> <td>    0.224</td> <td>    1.900</td> <td> 0.057</td> <td>   -0.013</td> <td>    0.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>byron</th>           <td>    0.9368</td> <td>    0.564</td> <td>    1.661</td> <td> 0.097</td> <td>   -0.169</td> <td>    2.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cacao</th>           <td>    0.1353</td> <td>    0.229</td> <td>    0.590</td> <td> 0.555</td> <td>   -0.315</td> <td>    0.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>called</th>          <td>    0.4328</td> <td>    0.513</td> <td>    0.844</td> <td> 0.399</td> <td>   -0.573</td> <td>    1.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>candied</th>         <td>    0.4442</td> <td>    0.245</td> <td>    1.811</td> <td> 0.070</td> <td>   -0.037</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>candy</th>           <td>    0.6525</td> <td>    0.428</td> <td>    1.524</td> <td> 0.128</td> <td>   -0.187</td> <td>    1.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cane</th>            <td>    0.8454</td> <td>    0.774</td> <td>    1.092</td> <td> 0.275</td> <td>   -0.672</td> <td>    2.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cappuccino</th>      <td>    0.7637</td> <td>    0.571</td> <td>    1.337</td> <td> 0.181</td> <td>   -0.356</td> <td>    1.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>capsule</th>         <td>   -1.2131</td> <td>    1.031</td> <td>   -1.176</td> <td> 0.239</td> <td>   -3.235</td> <td>    0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caramel</th>         <td>    0.0640</td> <td>    0.179</td> <td>    0.357</td> <td> 0.721</td> <td>   -0.288</td> <td>    0.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caramelly</th>       <td>    0.5240</td> <td>    0.291</td> <td>    1.800</td> <td> 0.072</td> <td>   -0.047</td> <td>    1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carbon</th>          <td>   -0.5481</td> <td>    0.449</td> <td>   -1.220</td> <td> 0.223</td> <td>   -1.429</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cardamom</th>        <td>    0.1440</td> <td>    0.405</td> <td>    0.356</td> <td> 0.722</td> <td>   -0.649</td> <td>    0.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carob</th>           <td>    0.2525</td> <td>    0.353</td> <td>    0.715</td> <td> 0.475</td> <td>   -0.440</td> <td>    0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carried</th>         <td>   -0.1601</td> <td>    0.316</td> <td>   -0.507</td> <td> 0.612</td> <td>   -0.780</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carries</th>         <td>    0.2321</td> <td>    0.175</td> <td>    1.330</td> <td> 0.184</td> <td>   -0.110</td> <td>    0.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carry</th>           <td>   -0.0775</td> <td>    0.109</td> <td>   -0.711</td> <td> 0.477</td> <td>   -0.291</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carrying</th>        <td>    0.1216</td> <td>    0.267</td> <td>    0.456</td> <td> 0.649</td> <td>   -0.401</td> <td>    0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cashew</th>          <td>    0.1068</td> <td>    0.224</td> <td>    0.476</td> <td> 0.634</td> <td>   -0.333</td> <td>    0.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cedar</th>           <td>    0.2738</td> <td>    0.125</td> <td>    2.192</td> <td> 0.028</td> <td>    0.029</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cedary</th>          <td>    0.2480</td> <td>    0.236</td> <td>    1.052</td> <td> 0.293</td> <td>   -0.214</td> <td>    0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>center</th>          <td>    0.1597</td> <td>    0.428</td> <td>    0.373</td> <td> 0.709</td> <td>   -0.679</td> <td>    0.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centered</th>        <td>    0.0144</td> <td>    0.209</td> <td>    0.069</td> <td> 0.945</td> <td>   -0.394</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>centers</th>         <td>    0.0635</td> <td>    0.135</td> <td>    0.470</td> <td> 0.638</td> <td>   -0.201</td> <td>    0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>character</th>       <td>    0.2563</td> <td>    0.229</td> <td>    1.120</td> <td> 0.263</td> <td>   -0.192</td> <td>    0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>charred</th>         <td>   -0.5275</td> <td>    0.362</td> <td>   -1.456</td> <td> 0.146</td> <td>   -1.238</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cherry</th>          <td>    0.4708</td> <td>    0.163</td> <td>    2.892</td> <td> 0.004</td> <td>    0.152</td> <td>    0.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cherryish</th>       <td>    1.4278</td> <td>    0.253</td> <td>    5.643</td> <td> 0.000</td> <td>    0.932</td> <td>    1.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chocolate</th>       <td>    0.7558</td> <td>    0.146</td> <td>    5.174</td> <td> 0.000</td> <td>    0.469</td> <td>    1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chocolaty</th>       <td>    0.3996</td> <td>    0.180</td> <td>    2.223</td> <td> 0.026</td> <td>    0.047</td> <td>    0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cinnamon</th>        <td>    0.2662</td> <td>    0.267</td> <td>    0.996</td> <td> 0.319</td> <td>   -0.258</td> <td>    0.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cited</th>           <td>    0.0031</td> <td>    0.518</td> <td>    0.006</td> <td> 0.995</td> <td>   -1.013</td> <td>    1.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citrus</th>          <td>    0.1601</td> <td>    0.174</td> <td>    0.920</td> <td> 0.358</td> <td>   -0.181</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citrusy</th>         <td>    0.2376</td> <td>    0.248</td> <td>    0.959</td> <td> 0.338</td> <td>   -0.248</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>classic</th>         <td>    0.3655</td> <td>    0.281</td> <td>    1.300</td> <td> 0.194</td> <td>   -0.186</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clean</th>           <td>    0.6244</td> <td>    0.204</td> <td>    3.062</td> <td> 0.002</td> <td>    0.225</td> <td>    1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cleanly</th>         <td>    0.5963</td> <td>    0.196</td> <td>    3.043</td> <td> 0.002</td> <td>    0.212</td> <td>    0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clear</th>           <td>    0.2571</td> <td>    0.355</td> <td>    0.724</td> <td> 0.469</td> <td>   -0.439</td> <td>    0.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clove</th>           <td>    0.2805</td> <td>    0.273</td> <td>    1.027</td> <td> 0.304</td> <td>   -0.255</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cocoa</th>           <td>    0.6052</td> <td>    0.163</td> <td>    3.707</td> <td> 0.000</td> <td>    0.285</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cocoaish</th>        <td>    0.1596</td> <td>    0.265</td> <td>    0.603</td> <td> 0.547</td> <td>   -0.359</td> <td>    0.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coconut</th>         <td>    0.4847</td> <td>    0.293</td> <td>    1.657</td> <td> 0.098</td> <td>   -0.089</td> <td>    1.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coffee</th>          <td>    0.4064</td> <td>    0.199</td> <td>    2.046</td> <td> 0.041</td> <td>    0.017</td> <td>    0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>coffees</th>         <td>    0.1868</td> <td>    0.394</td> <td>    0.474</td> <td> 0.635</td> <td>   -0.585</td> <td>    0.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cold</th>            <td>    2.0838</td> <td>    0.704</td> <td>    2.959</td> <td> 0.003</td> <td>    0.703</td> <td>    3.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complete</th>        <td>    0.5830</td> <td>    0.247</td> <td>    2.364</td> <td> 0.018</td> <td>    0.099</td> <td>    1.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complex</th>         <td>    0.5424</td> <td>    0.125</td> <td>    4.355</td> <td> 0.000</td> <td>    0.298</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complexity</th>      <td>    0.4614</td> <td>    0.255</td> <td>    1.809</td> <td> 0.071</td> <td>   -0.039</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complexly</th>       <td>    0.4802</td> <td>    0.211</td> <td>    2.279</td> <td> 0.023</td> <td>    0.067</td> <td>    0.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicate</th>      <td>   -0.3409</td> <td>    0.390</td> <td>   -0.874</td> <td> 0.382</td> <td>   -1.106</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicated</th>     <td>   -0.5547</td> <td>    0.168</td> <td>   -3.306</td> <td> 0.001</td> <td>   -0.884</td> <td>   -0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicates</th>     <td>    0.6191</td> <td>    0.348</td> <td>    1.777</td> <td> 0.076</td> <td>   -0.064</td> <td>    1.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complicating</th>    <td>   -0.0467</td> <td>    0.332</td> <td>   -0.140</td> <td> 0.888</td> <td>   -0.699</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complication</th>    <td>   -0.3345</td> <td>    0.260</td> <td>   -1.287</td> <td> 0.198</td> <td>   -0.844</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>complications</th>   <td>   -0.2008</td> <td>    0.278</td> <td>   -0.722</td> <td> 0.470</td> <td>   -0.746</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concord</th>         <td>    0.6028</td> <td>    0.381</td> <td>    1.583</td> <td> 0.113</td> <td>   -0.144</td> <td>    1.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>consolidates</th>    <td>    0.1458</td> <td>    0.108</td> <td>    1.352</td> <td> 0.177</td> <td>   -0.066</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>consolidating</th>   <td>    0.0421</td> <td>    0.272</td> <td>    0.155</td> <td> 0.877</td> <td>   -0.492</td> <td>    0.576</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>continued</th>       <td>    0.4276</td> <td>    0.187</td> <td>    2.284</td> <td> 0.022</td> <td>    0.061</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>continuing</th>      <td>   -0.0814</td> <td>    0.230</td> <td>   -0.354</td> <td> 0.723</td> <td>   -0.532</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cools</th>           <td>   -0.3132</td> <td>    0.226</td> <td>   -1.384</td> <td> 0.167</td> <td>   -0.757</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>creamy</th>          <td>   -0.0264</td> <td>    0.135</td> <td>   -0.196</td> <td> 0.845</td> <td>   -0.291</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crisp</th>           <td>    0.2117</td> <td>    0.123</td> <td>    1.718</td> <td> 0.086</td> <td>   -0.030</td> <td>    0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>crisply</th>         <td>    0.6254</td> <td>    0.246</td> <td>    2.538</td> <td> 0.011</td> <td>    0.142</td> <td>    1.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cupper</th>          <td>    0.3543</td> <td>    0.333</td> <td>    1.064</td> <td> 0.287</td> <td>   -0.299</td> <td>    1.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cupping</th>         <td>    0.1802</td> <td>    0.365</td> <td>    0.493</td> <td> 0.622</td> <td>   -0.536</td> <td>    0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cups</th>            <td>   -3.6663</td> <td>    0.480</td> <td>   -7.635</td> <td> 0.000</td> <td>   -4.608</td> <td>   -2.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>currant</th>         <td>    0.2962</td> <td>    0.238</td> <td>    1.246</td> <td> 0.213</td> <td>   -0.170</td> <td>    0.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut</th>             <td>    0.2715</td> <td>    0.225</td> <td>    1.205</td> <td> 0.228</td> <td>   -0.170</td> <td>    0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>            <td>   -0.2593</td> <td>    0.199</td> <td>   -1.302</td> <td> 0.193</td> <td>   -0.650</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>date</th>            <td>    0.4745</td> <td>    0.186</td> <td>    2.546</td> <td> 0.011</td> <td>    0.109</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deep</th>            <td>    0.4080</td> <td>    0.145</td> <td>    2.808</td> <td> 0.005</td> <td>    0.123</td> <td>    0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepen</th>          <td>   -0.1971</td> <td>    0.382</td> <td>   -0.516</td> <td> 0.606</td> <td>   -0.946</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepening</th>       <td>    0.6511</td> <td>    0.331</td> <td>    1.969</td> <td> 0.049</td> <td>    0.003</td> <td>    1.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deepens</th>         <td>    0.8888</td> <td>    0.271</td> <td>    3.281</td> <td> 0.001</td> <td>    0.358</td> <td>    1.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deeply</th>          <td>    0.4666</td> <td>    0.129</td> <td>    3.620</td> <td> 0.000</td> <td>    0.214</td> <td>    0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>delicate</th>        <td>    0.2693</td> <td>    0.165</td> <td>    1.628</td> <td> 0.104</td> <td>   -0.055</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>delicately</th>      <td>    0.3177</td> <td>    0.148</td> <td>    2.147</td> <td> 0.032</td> <td>    0.028</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>depth</th>           <td>    0.5919</td> <td>    0.328</td> <td>    1.807</td> <td> 0.071</td> <td>   -0.050</td> <td>    1.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>described</th>       <td>   -0.0629</td> <td>    0.476</td> <td>   -0.132</td> <td> 0.895</td> <td>   -0.995</td> <td>    0.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>device</th>          <td>    2.4385</td> <td>    1.297</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.104</td> <td>    4.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>did</th>             <td>    0.0176</td> <td>    0.532</td> <td>    0.033</td> <td> 0.974</td> <td>   -1.025</td> <td>    1.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dimension</th>       <td>   -0.9626</td> <td>    0.314</td> <td>   -3.070</td> <td> 0.002</td> <td>   -1.577</td> <td>   -0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>displays</th>        <td>   -0.1919</td> <td>    0.278</td> <td>   -0.690</td> <td> 0.491</td> <td>   -0.737</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinct</th>        <td>    0.2844</td> <td>    0.238</td> <td>    1.196</td> <td> 0.232</td> <td>   -0.182</td> <td>    0.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinctive</th>     <td>    0.2835</td> <td>    0.408</td> <td>    0.695</td> <td> 0.487</td> <td>   -0.516</td> <td>    1.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distinctly</th>      <td>   -0.2630</td> <td>    0.244</td> <td>   -1.076</td> <td> 0.282</td> <td>   -0.742</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominate</th>        <td>   -0.2726</td> <td>    0.168</td> <td>   -1.624</td> <td> 0.105</td> <td>   -0.602</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominated</th>       <td>    0.0258</td> <td>    0.236</td> <td>    0.110</td> <td> 0.913</td> <td>   -0.436</td> <td>    0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominates</th>       <td>    0.0546</td> <td>    0.208</td> <td>    0.262</td> <td> 0.793</td> <td>   -0.354</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dominating</th>      <td>    0.3023</td> <td>    0.341</td> <td>    0.886</td> <td> 0.376</td> <td>   -0.367</td> <td>    0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dried</th>           <td>    0.1876</td> <td>    0.144</td> <td>    1.305</td> <td> 0.192</td> <td>   -0.094</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drink</th>           <td>    0.7825</td> <td>    0.751</td> <td>    1.042</td> <td> 0.298</td> <td>   -0.690</td> <td>    2.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>driven</th>          <td>    0.0848</td> <td>    0.284</td> <td>    0.299</td> <td> 0.765</td> <td>   -0.472</td> <td>    0.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dry</th>             <td>   -0.1491</td> <td>    0.149</td> <td>   -0.999</td> <td> 0.318</td> <td>   -0.442</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drying</th>          <td>   -0.3595</td> <td>    0.123</td> <td>   -2.913</td> <td> 0.004</td> <td>   -0.601</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dusk</th>            <td>    0.5144</td> <td>    0.359</td> <td>    1.434</td> <td> 0.152</td> <td>   -0.189</td> <td>    1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earth</th>           <td>    0.9772</td> <td>    0.272</td> <td>    3.594</td> <td> 0.000</td> <td>    0.444</td> <td>    1.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>earthy</th>          <td>    0.4293</td> <td>    0.339</td> <td>    1.268</td> <td> 0.205</td> <td>   -0.234</td> <td>    1.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>edge</th>            <td>    0.3965</td> <td>    0.215</td> <td>    1.844</td> <td> 0.065</td> <td>   -0.025</td> <td>    0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>edged</th>           <td>    0.0179</td> <td>    0.311</td> <td>    0.058</td> <td> 0.954</td> <td>   -0.592</td> <td>    0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>effervescent</th>    <td>    0.6090</td> <td>    0.389</td> <td>    1.566</td> <td> 0.117</td> <td>   -0.153</td> <td>    1.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elegant</th>         <td>    0.6437</td> <td>    0.250</td> <td>    2.571</td> <td> 0.010</td> <td>    0.153</td> <td>    1.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>elegantly</th>       <td>    0.7405</td> <td>    0.229</td> <td>    3.231</td> <td> 0.001</td> <td>    0.291</td> <td>    1.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emerge</th>          <td>   -0.1342</td> <td>    0.345</td> <td>   -0.389</td> <td> 0.697</td> <td>   -0.811</td> <td>    0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emerges</th>         <td>    0.0020</td> <td>    0.269</td> <td>    0.007</td> <td> 0.994</td> <td>   -0.525</td> <td>    0.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engaging</th>        <td>    0.1087</td> <td>    0.314</td> <td>    0.347</td> <td> 0.729</td> <td>   -0.506</td> <td>    0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enveloped</th>       <td>    0.0828</td> <td>    0.314</td> <td>    0.264</td> <td> 0.792</td> <td>   -0.532</td> <td>    0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>espresso</th>        <td>    1.6112</td> <td>    0.475</td> <td>    3.391</td> <td> 0.001</td> <td>    0.680</td> <td>    2.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ethan</th>           <td>    1.1506</td> <td>    0.633</td> <td>    1.817</td> <td> 0.069</td> <td>   -0.091</td> <td>    2.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>evaluated</th>       <td>   -0.6210</td> <td>    0.299</td> <td>   -2.079</td> <td> 0.038</td> <td>   -1.207</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>excellent</th>       <td>    0.2839</td> <td>    0.345</td> <td>    0.822</td> <td> 0.411</td> <td>   -0.393</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exhilarating</th>    <td>    0.5049</td> <td>    0.321</td> <td>    1.574</td> <td> 0.116</td> <td>   -0.124</td> <td>    1.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exhilaratingly</th>  <td>    0.2347</td> <td>    0.384</td> <td>    0.610</td> <td> 0.542</td> <td>   -0.519</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exotic</th>          <td>    0.7387</td> <td>    0.318</td> <td>    2.324</td> <td> 0.020</td> <td>    0.115</td> <td>    1.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>explicit</th>        <td>    0.8840</td> <td>    0.370</td> <td>    2.390</td> <td> 0.017</td> <td>    0.159</td> <td>    1.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expressed</th>       <td>   -0.0333</td> <td>    0.277</td> <td>   -0.120</td> <td> 0.904</td> <td>   -0.577</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fade</th>            <td>    0.5925</td> <td>    0.304</td> <td>    1.948</td> <td> 0.051</td> <td>   -0.004</td> <td>    1.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fades</th>           <td>   -0.1829</td> <td>    0.282</td> <td>   -0.648</td> <td> 0.517</td> <td>   -0.736</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>faint</th>           <td>   -0.6428</td> <td>    0.257</td> <td>   -2.506</td> <td> 0.012</td> <td>   -1.146</td> <td>   -0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>faintly</th>         <td>   -0.6172</td> <td>    0.532</td> <td>   -1.159</td> <td> 0.246</td> <td>   -1.661</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fallen</th>          <td>   -0.2963</td> <td>    0.544</td> <td>   -0.544</td> <td> 0.586</td> <td>   -1.363</td> <td>    0.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>far</th>             <td>    0.3556</td> <td>    0.281</td> <td>    1.267</td> <td> 0.205</td> <td>   -0.195</td> <td>    0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>felt</th>            <td>   -0.5135</td> <td>    0.384</td> <td>   -1.336</td> <td> 0.182</td> <td>   -1.267</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ferment</th>         <td>   -1.2666</td> <td>    0.300</td> <td>   -4.219</td> <td> 0.000</td> <td>   -1.855</td> <td>   -0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fermented</th>       <td>   -1.3325</td> <td>    0.380</td> <td>   -3.504</td> <td> 0.000</td> <td>   -2.078</td> <td>   -0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fermenty</th>        <td>    0.2807</td> <td>    0.305</td> <td>    0.919</td> <td> 0.358</td> <td>   -0.318</td> <td>    0.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fig</th>             <td>    0.3738</td> <td>    0.358</td> <td>    1.044</td> <td> 0.297</td> <td>   -0.328</td> <td>    1.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fine</th>            <td>    0.3025</td> <td>    0.224</td> <td>    1.348</td> <td> 0.178</td> <td>   -0.137</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fir</th>             <td>   -0.0682</td> <td>    0.190</td> <td>   -0.359</td> <td> 0.719</td> <td>   -0.440</td> <td>    0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flat</th>            <td>   -2.4885</td> <td>    0.450</td> <td>   -5.529</td> <td> 0.000</td> <td>   -3.371</td> <td>   -1.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavor.1</th>        <td>   -0.2124</td> <td>    0.140</td> <td>   -1.517</td> <td> 0.129</td> <td>   -0.487</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flavors</th>         <td>   -0.2424</td> <td>    0.299</td> <td>   -0.811</td> <td> 0.417</td> <td>   -0.828</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floral</th>          <td>    0.6570</td> <td>    0.137</td> <td>    4.791</td> <td> 0.000</td> <td>    0.388</td> <td>    0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>florals</th>         <td>    0.1249</td> <td>    0.183</td> <td>    0.684</td> <td> 0.494</td> <td>   -0.233</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flower</th>          <td>    1.1551</td> <td>    0.372</td> <td>    3.103</td> <td> 0.002</td> <td>    0.425</td> <td>    1.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flowering</th>       <td>   -0.1221</td> <td>    0.553</td> <td>   -0.221</td> <td> 0.825</td> <td>   -1.206</td> <td>    0.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flowers</th>         <td>    0.7282</td> <td>    0.154</td> <td>    4.737</td> <td> 0.000</td> <td>    0.427</td> <td>    1.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>forward</th>         <td>   -0.2171</td> <td>    0.209</td> <td>   -1.038</td> <td> 0.299</td> <td>   -0.627</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fragrant</th>        <td>    0.7763</td> <td>    0.325</td> <td>    2.388</td> <td> 0.017</td> <td>    0.139</td> <td>    1.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>framed</th>          <td>    0.1635</td> <td>    0.286</td> <td>    0.572</td> <td> 0.567</td> <td>   -0.397</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frankincense</th>    <td>    0.2050</td> <td>    0.253</td> <td>    0.811</td> <td> 0.417</td> <td>   -0.291</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freesia</th>         <td>    0.2752</td> <td>    0.204</td> <td>    1.350</td> <td> 0.177</td> <td>   -0.124</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh</th>           <td>   -0.2731</td> <td>    0.347</td> <td>   -0.787</td> <td> 0.432</td> <td>   -0.954</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fruit</th>           <td>    0.4583</td> <td>    0.153</td> <td>    2.995</td> <td> 0.003</td> <td>    0.158</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fruity</th>          <td>    0.3838</td> <td>    0.220</td> <td>    1.741</td> <td> 0.082</td> <td>   -0.048</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fudge</th>           <td>    0.2744</td> <td>    0.236</td> <td>    1.164</td> <td> 0.245</td> <td>   -0.188</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gardenia</th>        <td>    0.2398</td> <td>    0.226</td> <td>    1.059</td> <td> 0.290</td> <td>   -0.204</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gentle</th>          <td>    0.2302</td> <td>    0.127</td> <td>    1.819</td> <td> 0.069</td> <td>   -0.018</td> <td>    0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gently</th>          <td>    0.2925</td> <td>    0.128</td> <td>    2.292</td> <td> 0.022</td> <td>    0.042</td> <td>    0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ginger</th>          <td>    0.1827</td> <td>    0.309</td> <td>    0.591</td> <td> 0.554</td> <td>   -0.423</td> <td>    0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>good</th>            <td>   -0.3029</td> <td>    0.258</td> <td>   -1.174</td> <td> 0.240</td> <td>   -0.809</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grace</th>           <td>    0.0877</td> <td>    0.397</td> <td>    0.221</td> <td> 0.825</td> <td>   -0.691</td> <td>    0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grape</th>           <td>    0.1559</td> <td>    0.255</td> <td>    0.611</td> <td> 0.541</td> <td>   -0.344</td> <td>    0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grapefruit</th>      <td>    0.3868</td> <td>    0.195</td> <td>    1.984</td> <td> 0.047</td> <td>    0.005</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grappa</th>          <td>    0.6817</td> <td>    0.411</td> <td>    1.660</td> <td> 0.097</td> <td>   -0.123</td> <td>    1.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grass</th>           <td>    0.7948</td> <td>    0.496</td> <td>    1.604</td> <td> 0.109</td> <td>   -0.177</td> <td>    1.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>great</th>           <td>    0.5280</td> <td>    0.335</td> <td>    1.577</td> <td> 0.115</td> <td>   -0.129</td> <td>    1.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>green</th>           <td>   -0.0395</td> <td>    0.301</td> <td>   -0.131</td> <td> 0.896</td> <td>   -0.629</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>guava</th>           <td>    0.3908</td> <td>    0.275</td> <td>    1.421</td> <td> 0.155</td> <td>   -0.148</td> <td>    0.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hard</th>            <td>   -3.3345</td> <td>    0.414</td> <td>   -8.055</td> <td> 0.000</td> <td>   -4.146</td> <td>   -2.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hazelnut</th>        <td>    0.2785</td> <td>    0.156</td> <td>    1.789</td> <td> 0.074</td> <td>   -0.027</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>heavy</th>           <td>   -0.4674</td> <td>    0.254</td> <td>   -1.837</td> <td> 0.066</td> <td>   -0.966</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herb</th>            <td>    0.7265</td> <td>    0.314</td> <td>    2.313</td> <td> 0.021</td> <td>    0.111</td> <td>    1.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herbaceous</th>      <td>    0.1439</td> <td>    0.271</td> <td>    0.530</td> <td> 0.596</td> <td>   -0.388</td> <td>    0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>herby</th>           <td>   -0.3071</td> <td>    0.338</td> <td>   -0.907</td> <td> 0.364</td> <td>   -0.971</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hibiscus</th>        <td>   -0.0081</td> <td>    0.327</td> <td>   -0.025</td> <td> 0.980</td> <td>   -0.650</td> <td>    0.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>high</th>            <td>    0.7567</td> <td>    0.182</td> <td>    4.160</td> <td> 0.000</td> <td>    0.400</td> <td>    1.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hint</th>            <td>    0.1173</td> <td>    0.138</td> <td>    0.850</td> <td> 0.395</td> <td>   -0.153</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hints</th>           <td>    0.0445</td> <td>    0.173</td> <td>    0.258</td> <td> 0.797</td> <td>   -0.294</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honey</th>           <td>    0.5681</td> <td>    0.180</td> <td>    3.164</td> <td> 0.002</td> <td>    0.216</td> <td>    0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honeyish</th>        <td>    0.9190</td> <td>    0.365</td> <td>    2.516</td> <td> 0.012</td> <td>    0.203</td> <td>    1.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honeysuckle</th>     <td>    0.2940</td> <td>    0.211</td> <td>    1.392</td> <td> 0.164</td> <td>   -0.120</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hop</th>             <td>    0.1418</td> <td>    0.285</td> <td>    0.497</td> <td> 0.619</td> <td>   -0.418</td> <td>    0.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hot</th>             <td>   -0.8638</td> <td>    0.410</td> <td>   -2.108</td> <td> 0.035</td> <td>   -1.667</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impression</th>      <td>    2.0986</td> <td>    0.498</td> <td>    4.217</td> <td> 0.000</td> <td>    1.123</td> <td>    3.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impressive</th>      <td>    0.5438</td> <td>    0.238</td> <td>    2.280</td> <td> 0.023</td> <td>    0.076</td> <td>    1.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>impressively</th>    <td>    0.4533</td> <td>    0.243</td> <td>    1.863</td> <td> 0.063</td> <td>   -0.024</td> <td>    0.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>influenced</th>      <td>    0.5640</td> <td>    0.414</td> <td>    1.364</td> <td> 0.173</td> <td>   -0.247</td> <td>    1.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>integrated</th>      <td>    0.4379</td> <td>    0.302</td> <td>    1.451</td> <td> 0.147</td> <td>   -0.154</td> <td>    1.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intense</th>         <td>    0.4143</td> <td>    0.192</td> <td>    2.156</td> <td> 0.031</td> <td>    0.038</td> <td>    0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intensely</th>       <td>    0.2051</td> <td>    0.236</td> <td>    0.868</td> <td> 0.385</td> <td>   -0.258</td> <td>    0.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intensity</th>       <td>   -0.2896</td> <td>    0.456</td> <td>   -0.636</td> <td> 0.525</td> <td>   -1.183</td> <td>    0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interesting</th>     <td>   -1.0493</td> <td>    0.388</td> <td>   -2.703</td> <td> 0.007</td> <td>   -1.810</td> <td>   -0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intricate</th>       <td>    0.2443</td> <td>    0.183</td> <td>    1.337</td> <td> 0.181</td> <td>   -0.114</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intricately</th>     <td>    0.2900</td> <td>    0.241</td> <td>    1.205</td> <td> 0.228</td> <td>   -0.182</td> <td>    0.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intrigue</th>        <td>   -1.0265</td> <td>    0.363</td> <td>   -2.831</td> <td> 0.005</td> <td>   -1.737</td> <td>   -0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intriguing</th>      <td>    0.1489</td> <td>    0.327</td> <td>    0.456</td> <td> 0.648</td> <td>   -0.491</td> <td>    0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jam</th>             <td>    0.3998</td> <td>    0.419</td> <td>    0.955</td> <td> 0.340</td> <td>   -0.421</td> <td>    1.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jasmine</th>         <td>    0.3228</td> <td>    0.186</td> <td>    1.735</td> <td> 0.083</td> <td>   -0.042</td> <td>    0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jim</th>             <td>    1.7494</td> <td>    0.642</td> <td>    2.725</td> <td> 0.006</td> <td>    0.491</td> <td>    3.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>juicy</th>           <td>    0.2147</td> <td>    0.141</td> <td>    1.522</td> <td> 0.128</td> <td>   -0.062</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>just</th>            <td>    0.1313</td> <td>    0.384</td> <td>    0.342</td> <td> 0.733</td> <td>   -0.622</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ken</th>             <td>   -0.5341</td> <td>    0.393</td> <td>   -1.359</td> <td> 0.174</td> <td>   -1.304</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>kenya</th>           <td>    1.9577</td> <td>    0.398</td> <td>    4.919</td> <td> 0.000</td> <td>    1.177</td> <td>    2.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>keurig</th>          <td>    0.8358</td> <td>    0.719</td> <td>    1.163</td> <td> 0.245</td> <td>   -0.573</td> <td>    2.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>key</th>             <td>   -0.6026</td> <td>    0.398</td> <td>   -1.512</td> <td> 0.131</td> <td>   -1.384</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>knit</th>            <td>    1.5100</td> <td>    0.549</td> <td>    2.748</td> <td> 0.006</td> <td>    0.433</td> <td>    2.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>laden</th>           <td>    0.3361</td> <td>    0.237</td> <td>    1.415</td> <td> 0.157</td> <td>   -0.129</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lavender</th>        <td>    0.2097</td> <td>    0.178</td> <td>    1.177</td> <td> 0.239</td> <td>   -0.140</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>layered</th>         <td>    0.0465</td> <td>    0.267</td> <td>    0.174</td> <td> 0.862</td> <td>   -0.476</td> <td>    0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>layers</th>          <td>    0.6325</td> <td>    0.377</td> <td>    1.677</td> <td> 0.094</td> <td>   -0.107</td> <td>    1.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lead</th>            <td>    0.0311</td> <td>    0.249</td> <td>    0.125</td> <td> 0.901</td> <td>   -0.457</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leads</th>           <td>    0.0706</td> <td>    0.180</td> <td>    0.393</td> <td> 0.694</td> <td>   -0.282</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaf</th>            <td>    0.3050</td> <td>    0.384</td> <td>    0.793</td> <td> 0.428</td> <td>   -0.449</td> <td>    1.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lean</th>            <td>   -0.7622</td> <td>    0.306</td> <td>   -2.493</td> <td> 0.013</td> <td>   -1.362</td> <td>   -0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaning</th>         <td>    0.1476</td> <td>    0.234</td> <td>    0.630</td> <td> 0.529</td> <td>   -0.312</td> <td>    0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leanish</th>         <td>   -0.4198</td> <td>    0.329</td> <td>   -1.277</td> <td> 0.202</td> <td>   -1.064</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leather</th>         <td>    0.6368</td> <td>    0.441</td> <td>    1.445</td> <td> 0.149</td> <td>   -0.227</td> <td>    1.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leaves</th>          <td>    0.9602</td> <td>    0.554</td> <td>    1.732</td> <td> 0.083</td> <td>   -0.127</td> <td>    2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lemon</th>           <td>    0.3187</td> <td>    0.164</td> <td>    1.946</td> <td> 0.052</td> <td>   -0.002</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lemongrass</th>      <td>    0.4557</td> <td>    0.411</td> <td>    1.108</td> <td> 0.268</td> <td>   -0.350</td> <td>    1.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lemony</th>          <td>    0.6423</td> <td>    0.232</td> <td>    2.765</td> <td> 0.006</td> <td>    0.187</td> <td>    1.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>licorice</th>        <td>    0.4611</td> <td>    0.510</td> <td>    0.904</td> <td> 0.366</td> <td>   -0.539</td> <td>    1.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>light</th>           <td>   -0.2469</td> <td>    0.196</td> <td>   -1.262</td> <td> 0.207</td> <td>   -0.630</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lightly</th>         <td>   -0.1254</td> <td>    0.155</td> <td>   -0.812</td> <td> 0.417</td> <td>   -0.428</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>like</th>            <td>   -0.3822</td> <td>    0.136</td> <td>   -2.805</td> <td> 0.005</td> <td>   -0.649</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lilac</th>           <td>    0.2712</td> <td>    0.191</td> <td>    1.422</td> <td> 0.155</td> <td>   -0.103</td> <td>    0.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lily</th>            <td>    0.1809</td> <td>    0.182</td> <td>    0.992</td> <td> 0.321</td> <td>   -0.177</td> <td>    0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lime</th>            <td>    0.2623</td> <td>    0.242</td> <td>    1.085</td> <td> 0.278</td> <td>   -0.212</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>limited</th>         <td>   -1.1383</td> <td>    0.455</td> <td>   -2.504</td> <td> 0.012</td> <td>   -2.030</td> <td>   -0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>linger</th>          <td>    0.3480</td> <td>    0.264</td> <td>    1.317</td> <td> 0.188</td> <td>   -0.170</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lingering</th>       <td>   -0.1287</td> <td>    0.211</td> <td>   -0.609</td> <td> 0.542</td> <td>   -0.543</td> <td>    0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lingers</th>         <td>    0.3097</td> <td>    0.291</td> <td>    1.064</td> <td> 0.287</td> <td>   -0.261</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>little</th>          <td>   -0.1523</td> <td>    0.292</td> <td>   -0.521</td> <td> 0.602</td> <td>   -0.725</td> <td>    0.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lively</th>          <td>    0.0480</td> <td>    0.141</td> <td>    0.340</td> <td> 0.734</td> <td>   -0.229</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>long</th>            <td>    0.6421</td> <td>    0.133</td> <td>    4.821</td> <td> 0.000</td> <td>    0.381</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lovely</th>          <td>   -0.0940</td> <td>    0.426</td> <td>   -0.221</td> <td> 0.825</td> <td>   -0.929</td> <td>    0.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>low</th>             <td>    0.8690</td> <td>    0.225</td> <td>    3.855</td> <td> 0.000</td> <td>    0.427</td> <td>    1.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lush</th>            <td>    0.4356</td> <td>    0.147</td> <td>    2.964</td> <td> 0.003</td> <td>    0.147</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lushly</th>          <td>    1.0126</td> <td>    0.265</td> <td>    3.825</td> <td> 0.000</td> <td>    0.494</td> <td>    1.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lychee</th>          <td>    0.5118</td> <td>    0.254</td> <td>    2.014</td> <td> 0.044</td> <td>    0.014</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lyric</th>           <td>    0.4797</td> <td>    0.332</td> <td>    1.443</td> <td> 0.149</td> <td>   -0.172</td> <td>    1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lyrical</th>         <td>    0.4321</td> <td>    0.338</td> <td>    1.279</td> <td> 0.201</td> <td>   -0.230</td> <td>    1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lyrically</th>       <td>    0.6829</td> <td>    0.270</td> <td>    2.529</td> <td> 0.011</td> <td>    0.153</td> <td>    1.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>macadamia</th>       <td>    0.4240</td> <td>    0.409</td> <td>    1.037</td> <td> 0.300</td> <td>   -0.377</td> <td>    1.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>magnolia</th>        <td>    0.2010</td> <td>    0.183</td> <td>    1.098</td> <td> 0.272</td> <td>   -0.158</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>maintains</th>       <td>    0.3764</td> <td>    0.303</td> <td>    1.241</td> <td> 0.215</td> <td>   -0.218</td> <td>    0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>malt</th>            <td>    0.3415</td> <td>    0.465</td> <td>    0.734</td> <td> 0.463</td> <td>   -0.570</td> <td>    1.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>malty</th>           <td>    0.5710</td> <td>    0.420</td> <td>    1.359</td> <td> 0.174</td> <td>   -0.253</td> <td>    1.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mango</th>           <td>    0.4301</td> <td>    0.232</td> <td>    1.854</td> <td> 0.064</td> <td>   -0.025</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>maple</th>           <td>    1.7372</td> <td>    0.654</td> <td>    2.657</td> <td> 0.008</td> <td>    0.456</td> <td>    3.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marjoram</th>        <td>    0.4229</td> <td>    0.250</td> <td>    1.694</td> <td> 0.090</td> <td>   -0.067</td> <td>    0.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>medium</th>          <td>    0.1620</td> <td>    0.174</td> <td>    0.932</td> <td> 0.351</td> <td>   -0.179</td> <td>    0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>melon</th>           <td>    0.3095</td> <td>    0.322</td> <td>    0.961</td> <td> 0.337</td> <td>   -0.322</td> <td>    0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mesquite</th>        <td>    0.2190</td> <td>    0.439</td> <td>    0.499</td> <td> 0.618</td> <td>   -0.642</td> <td>    1.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>meyer</th>           <td>    0.2591</td> <td>    0.331</td> <td>    0.784</td> <td> 0.433</td> <td>   -0.389</td> <td>    0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mid</th>             <td>    0.5485</td> <td>    0.381</td> <td>    1.439</td> <td> 0.150</td> <td>   -0.199</td> <td>    1.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>miguel</th>          <td>    1.1495</td> <td>    0.561</td> <td>    2.049</td> <td> 0.041</td> <td>    0.050</td> <td>    2.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mild</th>            <td>   -1.0126</td> <td>    0.385</td> <td>   -2.628</td> <td> 0.009</td> <td>   -1.768</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mildly</th>          <td>   -0.1861</td> <td>    0.236</td> <td>   -0.788</td> <td> 0.431</td> <td>   -0.649</td> <td>    0.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>milk</th>            <td>    0.0859</td> <td>    0.234</td> <td>    0.368</td> <td> 0.713</td> <td>   -0.372</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mint</th>            <td>    0.2454</td> <td>    0.463</td> <td>    0.531</td> <td> 0.596</td> <td>   -0.661</td> <td>    1.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minty</th>           <td>    0.0538</td> <td>    0.369</td> <td>    0.146</td> <td> 0.884</td> <td>   -0.669</td> <td>    0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>moist</th>           <td>    0.1449</td> <td>    0.327</td> <td>    0.443</td> <td> 0.658</td> <td>   -0.496</td> <td>    0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>molasses</th>        <td>    0.4025</td> <td>    0.195</td> <td>    2.063</td> <td> 0.039</td> <td>    0.020</td> <td>    0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mulberry</th>        <td>    0.4285</td> <td>    0.278</td> <td>    1.543</td> <td> 0.123</td> <td>   -0.116</td> <td>    0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>multi</th>           <td>    0.3100</td> <td>    0.241</td> <td>    1.286</td> <td> 0.199</td> <td>   -0.163</td> <td>    0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mushroom</th>        <td>    0.4174</td> <td>    0.337</td> <td>    1.239</td> <td> 0.215</td> <td>   -0.243</td> <td>    1.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musk</th>            <td>    0.2553</td> <td>    0.295</td> <td>    0.864</td> <td> 0.387</td> <td>   -0.324</td> <td>    0.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musky</th>           <td>    0.2093</td> <td>    0.443</td> <td>    0.473</td> <td> 0.636</td> <td>   -0.659</td> <td>    1.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mustiness</th>       <td>   -1.1697</td> <td>    0.472</td> <td>   -2.477</td> <td> 0.013</td> <td>   -2.096</td> <td>   -0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>musty</th>           <td>   -0.3256</td> <td>    0.400</td> <td>   -0.813</td> <td> 0.416</td> <td>   -1.110</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>muted</th>           <td>   -0.1715</td> <td>    0.232</td> <td>   -0.740</td> <td> 0.460</td> <td>   -0.626</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>myrrh</th>           <td>    0.3363</td> <td>    0.253</td> <td>    1.329</td> <td> 0.184</td> <td>   -0.160</td> <td>    0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>narcissus</th>       <td>    0.3465</td> <td>    0.180</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.006</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nectar</th>          <td>    0.1426</td> <td>    0.361</td> <td>    0.395</td> <td> 0.693</td> <td>   -0.565</td> <td>    0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nectarine</th>       <td>    0.4366</td> <td>    0.329</td> <td>    1.327</td> <td> 0.185</td> <td>   -0.208</td> <td>    1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nib</th>             <td>   -0.0014</td> <td>    0.172</td> <td>   -0.008</td> <td> 0.994</td> <td>   -0.339</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nice</th>            <td>   -1.8046</td> <td>    0.602</td> <td>   -2.998</td> <td> 0.003</td> <td>   -2.985</td> <td>   -0.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nicely</th>          <td>    0.5095</td> <td>    0.239</td> <td>    2.132</td> <td> 0.033</td> <td>    0.041</td> <td>    0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night</th>           <td>   -0.1596</td> <td>    0.246</td> <td>   -0.648</td> <td> 0.517</td> <td>   -0.643</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nominated</th>       <td>    0.4637</td> <td>    0.413</td> <td>    1.124</td> <td> 0.261</td> <td>   -0.345</td> <td>    1.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nose</th>            <td>   -0.5167</td> <td>    0.260</td> <td>   -1.986</td> <td> 0.047</td> <td>   -1.027</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>note</th>            <td>   -0.1797</td> <td>    0.182</td> <td>   -0.988</td> <td> 0.323</td> <td>   -0.536</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>notes</th>           <td>    0.2977</td> <td>    0.143</td> <td>    2.084</td> <td> 0.037</td> <td>    0.018</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nougat</th>          <td>    0.2464</td> <td>    0.227</td> <td>    1.084</td> <td> 0.279</td> <td>   -0.199</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuance</th>          <td>    0.2310</td> <td>    0.259</td> <td>    0.892</td> <td> 0.372</td> <td>   -0.277</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuanced</th>         <td>    0.3055</td> <td>    0.220</td> <td>    1.386</td> <td> 0.166</td> <td>   -0.127</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nut</th>             <td>    0.0419</td> <td>    0.133</td> <td>    0.315</td> <td> 0.753</td> <td>   -0.219</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutella</th>         <td>    0.7505</td> <td>    0.419</td> <td>    1.791</td> <td> 0.073</td> <td>   -0.071</td> <td>    1.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutmeg</th>          <td>    0.4901</td> <td>    0.362</td> <td>    1.353</td> <td> 0.176</td> <td>   -0.220</td> <td>    1.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nuts</th>            <td>   -1.1144</td> <td>    0.441</td> <td>   -2.525</td> <td> 0.012</td> <td>   -1.980</td> <td>   -0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nutty</th>           <td>   -0.0240</td> <td>    0.243</td> <td>   -0.099</td> <td> 0.921</td> <td>   -0.501</td> <td>    0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oak</th>             <td>    0.2704</td> <td>    0.170</td> <td>    1.593</td> <td> 0.111</td> <td>   -0.062</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opulent</th>         <td>    0.5892</td> <td>    0.292</td> <td>    2.016</td> <td> 0.044</td> <td>    0.016</td> <td>    1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orange</th>          <td>    0.4146</td> <td>    0.154</td> <td>    2.685</td> <td> 0.007</td> <td>    0.112</td> <td>    0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orangy</th>          <td>    0.2591</td> <td>    0.266</td> <td>    0.973</td> <td> 0.331</td> <td>   -0.263</td> <td>    0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>orchid</th>          <td>    0.4506</td> <td>    0.397</td> <td>    1.136</td> <td> 0.256</td> <td>   -0.327</td> <td>    1.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>original</th>        <td>    0.2300</td> <td>    0.298</td> <td>    0.771</td> <td> 0.441</td> <td>   -0.355</td> <td>    0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ounce</th>           <td>    0.4106</td> <td>    0.994</td> <td>    0.413</td> <td> 0.680</td> <td>   -1.538</td> <td>    2.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ounces</th>          <td>   -1.6078</td> <td>    0.729</td> <td>   -2.204</td> <td> 0.028</td> <td>   -3.038</td> <td>   -0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overall</th>         <td>    0.3111</td> <td>    0.445</td> <td>    0.700</td> <td> 0.484</td> <td>   -0.561</td> <td>    1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overripe</th>        <td>    0.4541</td> <td>    0.427</td> <td>    1.063</td> <td> 0.288</td> <td>   -0.383</td> <td>    1.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>owing</th>           <td>    0.0036</td> <td>    0.474</td> <td>    0.008</td> <td> 0.994</td> <td>   -0.926</td> <td>    0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>panelists</th>       <td>    0.4273</td> <td>    0.476</td> <td>    0.897</td> <td> 0.370</td> <td>   -0.506</td> <td>    1.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>papaya</th>          <td>    0.2742</td> <td>    0.349</td> <td>    0.785</td> <td> 0.432</td> <td>   -0.410</td> <td>    0.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>particular</th>      <td>    0.0948</td> <td>    0.197</td> <td>    0.482</td> <td> 0.630</td> <td>   -0.291</td> <td>    0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>particularly</th>    <td>   -0.2992</td> <td>    0.266</td> <td>   -1.123</td> <td> 0.261</td> <td>   -0.821</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parts</th>           <td>    0.3228</td> <td>    0.270</td> <td>    1.198</td> <td> 0.231</td> <td>   -0.206</td> <td>    0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passion</th>         <td>    0.0773</td> <td>    0.404</td> <td>    0.192</td> <td> 0.848</td> <td>   -0.714</td> <td>    0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passionfruit</th>    <td>    0.3121</td> <td>    0.426</td> <td>    0.732</td> <td> 0.464</td> <td>   -0.523</td> <td>    1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peach</th>           <td>    0.2914</td> <td>    0.171</td> <td>    1.708</td> <td> 0.088</td> <td>   -0.043</td> <td>    0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pear</th>            <td>    0.6819</td> <td>    0.221</td> <td>    3.091</td> <td> 0.002</td> <td>    0.249</td> <td>    1.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pecan</th>           <td>   -0.1664</td> <td>    0.317</td> <td>   -0.524</td> <td> 0.600</td> <td>   -0.789</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peppercorn</th>      <td>    0.5412</td> <td>    0.272</td> <td>    1.986</td> <td> 0.047</td> <td>    0.007</td> <td>    1.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perfumy</th>         <td>    0.4932</td> <td>    0.336</td> <td>    1.469</td> <td> 0.142</td> <td>   -0.165</td> <td>    1.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persimmon</th>       <td>    0.7759</td> <td>    0.322</td> <td>    2.410</td> <td> 0.016</td> <td>    0.145</td> <td>    1.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persist</th>         <td>    0.2433</td> <td>    0.218</td> <td>    1.115</td> <td> 0.265</td> <td>   -0.185</td> <td>    0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persistence</th>     <td>    0.6243</td> <td>    0.340</td> <td>    1.835</td> <td> 0.067</td> <td>   -0.043</td> <td>    1.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persistent</th>      <td>    0.0498</td> <td>    0.351</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.639</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persists</th>        <td>    0.0200</td> <td>    0.211</td> <td>    0.095</td> <td> 0.924</td> <td>   -0.394</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pert</th>            <td>    0.0912</td> <td>    0.236</td> <td>    0.386</td> <td> 0.699</td> <td>   -0.371</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pie</th>             <td>    0.4526</td> <td>    0.432</td> <td>    1.048</td> <td> 0.295</td> <td>   -0.394</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pine</th>            <td>    0.3135</td> <td>    0.339</td> <td>    0.925</td> <td> 0.355</td> <td>   -0.351</td> <td>    0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pineapple</th>       <td>    0.4108</td> <td>    0.256</td> <td>    1.605</td> <td> 0.109</td> <td>   -0.091</td> <td>    0.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pink</th>            <td>    0.0737</td> <td>    0.237</td> <td>    0.311</td> <td> 0.756</td> <td>   -0.390</td> <td>    0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pipe</th>            <td>    0.3268</td> <td>    0.392</td> <td>    0.834</td> <td> 0.404</td> <td>   -0.442</td> <td>    1.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pistachio</th>       <td>    0.2325</td> <td>    0.277</td> <td>    0.840</td> <td> 0.401</td> <td>   -0.310</td> <td>    0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>platinum</th>        <td>    0.0461</td> <td>    1.173</td> <td>    0.039</td> <td> 0.969</td> <td>   -2.255</td> <td>    2.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasant</th>        <td>    0.4653</td> <td>    0.372</td> <td>    1.250</td> <td> 0.212</td> <td>   -0.265</td> <td>    1.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasantly</th>      <td>    0.3728</td> <td>    0.208</td> <td>    1.792</td> <td> 0.073</td> <td>   -0.035</td> <td>    0.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasing</th>        <td>    0.0391</td> <td>    0.203</td> <td>    0.192</td> <td> 0.847</td> <td>   -0.359</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pleasingly</th>      <td>    0.0069</td> <td>    0.241</td> <td>    0.029</td> <td> 0.977</td> <td>   -0.467</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plum</th>            <td>    0.2073</td> <td>    0.172</td> <td>    1.208</td> <td> 0.227</td> <td>   -0.129</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plumeria</th>        <td>    0.7630</td> <td>    0.346</td> <td>    2.204</td> <td> 0.028</td> <td>    0.084</td> <td>    1.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plump</th>           <td>    0.1423</td> <td>    0.203</td> <td>    0.702</td> <td> 0.483</td> <td>   -0.255</td> <td>    0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plush</th>           <td>   -0.0531</td> <td>    0.115</td> <td>   -0.460</td> <td> 0.646</td> <td>   -0.279</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pod</th>             <td>   -1.0049</td> <td>    0.791</td> <td>   -1.271</td> <td> 0.204</td> <td>   -2.555</td> <td>    0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pomegranate</th>     <td>    0.5843</td> <td>    0.235</td> <td>    2.482</td> <td> 0.013</td> <td>    0.123</td> <td>    1.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>powder</th>          <td>   -0.0897</td> <td>    0.257</td> <td>   -0.349</td> <td> 0.727</td> <td>   -0.593</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>power</th>           <td>   -0.0640</td> <td>    0.442</td> <td>   -0.145</td> <td> 0.885</td> <td>   -0.930</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>powerful</th>        <td>    0.7669</td> <td>    0.328</td> <td>    2.337</td> <td> 0.019</td> <td>    0.124</td> <td>    1.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>presence</th>        <td>    0.1709</td> <td>    0.271</td> <td>    0.630</td> <td> 0.529</td> <td>   -0.361</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pretty</th>          <td>    0.1807</td> <td>    0.307</td> <td>    0.588</td> <td> 0.557</td> <td>   -0.422</td> <td>    0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>produce</th>         <td>    0.2836</td> <td>    0.727</td> <td>    0.390</td> <td> 0.696</td> <td>   -1.141</td> <td>    1.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>produced</th>        <td>   -1.7364</td> <td>    0.616</td> <td>   -2.817</td> <td> 0.005</td> <td>   -2.945</td> <td>   -0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>profile</th>         <td>    0.2918</td> <td>    0.232</td> <td>    1.259</td> <td> 0.208</td> <td>   -0.163</td> <td>    0.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>promise</th>         <td>    0.0209</td> <td>    0.317</td> <td>    0.066</td> <td> 0.948</td> <td>   -0.601</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pronounced</th>      <td>    0.4512</td> <td>    0.276</td> <td>    1.635</td> <td> 0.102</td> <td>   -0.090</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prune</th>           <td>   -0.6778</td> <td>    0.319</td> <td>   -2.126</td> <td> 0.034</td> <td>   -1.303</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pruny</th>           <td>   -2.6363</td> <td>    0.390</td> <td>   -6.766</td> <td> 0.000</td> <td>   -3.400</td> <td>   -1.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungency</th>        <td>    0.6388</td> <td>    0.278</td> <td>    2.296</td> <td> 0.022</td> <td>    0.093</td> <td>    1.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungent</th>         <td>    0.2657</td> <td>    0.149</td> <td>    1.786</td> <td> 0.074</td> <td>   -0.026</td> <td>    0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pungently</th>       <td>    0.5754</td> <td>    0.306</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.025</td> <td>    1.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pure</th>            <td>    0.7187</td> <td>    0.249</td> <td>    2.886</td> <td> 0.004</td> <td>    0.230</td> <td>    1.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quickly</th>         <td>    0.0481</td> <td>    0.422</td> <td>    0.114</td> <td> 0.909</td> <td>   -0.780</td> <td>    0.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quiet</th>           <td>    0.2291</td> <td>    0.172</td> <td>    1.328</td> <td> 0.184</td> <td>   -0.109</td> <td>    0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quietly</th>         <td>    0.3367</td> <td>    0.155</td> <td>    2.174</td> <td> 0.030</td> <td>    0.033</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quite</th>           <td>    0.0664</td> <td>    0.284</td> <td>    0.234</td> <td> 0.815</td> <td>   -0.491</td> <td>    0.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raisin</th>          <td>    0.5175</td> <td>    0.206</td> <td>    2.514</td> <td> 0.012</td> <td>    0.114</td> <td>    0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raisiny</th>         <td>    0.7961</td> <td>    0.293</td> <td>    2.721</td> <td> 0.007</td> <td>    0.222</td> <td>    1.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>range</th>           <td>    0.3349</td> <td>    0.253</td> <td>    1.326</td> <td> 0.185</td> <td>   -0.160</td> <td>    0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raspberry</th>       <td>    0.4237</td> <td>    0.194</td> <td>    2.183</td> <td> 0.029</td> <td>    0.043</td> <td>    0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating</th>          <td>   -0.5414</td> <td>    0.367</td> <td>   -1.475</td> <td> 0.140</td> <td>   -1.261</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>raw</th>             <td>   -0.5864</td> <td>    0.536</td> <td>   -1.094</td> <td> 0.274</td> <td>   -1.637</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>read</th>            <td>    0.3088</td> <td>    0.272</td> <td>    1.135</td> <td> 0.256</td> <td>   -0.224</td> <td>    0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reader</th>          <td>    0.1099</td> <td>    0.378</td> <td>    0.291</td> <td> 0.771</td> <td>   -0.631</td> <td>    0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reads</th>           <td>    0.1209</td> <td>    0.284</td> <td>    0.426</td> <td> 0.670</td> <td>   -0.436</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ready</th>           <td>   -0.2532</td> <td>    1.007</td> <td>   -0.251</td> <td> 0.801</td> <td>   -2.228</td> <td>    1.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red</th>             <td>    0.4446</td> <td>    0.229</td> <td>    1.937</td> <td> 0.053</td> <td>   -0.005</td> <td>    0.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>redolent</th>        <td>    0.1862</td> <td>    0.282</td> <td>    0.661</td> <td> 0.509</td> <td>   -0.366</td> <td>    0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refreshing</th>      <td>    0.6074</td> <td>    0.340</td> <td>    1.785</td> <td> 0.074</td> <td>   -0.060</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relatively</th>      <td>    0.6762</td> <td>    0.351</td> <td>    1.929</td> <td> 0.054</td> <td>   -0.011</td> <td>    1.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>remains</th>         <td>    0.3724</td> <td>    0.303</td> <td>    1.228</td> <td> 0.220</td> <td>   -0.222</td> <td>    0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonance</th>       <td>    0.1681</td> <td>    0.341</td> <td>    0.493</td> <td> 0.622</td> <td>   -0.500</td> <td>    0.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonant</th>        <td>    0.1181</td> <td>    0.118</td> <td>    1.002</td> <td> 0.317</td> <td>   -0.113</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonantly</th>      <td>    0.2082</td> <td>    0.310</td> <td>    0.672</td> <td> 0.502</td> <td>   -0.400</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonate</th>        <td>    0.6201</td> <td>    0.365</td> <td>    1.701</td> <td> 0.089</td> <td>   -0.095</td> <td>    1.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resonates</th>       <td>    0.3856</td> <td>    0.351</td> <td>    1.098</td> <td> 0.272</td> <td>   -0.303</td> <td>    1.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resurfacing</th>     <td>    0.0668</td> <td>    0.312</td> <td>    0.214</td> <td> 0.831</td> <td>   -0.545</td> <td>    0.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>retains</th>         <td>   -0.5383</td> <td>    0.328</td> <td>   -1.644</td> <td> 0.100</td> <td>   -1.181</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rhododendron</th>    <td>    0.1941</td> <td>    0.287</td> <td>    0.676</td> <td> 0.499</td> <td>   -0.369</td> <td>    0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rich</th>            <td>    0.3162</td> <td>    0.108</td> <td>    2.923</td> <td> 0.003</td> <td>    0.104</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>richly</th>          <td>    0.6254</td> <td>    0.167</td> <td>    3.738</td> <td> 0.000</td> <td>    0.297</td> <td>    0.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>richness</th>        <td>    0.4609</td> <td>    0.341</td> <td>    1.351</td> <td> 0.177</td> <td>   -0.208</td> <td>    1.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rings</th>           <td>   -0.0382</td> <td>    0.299</td> <td>   -0.128</td> <td> 0.898</td> <td>   -0.625</td> <td>    0.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ripe</th>            <td>    0.4028</td> <td>    0.158</td> <td>    2.553</td> <td> 0.011</td> <td>    0.093</td> <td>    0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roast</th>           <td>   -0.1325</td> <td>    0.233</td> <td>   -0.569</td> <td> 0.569</td> <td>   -0.589</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roasted</th>         <td>    0.1241</td> <td>    0.186</td> <td>    0.668</td> <td> 0.504</td> <td>   -0.240</td> <td>    0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roastiness</th>      <td>    0.2285</td> <td>    0.401</td> <td>    0.569</td> <td> 0.569</td> <td>   -0.558</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roasty</th>          <td>    0.6342</td> <td>    0.273</td> <td>    2.320</td> <td> 0.020</td> <td>    0.098</td> <td>    1.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>robust</th>          <td>    0.8566</td> <td>    0.413</td> <td>    2.075</td> <td> 0.038</td> <td>    0.047</td> <td>    1.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rose</th>            <td>    0.3550</td> <td>    0.191</td> <td>    1.859</td> <td> 0.063</td> <td>   -0.019</td> <td>    0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rosemary</th>        <td>   -0.6414</td> <td>    0.450</td> <td>   -1.426</td> <td> 0.154</td> <td>   -1.523</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rough</th>           <td>   -0.5255</td> <td>    0.290</td> <td>   -1.809</td> <td> 0.070</td> <td>   -1.095</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>round</th>           <td>    0.0290</td> <td>    0.151</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.266</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounded</th>         <td>    0.2254</td> <td>    0.205</td> <td>    1.097</td> <td> 0.273</td> <td>   -0.177</td> <td>    0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounding</th>        <td>    0.0233</td> <td>    0.185</td> <td>    0.126</td> <td> 0.900</td> <td>   -0.339</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roundly</th>         <td>    0.1794</td> <td>    0.179</td> <td>    1.001</td> <td> 0.317</td> <td>   -0.172</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rounds</th>          <td>    0.1041</td> <td>    0.232</td> <td>    0.449</td> <td> 0.654</td> <td>   -0.351</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rum</th>             <td>    0.8381</td> <td>    0.433</td> <td>    1.938</td> <td> 0.053</td> <td>   -0.010</td> <td>    1.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rye</th>             <td>    0.1529</td> <td>    0.561</td> <td>    0.273</td> <td> 0.785</td> <td>   -0.947</td> <td>    1.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sage</th>            <td>    0.1147</td> <td>    0.307</td> <td>    0.373</td> <td> 0.709</td> <td>   -0.488</td> <td>    0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salted</th>          <td>    0.0936</td> <td>    0.440</td> <td>    0.212</td> <td> 0.832</td> <td>   -0.770</td> <td>    0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>salty</th>           <td>   -0.2726</td> <td>    0.273</td> <td>   -0.998</td> <td> 0.318</td> <td>   -0.808</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sample</th>          <td>   -0.9808</td> <td>    0.466</td> <td>   -2.104</td> <td> 0.035</td> <td>   -1.895</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sandalwood</th>      <td>    0.2535</td> <td>    0.147</td> <td>    1.729</td> <td> 0.084</td> <td>   -0.034</td> <td>    0.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sassafras</th>       <td>    0.3639</td> <td>    0.482</td> <td>    0.755</td> <td> 0.450</td> <td>   -0.581</td> <td>    1.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satiny</th>          <td>   -0.1927</td> <td>    0.111</td> <td>   -1.728</td> <td> 0.084</td> <td>   -0.411</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfying</th>      <td>    0.0197</td> <td>    0.351</td> <td>    0.056</td> <td> 0.955</td> <td>   -0.668</td> <td>    0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saturate</th>        <td>    0.3841</td> <td>    0.359</td> <td>    1.069</td> <td> 0.285</td> <td>   -0.320</td> <td>    1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saturated</th>       <td>    0.6325</td> <td>    0.203</td> <td>    3.110</td> <td> 0.002</td> <td>    0.234</td> <td>    1.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saturates</th>       <td>    0.3571</td> <td>    0.293</td> <td>    1.221</td> <td> 0.222</td> <td>   -0.216</td> <td>    0.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>savory</th>          <td>    0.0651</td> <td>    0.141</td> <td>    0.461</td> <td> 0.645</td> <td>   -0.212</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scaled</th>          <td>   -0.1117</td> <td>    0.602</td> <td>   -0.186</td> <td> 0.853</td> <td>   -1.292</td> <td>    1.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scorched</th>        <td>    0.0026</td> <td>    0.219</td> <td>    0.012</td> <td> 0.990</td> <td>   -0.426</td> <td>    0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sean</th>            <td>    0.8579</td> <td>    0.549</td> <td>    1.562</td> <td> 0.118</td> <td>   -0.219</td> <td>    1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>semi</th>            <td>   -0.0232</td> <td>    0.294</td> <td>   -0.079</td> <td> 0.937</td> <td>   -0.599</td> <td>    0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sensation</th>       <td>   -0.2567</td> <td>    0.293</td> <td>   -0.876</td> <td> 0.381</td> <td>   -0.831</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>serve</th>           <td>    0.1423</td> <td>    1.127</td> <td>    0.126</td> <td> 0.900</td> <td>   -2.067</td> <td>    2.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>serving</th>         <td>   -0.5231</td> <td>    1.218</td> <td>   -0.429</td> <td> 0.668</td> <td>   -2.912</td> <td>    1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shadow</th>          <td>   -1.2718</td> <td>    0.488</td> <td>   -2.604</td> <td> 0.009</td> <td>   -2.229</td> <td>   -0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shallow</th>         <td>   -0.9506</td> <td>    0.388</td> <td>   -2.451</td> <td> 0.014</td> <td>   -1.711</td> <td>   -0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sharp</th>           <td>   -2.8676</td> <td>    0.348</td> <td>   -8.243</td> <td> 0.000</td> <td>   -3.550</td> <td>   -2.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sharpness</th>       <td>   -1.4028</td> <td>    0.378</td> <td>   -3.711</td> <td> 0.000</td> <td>   -2.144</td> <td>   -0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shifting</th>        <td>    0.3932</td> <td>    0.324</td> <td>    1.213</td> <td> 0.225</td> <td>   -0.242</td> <td>    1.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shimmer</th>         <td>    0.6130</td> <td>    0.257</td> <td>    2.384</td> <td> 0.017</td> <td>    0.109</td> <td>    1.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>short</th>           <td>   -0.3539</td> <td>    0.124</td> <td>   -2.859</td> <td> 0.004</td> <td>   -0.597</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>shot</th>            <td>    0.2185</td> <td>    0.456</td> <td>    0.480</td> <td> 0.631</td> <td>   -0.675</td> <td>    1.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>silky</th>           <td>   -0.1635</td> <td>    0.138</td> <td>   -1.185</td> <td> 0.236</td> <td>   -0.434</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simple</th>          <td>   -0.3342</td> <td>    0.200</td> <td>   -1.672</td> <td> 0.095</td> <td>   -0.726</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simplifies</th>      <td>    0.0154</td> <td>    0.225</td> <td>    0.068</td> <td> 0.946</td> <td>   -0.426</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>simplify</th>        <td>   -0.0633</td> <td>    0.341</td> <td>   -0.186</td> <td> 0.853</td> <td>   -0.732</td> <td>    0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>singed</th>          <td>    0.3523</td> <td>    0.451</td> <td>    0.782</td> <td> 0.434</td> <td>   -0.531</td> <td>    1.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single</th>          <td>   -1.4266</td> <td>    0.779</td> <td>   -1.832</td> <td> 0.067</td> <td>   -2.953</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>            <td>   -0.1228</td> <td>    0.504</td> <td>   -0.244</td> <td> 0.807</td> <td>   -1.110</td> <td>    0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slight</th>          <td>    0.7093</td> <td>    0.211</td> <td>    3.366</td> <td> 0.001</td> <td>    0.296</td> <td>    1.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slightly</th>        <td>   -0.0024</td> <td>    0.174</td> <td>   -0.014</td> <td> 0.989</td> <td>   -0.343</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>small</th>           <td>   -0.0994</td> <td>    0.259</td> <td>   -0.384</td> <td> 0.701</td> <td>   -0.607</td> <td>    0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoke</th>           <td>   -0.4267</td> <td>    0.420</td> <td>   -1.015</td> <td> 0.310</td> <td>   -1.251</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoky</th>           <td>   -0.1119</td> <td>    0.240</td> <td>   -0.466</td> <td> 0.641</td> <td>   -0.582</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smooth</th>          <td>   -0.0448</td> <td>    0.107</td> <td>   -0.421</td> <td> 0.674</td> <td>   -0.254</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoothes</th>        <td>    0.4497</td> <td>    0.347</td> <td>    1.296</td> <td> 0.195</td> <td>   -0.231</td> <td>    1.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoothly</th>        <td>   -0.0019</td> <td>    0.251</td> <td>   -0.008</td> <td> 0.994</td> <td>   -0.493</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soft</th>            <td>    0.5745</td> <td>    0.203</td> <td>    2.823</td> <td> 0.005</td> <td>    0.176</td> <td>    0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soften</th>          <td>    0.3519</td> <td>    0.330</td> <td>    1.065</td> <td> 0.287</td> <td>   -0.296</td> <td>    0.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softened</th>        <td>    0.2248</td> <td>    0.330</td> <td>    0.681</td> <td> 0.496</td> <td>   -0.423</td> <td>    0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softening</th>       <td>   -0.3135</td> <td>    0.394</td> <td>   -0.795</td> <td> 0.426</td> <td>   -1.086</td> <td>    0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softens</th>         <td>   -0.1577</td> <td>    0.235</td> <td>   -0.672</td> <td> 0.502</td> <td>   -0.618</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>softly</th>          <td>    0.2688</td> <td>    0.241</td> <td>    1.115</td> <td> 0.265</td> <td>   -0.204</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>solid</th>           <td>   -0.4953</td> <td>    0.326</td> <td>   -1.521</td> <td> 0.128</td> <td>   -1.134</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>somewhat</th>        <td>   -0.3436</td> <td>    0.428</td> <td>   -0.802</td> <td> 0.423</td> <td>   -1.184</td> <td>    0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sort</th>            <td>   -0.3016</td> <td>    0.291</td> <td>   -1.035</td> <td> 0.301</td> <td>   -0.873</td> <td>    0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sour</th>            <td>   -0.9182</td> <td>    0.479</td> <td>   -1.917</td> <td> 0.055</td> <td>   -1.857</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spearmint</th>       <td>    0.7081</td> <td>    0.409</td> <td>    1.732</td> <td> 0.083</td> <td>   -0.093</td> <td>    1.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spice</th>           <td>    0.4405</td> <td>    0.205</td> <td>    2.151</td> <td> 0.032</td> <td>    0.039</td> <td>    0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spices</th>          <td>    0.4998</td> <td>    0.314</td> <td>    1.592</td> <td> 0.111</td> <td>   -0.116</td> <td>    1.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spicy</th>           <td>    0.1615</td> <td>    0.212</td> <td>    0.761</td> <td> 0.447</td> <td>   -0.255</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>star</th>            <td>    0.2737</td> <td>    0.270</td> <td>    1.014</td> <td> 0.311</td> <td>   -0.256</td> <td>    0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stone</th>           <td>    0.0889</td> <td>    0.293</td> <td>    0.303</td> <td> 0.762</td> <td>   -0.486</td> <td>    0.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>straight</th>        <td>    0.9124</td> <td>    0.344</td> <td>    2.653</td> <td> 0.008</td> <td>    0.238</td> <td>    1.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>straightforward</th> <td>    0.0541</td> <td>    0.263</td> <td>    0.206</td> <td> 0.837</td> <td>   -0.462</td> <td>    0.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>strawberry</th>      <td>    0.2280</td> <td>    0.242</td> <td>    0.944</td> <td> 0.345</td> <td>   -0.246</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>structure</th>       <td>   -0.2161</td> <td>    0.141</td> <td>   -1.528</td> <td> 0.127</td> <td>   -0.493</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>style</th>           <td>   -0.1919</td> <td>    0.346</td> <td>   -0.555</td> <td> 0.579</td> <td>   -0.870</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subdued</th>         <td>    0.4246</td> <td>    0.268</td> <td>    1.583</td> <td> 0.113</td> <td>   -0.101</td> <td>    0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>substantial</th>     <td>   -0.7526</td> <td>    0.423</td> <td>   -1.781</td> <td> 0.075</td> <td>   -1.581</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subtle</th>          <td>    0.7578</td> <td>    0.290</td> <td>    2.616</td> <td> 0.009</td> <td>    0.190</td> <td>    1.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>subtly</th>          <td>   -0.0361</td> <td>    0.192</td> <td>   -0.187</td> <td> 0.851</td> <td>   -0.413</td> <td>    0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sugar</th>           <td>   -0.9960</td> <td>    0.774</td> <td>   -1.287</td> <td> 0.198</td> <td>   -2.513</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sugary</th>          <td>    0.7843</td> <td>    0.309</td> <td>    2.538</td> <td> 0.011</td> <td>    0.178</td> <td>    1.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggest</th>         <td>    0.7387</td> <td>    0.370</td> <td>    1.994</td> <td> 0.046</td> <td>    0.012</td> <td>    1.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggesting</th>      <td>    0.4651</td> <td>    0.280</td> <td>    1.659</td> <td> 0.097</td> <td>   -0.084</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggestion</th>      <td>    0.0846</td> <td>    0.222</td> <td>    0.381</td> <td> 0.703</td> <td>   -0.351</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggestions</th>     <td>   -0.1680</td> <td>    0.172</td> <td>   -0.976</td> <td> 0.329</td> <td>   -0.505</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suggests</th>        <td>    0.1554</td> <td>    0.337</td> <td>    0.461</td> <td> 0.645</td> <td>   -0.505</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sumatra</th>         <td>    0.6128</td> <td>    0.384</td> <td>    1.597</td> <td> 0.110</td> <td>   -0.139</td> <td>    1.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>superb</th>          <td>    0.9087</td> <td>    0.263</td> <td>    3.453</td> <td> 0.001</td> <td>    0.393</td> <td>    1.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>support</th>         <td>    0.3024</td> <td>    0.398</td> <td>    0.759</td> <td> 0.448</td> <td>   -0.479</td> <td>    1.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>supported</th>       <td>    0.1792</td> <td>    0.209</td> <td>    0.857</td> <td> 0.392</td> <td>   -0.231</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>supporting</th>      <td>    0.2884</td> <td>    0.392</td> <td>    0.736</td> <td> 0.462</td> <td>   -0.480</td> <td>    1.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surfaces</th>        <td>   -0.6810</td> <td>    0.314</td> <td>   -2.166</td> <td> 0.030</td> <td>   -1.298</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surprising</th>      <td>    1.1399</td> <td>    0.384</td> <td>    2.972</td> <td> 0.003</td> <td>    0.388</td> <td>    1.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surprisingly</th>    <td>    0.3284</td> <td>    0.239</td> <td>    1.373</td> <td> 0.170</td> <td>   -0.140</td> <td>    0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sustained</th>       <td>   -0.0469</td> <td>    0.311</td> <td>   -0.151</td> <td> 0.880</td> <td>   -0.657</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweet</th>           <td>    0.2672</td> <td>    0.130</td> <td>    2.063</td> <td> 0.039</td> <td>    0.013</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetening</th>      <td>   -0.0576</td> <td>    0.359</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.761</td> <td>    0.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetens</th>        <td>    0.6322</td> <td>    0.239</td> <td>    2.643</td> <td> 0.008</td> <td>    0.163</td> <td>    1.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetly</th>         <td>    0.2099</td> <td>    0.126</td> <td>    1.667</td> <td> 0.096</td> <td>   -0.037</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sweetness</th>       <td>    0.5802</td> <td>    0.234</td> <td>    2.481</td> <td> 0.013</td> <td>    0.122</td> <td>    1.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syrup</th>           <td>   -1.3917</td> <td>    0.655</td> <td>   -2.126</td> <td> 0.034</td> <td>   -2.675</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>syrupy</th>          <td>   -0.2425</td> <td>    0.162</td> <td>   -1.494</td> <td> 0.135</td> <td>   -0.561</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tamarind</th>        <td>    0.6992</td> <td>    0.232</td> <td>    3.010</td> <td> 0.003</td> <td>    0.244</td> <td>    1.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tangerine</th>       <td>    0.3016</td> <td>    0.184</td> <td>    1.636</td> <td> 0.102</td> <td>   -0.060</td> <td>    0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tangy</th>           <td>    0.3414</td> <td>    0.387</td> <td>    0.881</td> <td> 0.378</td> <td>   -0.418</td> <td>    1.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tart</th>            <td>    0.0790</td> <td>    0.145</td> <td>    0.544</td> <td> 0.586</td> <td>   -0.205</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tartly</th>          <td>    0.0104</td> <td>    0.229</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.439</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taste</th>           <td>   -2.2688</td> <td>    0.335</td> <td>   -6.770</td> <td> 0.000</td> <td>   -2.926</td> <td>   -1.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>taster</th>          <td>   -0.7303</td> <td>    0.608</td> <td>   -1.200</td> <td> 0.230</td> <td>   -1.923</td> <td>    0.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tea</th>             <td>   -0.0090</td> <td>    0.256</td> <td>   -0.035</td> <td> 0.972</td> <td>   -0.512</td> <td>    0.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ted</th>             <td>    0.4908</td> <td>    0.511</td> <td>    0.960</td> <td> 0.337</td> <td>   -0.512</td> <td>    1.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tested</th>          <td>   -1.3233</td> <td>    0.867</td> <td>   -1.527</td> <td> 0.127</td> <td>   -3.022</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>textured</th>        <td>   -0.0047</td> <td>    0.379</td> <td>   -0.012</td> <td> 0.990</td> <td>   -0.748</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>think</th>           <td>   -0.3643</td> <td>    0.358</td> <td>   -1.018</td> <td> 0.309</td> <td>   -1.066</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>throughline</th>     <td>   -0.0549</td> <td>    0.307</td> <td>   -0.179</td> <td> 0.858</td> <td>   -0.656</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thyme</th>           <td>    0.0766</td> <td>    0.264</td> <td>    0.290</td> <td> 0.772</td> <td>   -0.441</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tickle</th>          <td>    0.4624</td> <td>    0.338</td> <td>    1.368</td> <td> 0.171</td> <td>   -0.200</td> <td>    1.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tight</th>           <td>   -0.9219</td> <td>    0.503</td> <td>   -1.834</td> <td> 0.067</td> <td>   -1.908</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toast</th>           <td>    0.0164</td> <td>    0.292</td> <td>    0.056</td> <td> 0.955</td> <td>   -0.556</td> <td>    0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toasted</th>         <td>   -0.1762</td> <td>    0.405</td> <td>   -0.435</td> <td> 0.664</td> <td>   -0.971</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toasty</th>          <td>    1.0435</td> <td>    0.447</td> <td>    2.335</td> <td> 0.020</td> <td>    0.167</td> <td>    1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tobacco</th>         <td>    0.0507</td> <td>    0.422</td> <td>    0.120</td> <td> 0.904</td> <td>   -0.776</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toffee</th>          <td>    0.2754</td> <td>    0.247</td> <td>    1.116</td> <td> 0.264</td> <td>   -0.208</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tomato</th>          <td>    0.0507</td> <td>    0.299</td> <td>    0.169</td> <td> 0.866</td> <td>   -0.536</td> <td>    0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toned</th>           <td>   -0.1698</td> <td>    0.138</td> <td>   -1.229</td> <td> 0.219</td> <td>   -0.441</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tones</th>           <td>   -0.0164</td> <td>    0.174</td> <td>   -0.094</td> <td> 0.925</td> <td>   -0.358</td> <td>    0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>touch</th>           <td>    0.6071</td> <td>    0.296</td> <td>    2.053</td> <td> 0.040</td> <td>    0.027</td> <td>    1.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tropical</th>        <td>    0.5359</td> <td>    0.311</td> <td>    1.723</td> <td> 0.085</td> <td>   -0.074</td> <td>    1.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turn</th>            <td>    0.4446</td> <td>    0.306</td> <td>    1.451</td> <td> 0.147</td> <td>   -0.156</td> <td>    1.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turned</th>          <td>    0.2158</td> <td>    0.409</td> <td>    0.527</td> <td> 0.598</td> <td>   -0.586</td> <td>    1.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turning</th>         <td>   -1.0458</td> <td>    0.321</td> <td>   -3.259</td> <td> 0.001</td> <td>   -1.675</td> <td>   -0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>turns</th>           <td>   -0.1486</td> <td>    0.174</td> <td>   -0.852</td> <td> 0.394</td> <td>   -0.491</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>underlying</th>      <td>    0.7531</td> <td>    0.373</td> <td>    2.021</td> <td> 0.043</td> <td>    0.023</td> <td>    1.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>understated</th>     <td>   -0.0309</td> <td>    0.332</td> <td>   -0.093</td> <td> 0.926</td> <td>   -0.683</td> <td>    0.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>undertones</th>      <td>    0.1018</td> <td>    0.134</td> <td>    0.758</td> <td> 0.448</td> <td>   -0.161</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unusual</th>         <td>    0.2573</td> <td>    0.312</td> <td>    0.825</td> <td> 0.410</td> <td>   -0.355</td> <td>    0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>using</th>           <td>    0.5943</td> <td>    0.622</td> <td>    0.956</td> <td> 0.339</td> <td>   -0.625</td> <td>    1.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vanilla</th>         <td>   -0.0607</td> <td>    0.160</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.373</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velvety</th>         <td>   -0.1262</td> <td>    0.151</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.422</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>verbena</th>         <td>    0.1458</td> <td>    0.220</td> <td>    0.662</td> <td> 0.508</td> <td>   -0.286</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>version</th>         <td>   -0.5490</td> <td>    0.348</td> <td>   -1.579</td> <td> 0.114</td> <td>   -1.231</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vibrant</th>         <td>    0.2710</td> <td>    0.221</td> <td>    1.229</td> <td> 0.219</td> <td>   -0.162</td> <td>    0.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vibrantly</th>       <td>    0.3633</td> <td>    0.256</td> <td>    1.417</td> <td> 0.157</td> <td>   -0.139</td> <td>    0.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>violet</th>          <td>    0.1689</td> <td>    0.244</td> <td>    0.693</td> <td> 0.489</td> <td>   -0.309</td> <td>    0.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>viscous</th>         <td>    0.1532</td> <td>    0.172</td> <td>    0.892</td> <td> 0.373</td> <td>   -0.184</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vivacious</th>       <td>    0.3707</td> <td>    0.315</td> <td>    1.178</td> <td> 0.239</td> <td>   -0.246</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volume</th>          <td>   -0.3502</td> <td>    0.944</td> <td>   -0.371</td> <td> 0.711</td> <td>   -2.201</td> <td>    1.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>walnut</th>          <td>    0.2051</td> <td>    0.228</td> <td>    0.898</td> <td> 0.369</td> <td>   -0.243</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>water</th>           <td>    1.4787</td> <td>    0.630</td> <td>    2.346</td> <td> 0.019</td> <td>    0.243</td> <td>    2.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>watermelon</th>      <td>    0.1029</td> <td>    0.382</td> <td>    0.270</td> <td> 0.788</td> <td>   -0.645</td> <td>    0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>way</th>             <td>    0.7849</td> <td>    0.455</td> <td>    1.726</td> <td> 0.084</td> <td>   -0.107</td> <td>    1.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>whisky</th>          <td>    0.4506</td> <td>    0.511</td> <td>    0.882</td> <td> 0.378</td> <td>   -0.551</td> <td>    1.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>white</th>           <td>    0.1806</td> <td>    0.281</td> <td>    0.642</td> <td> 0.521</td> <td>   -0.371</td> <td>    0.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wild</th>            <td>    0.4234</td> <td>    0.292</td> <td>    1.450</td> <td> 0.147</td> <td>   -0.149</td> <td>    0.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>willem</th>          <td>    0.1294</td> <td>    0.478</td> <td>    0.271</td> <td> 0.787</td> <td>   -0.808</td> <td>    1.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wine</th>            <td>    1.7887</td> <td>    0.238</td> <td>    7.517</td> <td> 0.000</td> <td>    1.322</td> <td>    2.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>winy</th>            <td>    1.3868</td> <td>    0.340</td> <td>    4.084</td> <td> 0.000</td> <td>    0.721</td> <td>    2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wisteria</th>        <td>    0.2205</td> <td>    0.243</td> <td>    0.907</td> <td> 0.364</td> <td>   -0.256</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wood</th>            <td>   -0.0255</td> <td>    0.246</td> <td>   -0.104</td> <td> 0.917</td> <td>   -0.507</td> <td>    0.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>woody</th>           <td>   -1.6804</td> <td>    0.370</td> <td>   -4.541</td> <td> 0.000</td> <td>   -2.406</td> <td>   -0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zest</th>            <td>    0.1572</td> <td>    0.145</td> <td>    1.083</td> <td> 0.279</td> <td>   -0.127</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zesty</th>           <td>    0.0675</td> <td>    0.274</td> <td>    0.246</td> <td> 0.805</td> <td>   -0.470</td> <td>    0.605</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1123.358</td> <th>  Durbin-Watson:     </th> <td>   2.005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>48378.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.518</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>19.606</td>  <th>  Cond. No.          </th> <td>    268.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          overall_score   R-squared:                       0.941\n",
       "Model:                            OLS   Adj. R-squared:                  0.930\n",
       "Method:                 Least Squares   F-statistic:                     90.01\n",
       "Date:                Thu, 03 Nov 2022   Prob (F-statistic):               0.00\n",
       "Time:                        11:15:00   Log-Likelihood:                -5943.5\n",
       "No. Observations:                4194   AIC:                         1.315e+04\n",
       "Df Residuals:                    3563   BIC:                         1.715e+04\n",
       "Df Model:                         630                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              66.8850      0.411    162.789      0.000      66.079      67.691\n",
       "month               0.0251      0.061      0.408      0.683      -0.095       0.145\n",
       "year                0.1609      0.271      0.594      0.552      -0.370       0.692\n",
       "bean_agtron        -0.8571      0.373     -2.296      0.022      -1.589      -0.125\n",
       "ground_agtron       1.4394      0.313      4.605      0.000       0.827       2.052\n",
       "aroma               9.0722      0.283     32.017      0.000       8.517       9.628\n",
       "acidity             5.2718      0.356     14.822      0.000       4.574       5.969\n",
       "body                4.5382      0.225     20.138      0.000       4.096       4.980\n",
       "flavor              4.4015      0.330     13.338      0.000       3.755       5.048\n",
       "aftertaste          6.0364      0.343     17.617      0.000       5.365       6.708\n",
       "roaster_lat         0.0449      0.247      0.182      0.856      -0.439       0.529\n",
       "roaster_lon        -0.0015      0.091     -0.016      0.987      -0.180       0.177\n",
       "origin_lat         -0.6637      0.168     -3.961      0.000      -0.992      -0.335\n",
       "origin_lon         -0.0750      0.091     -0.824      0.410      -0.253       0.103\n",
       "acid               -0.6022      0.547     -1.101      0.271      -1.674       0.470\n",
       "acidity.1          -0.0995      0.162     -0.614      0.539      -0.418       0.218\n",
       "acidy               0.6202      0.249      2.493      0.013       0.132       1.108\n",
       "admired             0.5320      0.409      1.302      0.193      -0.269       1.333\n",
       "aftertaste.1        0.8524      0.289      2.948      0.003       0.286       1.419\n",
       "agave               1.4111      0.595      2.370      0.018       0.244       2.578\n",
       "aged               -0.2977      0.531     -0.560      0.575      -1.339       0.744\n",
       "agreeable          -0.2906      0.450     -0.645      0.519      -1.174       0.592\n",
       "agreeably           0.4098      0.349      1.174      0.240      -0.274       1.094\n",
       "alive               0.1050      0.317      0.331      0.741      -0.517       0.727\n",
       "almond              0.1144      0.144      0.792      0.428      -0.169       0.398\n",
       "amber               0.3853      0.361      1.067      0.286      -0.323       1.093\n",
       "amplified           0.0151      0.335      0.045      0.964      -0.641       0.671\n",
       "anise               0.3518      0.407      0.864      0.388      -0.447       1.150\n",
       "apple               0.7312      0.220      3.321      0.001       0.300       1.163\n",
       "apricot             0.2994      0.144      2.078      0.038       0.017       0.582\n",
       "aromatic           -0.0502      0.221     -0.227      0.820      -0.483       0.383\n",
       "aromatically        0.3928      0.400      0.981      0.327      -0.392       1.178\n",
       "aromatics           0.1131      0.255      0.443      0.658      -0.387       0.614\n",
       "astringency        -1.0581      0.239     -4.424      0.000      -1.527      -0.589\n",
       "astringent         -0.9194      0.219     -4.198      0.000      -1.349      -0.490\n",
       "attractive         -0.7269      0.284     -2.558      0.011      -1.284      -0.170\n",
       "authority           0.0458      0.320      0.143      0.886      -0.582       0.673\n",
       "b60                 0.6211      0.653      0.952      0.341      -0.658       1.900\n",
       "b70                -0.4283      1.072     -0.400      0.690      -2.530       1.674\n",
       "backgrounded       -0.0625      0.209     -0.300      0.764      -0.472       0.346\n",
       "baker              -0.1115      0.192     -0.581      0.562      -0.488       0.265\n",
       "baking              0.0024      0.198      0.012      0.990      -0.386       0.391\n",
       "balance             1.4785      0.250      5.910      0.000       0.988       1.969\n",
       "balanced            0.2373      0.104      2.284      0.022       0.034       0.441\n",
       "banana              0.3026      0.235      1.290      0.197      -0.157       0.763\n",
       "barrel             -0.3465      0.344     -1.007      0.314      -1.021       0.328\n",
       "bean               -0.3640      0.450     -0.808      0.419      -1.247       0.519\n",
       "bergamot            0.4480      0.248      1.807      0.071      -0.038       0.934\n",
       "berries             0.4101      0.400      1.026      0.305      -0.374       1.194\n",
       "berry               1.1547      0.183      6.294      0.000       0.795       1.514\n",
       "best                1.7546      0.449      3.907      0.000       0.874       2.635\n",
       "big                 0.0408      0.184      0.222      0.824      -0.319       0.401\n",
       "bing                0.2686      0.431      0.623      0.533      -0.576       1.113\n",
       "bit                -0.4401      0.243     -1.812      0.070      -0.916       0.036\n",
       "bitter             -1.5936      0.375     -4.251      0.000      -2.328      -0.859\n",
       "bitterish          -0.8191      0.295     -2.777      0.006      -1.398      -0.241\n",
       "bitterness          0.2898      0.416      0.696      0.486      -0.526       1.106\n",
       "bittersweet        -0.2725      0.200     -1.361      0.174      -0.665       0.120\n",
       "black               0.4328      0.245      1.765      0.078      -0.048       0.913\n",
       "blackberry          0.2889      0.221      1.310      0.190      -0.144       0.721\n",
       "blend              -0.0346      0.350     -0.099      0.921      -0.721       0.652\n",
       "blood               0.2485      0.253      0.983      0.326      -0.247       0.744\n",
       "bloom               0.1975      0.389      0.508      0.612      -0.565       0.960\n",
       "blooming            0.0812      0.278      0.292      0.771      -0.465       0.627\n",
       "blooms             -0.0211      0.347     -0.061      0.951      -0.701       0.659\n",
       "blossom             0.0340      0.248      0.137      0.891      -0.452       0.520\n",
       "blueberry           0.3410      0.228      1.496      0.135      -0.106       0.788\n",
       "bodied              0.8427      0.208      4.050      0.000       0.435       1.251\n",
       "body.1              0.4785      0.189      2.526      0.012       0.107       0.850\n",
       "bracing             0.8190      0.304      2.693      0.007       0.223       1.415\n",
       "brandy              0.6242      0.285      2.193      0.028       0.066       1.182\n",
       "brandyish           0.5980      0.354      1.691      0.091      -0.095       1.291\n",
       "brazil             -0.0815      0.403     -0.202      0.840      -0.872       0.709\n",
       "brewed              0.2239      1.044      0.214      0.830      -1.823       2.271\n",
       "brewer              1.7565      0.817      2.151      0.032       0.156       3.358\n",
       "brewing            -1.6606      1.053     -1.578      0.115      -3.724       0.403\n",
       "bright              0.2941      0.138      2.125      0.034       0.023       0.565\n",
       "brightly            0.1300      0.207      0.627      0.531      -0.277       0.537\n",
       "brightness         -0.0383      0.440     -0.087      0.931      -0.900       0.824\n",
       "brisk              -0.0422      0.159     -0.265      0.791      -0.354       0.269\n",
       "briskly             0.1978      0.307      0.644      0.520      -0.405       0.800\n",
       "brittle             0.4597      0.287      1.601      0.109      -0.103       1.023\n",
       "brown               1.5068      0.794      1.897      0.058      -0.051       3.064\n",
       "buoyant            -0.0080      0.144     -0.055      0.956      -0.291       0.275\n",
       "buoyantly           0.3691      0.339      1.087      0.277      -0.296       1.035\n",
       "burned             -1.5480      0.403     -3.845      0.000      -2.337      -0.759\n",
       "butter              0.4950      0.165      3.005      0.003       0.172       0.818\n",
       "butterscotch        0.8461      0.270      3.139      0.002       0.318       1.374\n",
       "buttery             0.4255      0.224      1.900      0.057      -0.013       0.864\n",
       "byron               0.9368      0.564      1.661      0.097      -0.169       2.043\n",
       "cacao               0.1353      0.229      0.590      0.555      -0.315       0.585\n",
       "called              0.4328      0.513      0.844      0.399      -0.573       1.438\n",
       "candied             0.4442      0.245      1.811      0.070      -0.037       0.925\n",
       "candy               0.6525      0.428      1.524      0.128      -0.187       1.492\n",
       "cane                0.8454      0.774      1.092      0.275      -0.672       2.363\n",
       "cappuccino          0.7637      0.571      1.337      0.181      -0.356       1.884\n",
       "capsule            -1.2131      1.031     -1.176      0.239      -3.235       0.809\n",
       "caramel             0.0640      0.179      0.357      0.721      -0.288       0.416\n",
       "caramelly           0.5240      0.291      1.800      0.072      -0.047       1.095\n",
       "carbon             -0.5481      0.449     -1.220      0.223      -1.429       0.333\n",
       "cardamom            0.1440      0.405      0.356      0.722      -0.649       0.937\n",
       "carob               0.2525      0.353      0.715      0.475      -0.440       0.945\n",
       "carried            -0.1601      0.316     -0.507      0.612      -0.780       0.459\n",
       "carries             0.2321      0.175      1.330      0.184      -0.110       0.574\n",
       "carry              -0.0775      0.109     -0.711      0.477      -0.291       0.136\n",
       "carrying            0.1216      0.267      0.456      0.649      -0.401       0.644\n",
       "cashew              0.1068      0.224      0.476      0.634      -0.333       0.547\n",
       "cedar               0.2738      0.125      2.192      0.028       0.029       0.519\n",
       "cedary              0.2480      0.236      1.052      0.293      -0.214       0.710\n",
       "center              0.1597      0.428      0.373      0.709      -0.679       0.998\n",
       "centered            0.0144      0.209      0.069      0.945      -0.394       0.423\n",
       "centers             0.0635      0.135      0.470      0.638      -0.201       0.328\n",
       "character           0.2563      0.229      1.120      0.263      -0.192       0.705\n",
       "charred            -0.5275      0.362     -1.456      0.146      -1.238       0.183\n",
       "cherry              0.4708      0.163      2.892      0.004       0.152       0.790\n",
       "cherryish           1.4278      0.253      5.643      0.000       0.932       1.924\n",
       "chocolate           0.7558      0.146      5.174      0.000       0.469       1.042\n",
       "chocolaty           0.3996      0.180      2.223      0.026       0.047       0.752\n",
       "cinnamon            0.2662      0.267      0.996      0.319      -0.258       0.790\n",
       "cited               0.0031      0.518      0.006      0.995      -1.013       1.019\n",
       "citrus              0.1601      0.174      0.920      0.358      -0.181       0.501\n",
       "citrusy             0.2376      0.248      0.959      0.338      -0.248       0.724\n",
       "classic             0.3655      0.281      1.300      0.194      -0.186       0.917\n",
       "clean               0.6244      0.204      3.062      0.002       0.225       1.024\n",
       "cleanly             0.5963      0.196      3.043      0.002       0.212       0.981\n",
       "clear               0.2571      0.355      0.724      0.469      -0.439       0.953\n",
       "clove               0.2805      0.273      1.027      0.304      -0.255       0.816\n",
       "cocoa               0.6052      0.163      3.707      0.000       0.285       0.925\n",
       "cocoaish            0.1596      0.265      0.603      0.547      -0.359       0.679\n",
       "coconut             0.4847      0.293      1.657      0.098      -0.089       1.058\n",
       "coffee              0.4064      0.199      2.046      0.041       0.017       0.796\n",
       "coffees             0.1868      0.394      0.474      0.635      -0.585       0.959\n",
       "cold                2.0838      0.704      2.959      0.003       0.703       3.465\n",
       "complete            0.5830      0.247      2.364      0.018       0.099       1.067\n",
       "complex             0.5424      0.125      4.355      0.000       0.298       0.787\n",
       "complexity          0.4614      0.255      1.809      0.071      -0.039       0.961\n",
       "complexly           0.4802      0.211      2.279      0.023       0.067       0.893\n",
       "complicate         -0.3409      0.390     -0.874      0.382      -1.106       0.424\n",
       "complicated        -0.5547      0.168     -3.306      0.001      -0.884      -0.226\n",
       "complicates         0.6191      0.348      1.777      0.076      -0.064       1.302\n",
       "complicating       -0.0467      0.332     -0.140      0.888      -0.699       0.605\n",
       "complication       -0.3345      0.260     -1.287      0.198      -0.844       0.175\n",
       "complications      -0.2008      0.278     -0.722      0.470      -0.746       0.344\n",
       "concord             0.6028      0.381      1.583      0.113      -0.144       1.349\n",
       "consolidates        0.1458      0.108      1.352      0.177      -0.066       0.357\n",
       "consolidating       0.0421      0.272      0.155      0.877      -0.492       0.576\n",
       "continued           0.4276      0.187      2.284      0.022       0.061       0.795\n",
       "continuing         -0.0814      0.230     -0.354      0.723      -0.532       0.369\n",
       "cools              -0.3132      0.226     -1.384      0.167      -0.757       0.131\n",
       "creamy             -0.0264      0.135     -0.196      0.845      -0.291       0.239\n",
       "crisp               0.2117      0.123      1.718      0.086      -0.030       0.453\n",
       "crisply             0.6254      0.246      2.538      0.011       0.142       1.108\n",
       "cupper              0.3543      0.333      1.064      0.287      -0.299       1.007\n",
       "cupping             0.1802      0.365      0.493      0.622      -0.536       0.896\n",
       "cups               -3.6663      0.480     -7.635      0.000      -4.608      -2.725\n",
       "currant             0.2962      0.238      1.246      0.213      -0.170       0.762\n",
       "cut                 0.2715      0.225      1.205      0.228      -0.170       0.713\n",
       "dark               -0.2593      0.199     -1.302      0.193      -0.650       0.131\n",
       "date                0.4745      0.186      2.546      0.011       0.109       0.840\n",
       "deep                0.4080      0.145      2.808      0.005       0.123       0.693\n",
       "deepen             -0.1971      0.382     -0.516      0.606      -0.946       0.552\n",
       "deepening           0.6511      0.331      1.969      0.049       0.003       1.299\n",
       "deepens             0.8888      0.271      3.281      0.001       0.358       1.420\n",
       "deeply              0.4666      0.129      3.620      0.000       0.214       0.719\n",
       "delicate            0.2693      0.165      1.628      0.104      -0.055       0.594\n",
       "delicately          0.3177      0.148      2.147      0.032       0.028       0.608\n",
       "depth               0.5919      0.328      1.807      0.071      -0.050       1.234\n",
       "described          -0.0629      0.476     -0.132      0.895      -0.995       0.870\n",
       "device              2.4385      1.297      1.880      0.060      -0.104       4.981\n",
       "did                 0.0176      0.532      0.033      0.974      -1.025       1.060\n",
       "dimension          -0.9626      0.314     -3.070      0.002      -1.577      -0.348\n",
       "displays           -0.1919      0.278     -0.690      0.491      -0.737       0.354\n",
       "distinct            0.2844      0.238      1.196      0.232      -0.182       0.750\n",
       "distinctive         0.2835      0.408      0.695      0.487      -0.516       1.083\n",
       "distinctly         -0.2630      0.244     -1.076      0.282      -0.742       0.216\n",
       "dominate           -0.2726      0.168     -1.624      0.105      -0.602       0.057\n",
       "dominated           0.0258      0.236      0.110      0.913      -0.436       0.488\n",
       "dominates           0.0546      0.208      0.262      0.793      -0.354       0.463\n",
       "dominating          0.3023      0.341      0.886      0.376      -0.367       0.971\n",
       "dried               0.1876      0.144      1.305      0.192      -0.094       0.469\n",
       "drink               0.7825      0.751      1.042      0.298      -0.690       2.255\n",
       "driven              0.0848      0.284      0.299      0.765      -0.472       0.641\n",
       "dry                -0.1491      0.149     -0.999      0.318      -0.442       0.144\n",
       "drying             -0.3595      0.123     -2.913      0.004      -0.601      -0.118\n",
       "dusk                0.5144      0.359      1.434      0.152      -0.189       1.218\n",
       "earth               0.9772      0.272      3.594      0.000       0.444       1.510\n",
       "earthy              0.4293      0.339      1.268      0.205      -0.234       1.093\n",
       "edge                0.3965      0.215      1.844      0.065      -0.025       0.818\n",
       "edged               0.0179      0.311      0.058      0.954      -0.592       0.627\n",
       "effervescent        0.6090      0.389      1.566      0.117      -0.153       1.371\n",
       "elegant             0.6437      0.250      2.571      0.010       0.153       1.135\n",
       "elegantly           0.7405      0.229      3.231      0.001       0.291       1.190\n",
       "emerge             -0.1342      0.345     -0.389      0.697      -0.811       0.542\n",
       "emerges             0.0020      0.269      0.007      0.994      -0.525       0.529\n",
       "engaging            0.1087      0.314      0.347      0.729      -0.506       0.723\n",
       "enveloped           0.0828      0.314      0.264      0.792      -0.532       0.698\n",
       "espresso            1.6112      0.475      3.391      0.001       0.680       2.543\n",
       "ethan               1.1506      0.633      1.817      0.069      -0.091       2.392\n",
       "evaluated          -0.6210      0.299     -2.079      0.038      -1.207      -0.035\n",
       "excellent           0.2839      0.345      0.822      0.411      -0.393       0.961\n",
       "exhilarating        0.5049      0.321      1.574      0.116      -0.124       1.134\n",
       "exhilaratingly      0.2347      0.384      0.610      0.542      -0.519       0.988\n",
       "exotic              0.7387      0.318      2.324      0.020       0.115       1.362\n",
       "explicit            0.8840      0.370      2.390      0.017       0.159       1.609\n",
       "expressed          -0.0333      0.277     -0.120      0.904      -0.577       0.510\n",
       "fade                0.5925      0.304      1.948      0.051      -0.004       1.189\n",
       "fades              -0.1829      0.282     -0.648      0.517      -0.736       0.371\n",
       "faint              -0.6428      0.257     -2.506      0.012      -1.146      -0.140\n",
       "faintly            -0.6172      0.532     -1.159      0.246      -1.661       0.427\n",
       "fallen             -0.2963      0.544     -0.544      0.586      -1.363       0.771\n",
       "far                 0.3556      0.281      1.267      0.205      -0.195       0.906\n",
       "felt               -0.5135      0.384     -1.336      0.182      -1.267       0.240\n",
       "ferment            -1.2666      0.300     -4.219      0.000      -1.855      -0.678\n",
       "fermented          -1.3325      0.380     -3.504      0.000      -2.078      -0.587\n",
       "fermenty            0.2807      0.305      0.919      0.358      -0.318       0.879\n",
       "fig                 0.3738      0.358      1.044      0.297      -0.328       1.076\n",
       "fine                0.3025      0.224      1.348      0.178      -0.137       0.742\n",
       "fir                -0.0682      0.190     -0.359      0.719      -0.440       0.304\n",
       "flat               -2.4885      0.450     -5.529      0.000      -3.371      -1.606\n",
       "flavor.1           -0.2124      0.140     -1.517      0.129      -0.487       0.062\n",
       "flavors            -0.2424      0.299     -0.811      0.417      -0.828       0.344\n",
       "floral              0.6570      0.137      4.791      0.000       0.388       0.926\n",
       "florals             0.1249      0.183      0.684      0.494      -0.233       0.483\n",
       "flower              1.1551      0.372      3.103      0.002       0.425       1.885\n",
       "flowering          -0.1221      0.553     -0.221      0.825      -1.206       0.962\n",
       "flowers             0.7282      0.154      4.737      0.000       0.427       1.030\n",
       "forward            -0.2171      0.209     -1.038      0.299      -0.627       0.193\n",
       "fragrant            0.7763      0.325      2.388      0.017       0.139       1.414\n",
       "framed              0.1635      0.286      0.572      0.567      -0.397       0.724\n",
       "frankincense        0.2050      0.253      0.811      0.417      -0.291       0.701\n",
       "freesia             0.2752      0.204      1.350      0.177      -0.124       0.675\n",
       "fresh              -0.2731      0.347     -0.787      0.432      -0.954       0.408\n",
       "fruit               0.4583      0.153      2.995      0.003       0.158       0.758\n",
       "fruity              0.3838      0.220      1.741      0.082      -0.048       0.816\n",
       "fudge               0.2744      0.236      1.164      0.245      -0.188       0.737\n",
       "gardenia            0.2398      0.226      1.059      0.290      -0.204       0.684\n",
       "gentle              0.2302      0.127      1.819      0.069      -0.018       0.478\n",
       "gently              0.2925      0.128      2.292      0.022       0.042       0.543\n",
       "ginger              0.1827      0.309      0.591      0.554      -0.423       0.789\n",
       "good               -0.3029      0.258     -1.174      0.240      -0.809       0.203\n",
       "grace               0.0877      0.397      0.221      0.825      -0.691       0.867\n",
       "grape               0.1559      0.255      0.611      0.541      -0.344       0.656\n",
       "grapefruit          0.3868      0.195      1.984      0.047       0.005       0.769\n",
       "grappa              0.6817      0.411      1.660      0.097      -0.123       1.487\n",
       "grass               0.7948      0.496      1.604      0.109      -0.177       1.767\n",
       "great               0.5280      0.335      1.577      0.115      -0.129       1.185\n",
       "green              -0.0395      0.301     -0.131      0.896      -0.629       0.550\n",
       "guava               0.3908      0.275      1.421      0.155      -0.148       0.930\n",
       "hard               -3.3345      0.414     -8.055      0.000      -4.146      -2.523\n",
       "hazelnut            0.2785      0.156      1.789      0.074      -0.027       0.584\n",
       "heavy              -0.4674      0.254     -1.837      0.066      -0.966       0.031\n",
       "herb                0.7265      0.314      2.313      0.021       0.111       1.342\n",
       "herbaceous          0.1439      0.271      0.530      0.596      -0.388       0.676\n",
       "herby              -0.3071      0.338     -0.907      0.364      -0.971       0.356\n",
       "hibiscus           -0.0081      0.327     -0.025      0.980      -0.650       0.633\n",
       "high                0.7567      0.182      4.160      0.000       0.400       1.113\n",
       "hint                0.1173      0.138      0.850      0.395      -0.153       0.388\n",
       "hints               0.0445      0.173      0.258      0.797      -0.294       0.383\n",
       "honey               0.5681      0.180      3.164      0.002       0.216       0.920\n",
       "honeyish            0.9190      0.365      2.516      0.012       0.203       1.635\n",
       "honeysuckle         0.2940      0.211      1.392      0.164      -0.120       0.708\n",
       "hop                 0.1418      0.285      0.497      0.619      -0.418       0.701\n",
       "hot                -0.8638      0.410     -2.108      0.035      -1.667      -0.060\n",
       "impression          2.0986      0.498      4.217      0.000       1.123       3.074\n",
       "impressive          0.5438      0.238      2.280      0.023       0.076       1.011\n",
       "impressively        0.4533      0.243      1.863      0.063      -0.024       0.930\n",
       "influenced          0.5640      0.414      1.364      0.173      -0.247       1.375\n",
       "integrated          0.4379      0.302      1.451      0.147      -0.154       1.029\n",
       "intense             0.4143      0.192      2.156      0.031       0.038       0.791\n",
       "intensely           0.2051      0.236      0.868      0.385      -0.258       0.668\n",
       "intensity          -0.2896      0.456     -0.636      0.525      -1.183       0.604\n",
       "interesting        -1.0493      0.388     -2.703      0.007      -1.810      -0.288\n",
       "intricate           0.2443      0.183      1.337      0.181      -0.114       0.603\n",
       "intricately         0.2900      0.241      1.205      0.228      -0.182       0.762\n",
       "intrigue           -1.0265      0.363     -2.831      0.005      -1.737      -0.316\n",
       "intriguing          0.1489      0.327      0.456      0.648      -0.491       0.789\n",
       "jam                 0.3998      0.419      0.955      0.340      -0.421       1.220\n",
       "jasmine             0.3228      0.186      1.735      0.083      -0.042       0.688\n",
       "jim                 1.7494      0.642      2.725      0.006       0.491       3.008\n",
       "juicy               0.2147      0.141      1.522      0.128      -0.062       0.491\n",
       "just                0.1313      0.384      0.342      0.733      -0.622       0.885\n",
       "ken                -0.5341      0.393     -1.359      0.174      -1.304       0.236\n",
       "kenya               1.9577      0.398      4.919      0.000       1.177       2.738\n",
       "keurig              0.8358      0.719      1.163      0.245      -0.573       2.245\n",
       "key                -0.6026      0.398     -1.512      0.131      -1.384       0.179\n",
       "knit                1.5100      0.549      2.748      0.006       0.433       2.587\n",
       "laden               0.3361      0.237      1.415      0.157      -0.129       0.802\n",
       "lavender            0.2097      0.178      1.177      0.239      -0.140       0.559\n",
       "layered             0.0465      0.267      0.174      0.862      -0.476       0.569\n",
       "layers              0.6325      0.377      1.677      0.094      -0.107       1.372\n",
       "lead                0.0311      0.249      0.125      0.901      -0.457       0.520\n",
       "leads               0.0706      0.180      0.393      0.694      -0.282       0.423\n",
       "leaf                0.3050      0.384      0.793      0.428      -0.449       1.059\n",
       "lean               -0.7622      0.306     -2.493      0.013      -1.362      -0.163\n",
       "leaning             0.1476      0.234      0.630      0.529      -0.312       0.607\n",
       "leanish            -0.4198      0.329     -1.277      0.202      -1.064       0.225\n",
       "leather             0.6368      0.441      1.445      0.149      -0.227       1.501\n",
       "leaves              0.9602      0.554      1.732      0.083      -0.127       2.047\n",
       "lemon               0.3187      0.164      1.946      0.052      -0.002       0.640\n",
       "lemongrass          0.4557      0.411      1.108      0.268      -0.350       1.262\n",
       "lemony              0.6423      0.232      2.765      0.006       0.187       1.098\n",
       "licorice            0.4611      0.510      0.904      0.366      -0.539       1.461\n",
       "light              -0.2469      0.196     -1.262      0.207      -0.630       0.137\n",
       "lightly            -0.1254      0.155     -0.812      0.417      -0.428       0.178\n",
       "like               -0.3822      0.136     -2.805      0.005      -0.649      -0.115\n",
       "lilac               0.2712      0.191      1.422      0.155      -0.103       0.645\n",
       "lily                0.1809      0.182      0.992      0.321      -0.177       0.538\n",
       "lime                0.2623      0.242      1.085      0.278      -0.212       0.737\n",
       "limited            -1.1383      0.455     -2.504      0.012      -2.030      -0.247\n",
       "linger              0.3480      0.264      1.317      0.188      -0.170       0.866\n",
       "lingering          -0.1287      0.211     -0.609      0.542      -0.543       0.285\n",
       "lingers             0.3097      0.291      1.064      0.287      -0.261       0.880\n",
       "little             -0.1523      0.292     -0.521      0.602      -0.725       0.421\n",
       "lively              0.0480      0.141      0.340      0.734      -0.229       0.325\n",
       "long                0.6421      0.133      4.821      0.000       0.381       0.903\n",
       "lovely             -0.0940      0.426     -0.221      0.825      -0.929       0.741\n",
       "low                 0.8690      0.225      3.855      0.000       0.427       1.311\n",
       "lush                0.4356      0.147      2.964      0.003       0.147       0.724\n",
       "lushly              1.0126      0.265      3.825      0.000       0.494       1.532\n",
       "lychee              0.5118      0.254      2.014      0.044       0.014       1.010\n",
       "lyric               0.4797      0.332      1.443      0.149      -0.172       1.132\n",
       "lyrical             0.4321      0.338      1.279      0.201      -0.230       1.095\n",
       "lyrically           0.6829      0.270      2.529      0.011       0.153       1.212\n",
       "macadamia           0.4240      0.409      1.037      0.300      -0.377       1.225\n",
       "magnolia            0.2010      0.183      1.098      0.272      -0.158       0.560\n",
       "maintains           0.3764      0.303      1.241      0.215      -0.218       0.971\n",
       "malt                0.3415      0.465      0.734      0.463      -0.570       1.253\n",
       "malty               0.5710      0.420      1.359      0.174      -0.253       1.395\n",
       "mango               0.4301      0.232      1.854      0.064      -0.025       0.885\n",
       "maple               1.7372      0.654      2.657      0.008       0.456       3.019\n",
       "marjoram            0.4229      0.250      1.694      0.090      -0.067       0.912\n",
       "medium              0.1620      0.174      0.932      0.351      -0.179       0.503\n",
       "melon               0.3095      0.322      0.961      0.337      -0.322       0.941\n",
       "mesquite            0.2190      0.439      0.499      0.618      -0.642       1.080\n",
       "meyer               0.2591      0.331      0.784      0.433      -0.389       0.907\n",
       "mid                 0.5485      0.381      1.439      0.150      -0.199       1.296\n",
       "miguel              1.1495      0.561      2.049      0.041       0.050       2.249\n",
       "mild               -1.0126      0.385     -2.628      0.009      -1.768      -0.257\n",
       "mildly             -0.1861      0.236     -0.788      0.431      -0.649       0.277\n",
       "milk                0.0859      0.234      0.368      0.713      -0.372       0.544\n",
       "mint                0.2454      0.463      0.531      0.596      -0.661       1.152\n",
       "minty               0.0538      0.369      0.146      0.884      -0.669       0.776\n",
       "moist               0.1449      0.327      0.443      0.658      -0.496       0.786\n",
       "molasses            0.4025      0.195      2.063      0.039       0.020       0.785\n",
       "mulberry            0.4285      0.278      1.543      0.123      -0.116       0.973\n",
       "multi               0.3100      0.241      1.286      0.199      -0.163       0.783\n",
       "mushroom            0.4174      0.337      1.239      0.215      -0.243       1.078\n",
       "musk                0.2553      0.295      0.864      0.387      -0.324       0.834\n",
       "musky               0.2093      0.443      0.473      0.636      -0.659       1.077\n",
       "mustiness          -1.1697      0.472     -2.477      0.013      -2.096      -0.244\n",
       "musty              -0.3256      0.400     -0.813      0.416      -1.110       0.459\n",
       "muted              -0.1715      0.232     -0.740      0.460      -0.626       0.283\n",
       "myrrh               0.3363      0.253      1.329      0.184      -0.160       0.833\n",
       "narcissus           0.3465      0.180      1.926      0.054      -0.006       0.699\n",
       "nectar              0.1426      0.361      0.395      0.693      -0.565       0.850\n",
       "nectarine           0.4366      0.329      1.327      0.185      -0.208       1.081\n",
       "nib                -0.0014      0.172     -0.008      0.994      -0.339       0.336\n",
       "nice               -1.8046      0.602     -2.998      0.003      -2.985      -0.625\n",
       "nicely              0.5095      0.239      2.132      0.033       0.041       0.978\n",
       "night              -0.1596      0.246     -0.648      0.517      -0.643       0.323\n",
       "nominated           0.4637      0.413      1.124      0.261      -0.345       1.272\n",
       "nose               -0.5167      0.260     -1.986      0.047      -1.027      -0.007\n",
       "note               -0.1797      0.182     -0.988      0.323      -0.536       0.177\n",
       "notes               0.2977      0.143      2.084      0.037       0.018       0.578\n",
       "nougat              0.2464      0.227      1.084      0.279      -0.199       0.692\n",
       "nuance              0.2310      0.259      0.892      0.372      -0.277       0.739\n",
       "nuanced             0.3055      0.220      1.386      0.166      -0.127       0.737\n",
       "nut                 0.0419      0.133      0.315      0.753      -0.219       0.303\n",
       "nutella             0.7505      0.419      1.791      0.073      -0.071       1.572\n",
       "nutmeg              0.4901      0.362      1.353      0.176      -0.220       1.200\n",
       "nuts               -1.1144      0.441     -2.525      0.012      -1.980      -0.249\n",
       "nutty              -0.0240      0.243     -0.099      0.921      -0.501       0.453\n",
       "oak                 0.2704      0.170      1.593      0.111      -0.062       0.603\n",
       "opulent             0.5892      0.292      2.016      0.044       0.016       1.162\n",
       "orange              0.4146      0.154      2.685      0.007       0.112       0.717\n",
       "orangy              0.2591      0.266      0.973      0.331      -0.263       0.781\n",
       "orchid              0.4506      0.397      1.136      0.256      -0.327       1.229\n",
       "original            0.2300      0.298      0.771      0.441      -0.355       0.815\n",
       "ounce               0.4106      0.994      0.413      0.680      -1.538       2.359\n",
       "ounces             -1.6078      0.729     -2.204      0.028      -3.038      -0.178\n",
       "overall             0.3111      0.445      0.700      0.484      -0.561       1.183\n",
       "overripe            0.4541      0.427      1.063      0.288      -0.383       1.292\n",
       "owing               0.0036      0.474      0.008      0.994      -0.926       0.933\n",
       "panelists           0.4273      0.476      0.897      0.370      -0.506       1.361\n",
       "papaya              0.2742      0.349      0.785      0.432      -0.410       0.959\n",
       "particular          0.0948      0.197      0.482      0.630      -0.291       0.481\n",
       "particularly       -0.2992      0.266     -1.123      0.261      -0.821       0.223\n",
       "parts               0.3228      0.270      1.198      0.231      -0.206       0.851\n",
       "passion             0.0773      0.404      0.192      0.848      -0.714       0.869\n",
       "passionfruit        0.3121      0.426      0.732      0.464      -0.523       1.148\n",
       "peach               0.2914      0.171      1.708      0.088      -0.043       0.626\n",
       "pear                0.6819      0.221      3.091      0.002       0.249       1.114\n",
       "pecan              -0.1664      0.317     -0.524      0.600      -0.789       0.456\n",
       "peppercorn          0.5412      0.272      1.986      0.047       0.007       1.075\n",
       "perfumy             0.4932      0.336      1.469      0.142      -0.165       1.152\n",
       "persimmon           0.7759      0.322      2.410      0.016       0.145       1.407\n",
       "persist             0.2433      0.218      1.115      0.265      -0.185       0.671\n",
       "persistence         0.6243      0.340      1.835      0.067      -0.043       1.291\n",
       "persistent          0.0498      0.351      0.142      0.887      -0.639       0.739\n",
       "persists            0.0200      0.211      0.095      0.924      -0.394       0.434\n",
       "pert                0.0912      0.236      0.386      0.699      -0.371       0.554\n",
       "pie                 0.4526      0.432      1.048      0.295      -0.394       1.300\n",
       "pine                0.3135      0.339      0.925      0.355      -0.351       0.978\n",
       "pineapple           0.4108      0.256      1.605      0.109      -0.091       0.913\n",
       "pink                0.0737      0.237      0.311      0.756      -0.390       0.538\n",
       "pipe                0.3268      0.392      0.834      0.404      -0.442       1.095\n",
       "pistachio           0.2325      0.277      0.840      0.401      -0.310       0.775\n",
       "platinum            0.0461      1.173      0.039      0.969      -2.255       2.347\n",
       "pleasant            0.4653      0.372      1.250      0.212      -0.265       1.195\n",
       "pleasantly          0.3728      0.208      1.792      0.073      -0.035       0.781\n",
       "pleasing            0.0391      0.203      0.192      0.847      -0.359       0.437\n",
       "pleasingly          0.0069      0.241      0.029      0.977      -0.467       0.480\n",
       "plum                0.2073      0.172      1.208      0.227      -0.129       0.544\n",
       "plumeria            0.7630      0.346      2.204      0.028       0.084       1.442\n",
       "plump               0.1423      0.203      0.702      0.483      -0.255       0.540\n",
       "plush              -0.0531      0.115     -0.460      0.646      -0.279       0.173\n",
       "pod                -1.0049      0.791     -1.271      0.204      -2.555       0.545\n",
       "pomegranate         0.5843      0.235      2.482      0.013       0.123       1.046\n",
       "powder             -0.0897      0.257     -0.349      0.727      -0.593       0.414\n",
       "power              -0.0640      0.442     -0.145      0.885      -0.930       0.802\n",
       "powerful            0.7669      0.328      2.337      0.019       0.124       1.410\n",
       "presence            0.1709      0.271      0.630      0.529      -0.361       0.702\n",
       "pretty              0.1807      0.307      0.588      0.557      -0.422       0.783\n",
       "produce             0.2836      0.727      0.390      0.696      -1.141       1.709\n",
       "produced           -1.7364      0.616     -2.817      0.005      -2.945      -0.528\n",
       "profile             0.2918      0.232      1.259      0.208      -0.163       0.746\n",
       "promise             0.0209      0.317      0.066      0.948      -0.601       0.643\n",
       "pronounced          0.4512      0.276      1.635      0.102      -0.090       0.992\n",
       "prune              -0.6778      0.319     -2.126      0.034      -1.303      -0.053\n",
       "pruny              -2.6363      0.390     -6.766      0.000      -3.400      -1.872\n",
       "pungency            0.6388      0.278      2.296      0.022       0.093       1.184\n",
       "pungent             0.2657      0.149      1.786      0.074      -0.026       0.557\n",
       "pungently           0.5754      0.306      1.880      0.060      -0.025       1.175\n",
       "pure                0.7187      0.249      2.886      0.004       0.230       1.207\n",
       "quickly             0.0481      0.422      0.114      0.909      -0.780       0.876\n",
       "quiet               0.2291      0.172      1.328      0.184      -0.109       0.567\n",
       "quietly             0.3367      0.155      2.174      0.030       0.033       0.640\n",
       "quite               0.0664      0.284      0.234      0.815      -0.491       0.623\n",
       "raisin              0.5175      0.206      2.514      0.012       0.114       0.921\n",
       "raisiny             0.7961      0.293      2.721      0.007       0.222       1.370\n",
       "range               0.3349      0.253      1.326      0.185      -0.160       0.830\n",
       "raspberry           0.4237      0.194      2.183      0.029       0.043       0.804\n",
       "rating             -0.5414      0.367     -1.475      0.140      -1.261       0.178\n",
       "raw                -0.5864      0.536     -1.094      0.274      -1.637       0.464\n",
       "read                0.3088      0.272      1.135      0.256      -0.224       0.842\n",
       "reader              0.1099      0.378      0.291      0.771      -0.631       0.851\n",
       "reads               0.1209      0.284      0.426      0.670      -0.436       0.678\n",
       "ready              -0.2532      1.007     -0.251      0.801      -2.228       1.721\n",
       "red                 0.4446      0.229      1.937      0.053      -0.005       0.894\n",
       "redolent            0.1862      0.282      0.661      0.509      -0.366       0.738\n",
       "refreshing          0.6074      0.340      1.785      0.074      -0.060       1.275\n",
       "relatively          0.6762      0.351      1.929      0.054      -0.011       1.364\n",
       "remains             0.3724      0.303      1.228      0.220      -0.222       0.967\n",
       "resonance           0.1681      0.341      0.493      0.622      -0.500       0.836\n",
       "resonant            0.1181      0.118      1.002      0.317      -0.113       0.349\n",
       "resonantly          0.2082      0.310      0.672      0.502      -0.400       0.816\n",
       "resonate            0.6201      0.365      1.701      0.089      -0.095       1.335\n",
       "resonates           0.3856      0.351      1.098      0.272      -0.303       1.074\n",
       "resurfacing         0.0668      0.312      0.214      0.831      -0.545       0.679\n",
       "retains            -0.5383      0.328     -1.644      0.100      -1.181       0.104\n",
       "rhododendron        0.1941      0.287      0.676      0.499      -0.369       0.757\n",
       "rich                0.3162      0.108      2.923      0.003       0.104       0.528\n",
       "richly              0.6254      0.167      3.738      0.000       0.297       0.953\n",
       "richness            0.4609      0.341      1.351      0.177      -0.208       1.130\n",
       "rings              -0.0382      0.299     -0.128      0.898      -0.625       0.548\n",
       "ripe                0.4028      0.158      2.553      0.011       0.093       0.712\n",
       "roast              -0.1325      0.233     -0.569      0.569      -0.589       0.324\n",
       "roasted             0.1241      0.186      0.668      0.504      -0.240       0.488\n",
       "roastiness          0.2285      0.401      0.569      0.569      -0.558       1.015\n",
       "roasty              0.6342      0.273      2.320      0.020       0.098       1.170\n",
       "robust              0.8566      0.413      2.075      0.038       0.047       1.666\n",
       "rose                0.3550      0.191      1.859      0.063      -0.019       0.729\n",
       "rosemary           -0.6414      0.450     -1.426      0.154      -1.523       0.240\n",
       "rough              -0.5255      0.290     -1.809      0.070      -1.095       0.044\n",
       "round               0.0290      0.151      0.193      0.847      -0.266       0.324\n",
       "rounded             0.2254      0.205      1.097      0.273      -0.177       0.628\n",
       "rounding            0.0233      0.185      0.126      0.900      -0.339       0.386\n",
       "roundly             0.1794      0.179      1.001      0.317      -0.172       0.531\n",
       "rounds              0.1041      0.232      0.449      0.654      -0.351       0.559\n",
       "rum                 0.8381      0.433      1.938      0.053      -0.010       1.686\n",
       "rye                 0.1529      0.561      0.273      0.785      -0.947       1.253\n",
       "sage                0.1147      0.307      0.373      0.709      -0.488       0.717\n",
       "salted              0.0936      0.440      0.212      0.832      -0.770       0.957\n",
       "salty              -0.2726      0.273     -0.998      0.318      -0.808       0.263\n",
       "sample             -0.9808      0.466     -2.104      0.035      -1.895      -0.067\n",
       "sandalwood          0.2535      0.147      1.729      0.084      -0.034       0.541\n",
       "sassafras           0.3639      0.482      0.755      0.450      -0.581       1.309\n",
       "satiny             -0.1927      0.111     -1.728      0.084      -0.411       0.026\n",
       "satisfying          0.0197      0.351      0.056      0.955      -0.668       0.708\n",
       "saturate            0.3841      0.359      1.069      0.285      -0.320       1.088\n",
       "saturated           0.6325      0.203      3.110      0.002       0.234       1.031\n",
       "saturates           0.3571      0.293      1.221      0.222      -0.216       0.931\n",
       "savory              0.0651      0.141      0.461      0.645      -0.212       0.342\n",
       "scaled             -0.1117      0.602     -0.186      0.853      -1.292       1.068\n",
       "scorched            0.0026      0.219      0.012      0.990      -0.426       0.431\n",
       "sean                0.8579      0.549      1.562      0.118      -0.219       1.935\n",
       "semi               -0.0232      0.294     -0.079      0.937      -0.599       0.552\n",
       "sensation          -0.2567      0.293     -0.876      0.381      -0.831       0.318\n",
       "serve               0.1423      1.127      0.126      0.900      -2.067       2.351\n",
       "serving            -0.5231      1.218     -0.429      0.668      -2.912       1.865\n",
       "shadow             -1.2718      0.488     -2.604      0.009      -2.229      -0.314\n",
       "shallow            -0.9506      0.388     -2.451      0.014      -1.711      -0.190\n",
       "sharp              -2.8676      0.348     -8.243      0.000      -3.550      -2.186\n",
       "sharpness          -1.4028      0.378     -3.711      0.000      -2.144      -0.662\n",
       "shifting            0.3932      0.324      1.213      0.225      -0.242       1.029\n",
       "shimmer             0.6130      0.257      2.384      0.017       0.109       1.117\n",
       "short              -0.3539      0.124     -2.859      0.004      -0.597      -0.111\n",
       "shot                0.2185      0.456      0.480      0.631      -0.675       1.112\n",
       "silky              -0.1635      0.138     -1.185      0.236      -0.434       0.107\n",
       "simple             -0.3342      0.200     -1.672      0.095      -0.726       0.058\n",
       "simplifies          0.0154      0.225      0.068      0.946      -0.426       0.457\n",
       "simplify           -0.0633      0.341     -0.186      0.853      -0.732       0.605\n",
       "singed              0.3523      0.451      0.782      0.434      -0.531       1.236\n",
       "single             -1.4266      0.779     -1.832      0.067      -2.953       0.100\n",
       "size               -0.1228      0.504     -0.244      0.807      -1.110       0.865\n",
       "slight              0.7093      0.211      3.366      0.001       0.296       1.122\n",
       "slightly           -0.0024      0.174     -0.014      0.989      -0.343       0.338\n",
       "small              -0.0994      0.259     -0.384      0.701      -0.607       0.408\n",
       "smoke              -0.4267      0.420     -1.015      0.310      -1.251       0.398\n",
       "smoky              -0.1119      0.240     -0.466      0.641      -0.582       0.358\n",
       "smooth             -0.0448      0.107     -0.421      0.674      -0.254       0.164\n",
       "smoothes            0.4497      0.347      1.296      0.195      -0.231       1.130\n",
       "smoothly           -0.0019      0.251     -0.008      0.994      -0.493       0.489\n",
       "soft                0.5745      0.203      2.823      0.005       0.176       0.973\n",
       "soften              0.3519      0.330      1.065      0.287      -0.296       0.999\n",
       "softened            0.2248      0.330      0.681      0.496      -0.423       0.873\n",
       "softening          -0.3135      0.394     -0.795      0.426      -1.086       0.459\n",
       "softens            -0.1577      0.235     -0.672      0.502      -0.618       0.303\n",
       "softly              0.2688      0.241      1.115      0.265      -0.204       0.742\n",
       "solid              -0.4953      0.326     -1.521      0.128      -1.134       0.143\n",
       "somewhat           -0.3436      0.428     -0.802      0.423      -1.184       0.496\n",
       "sort               -0.3016      0.291     -1.035      0.301      -0.873       0.270\n",
       "sour               -0.9182      0.479     -1.917      0.055      -1.857       0.021\n",
       "spearmint           0.7081      0.409      1.732      0.083      -0.093       1.509\n",
       "spice               0.4405      0.205      2.151      0.032       0.039       0.842\n",
       "spices              0.4998      0.314      1.592      0.111      -0.116       1.115\n",
       "spicy               0.1615      0.212      0.761      0.447      -0.255       0.578\n",
       "star                0.2737      0.270      1.014      0.311      -0.256       0.803\n",
       "stone               0.0889      0.293      0.303      0.762      -0.486       0.664\n",
       "straight            0.9124      0.344      2.653      0.008       0.238       1.587\n",
       "straightforward     0.0541      0.263      0.206      0.837      -0.462       0.570\n",
       "strawberry          0.2280      0.242      0.944      0.345      -0.246       0.702\n",
       "structure          -0.2161      0.141     -1.528      0.127      -0.493       0.061\n",
       "style              -0.1919      0.346     -0.555      0.579      -0.870       0.487\n",
       "subdued             0.4246      0.268      1.583      0.113      -0.101       0.950\n",
       "substantial        -0.7526      0.423     -1.781      0.075      -1.581       0.076\n",
       "subtle              0.7578      0.290      2.616      0.009       0.190       1.326\n",
       "subtly             -0.0361      0.192     -0.187      0.851      -0.413       0.341\n",
       "sugar              -0.9960      0.774     -1.287      0.198      -2.513       0.522\n",
       "sugary              0.7843      0.309      2.538      0.011       0.178       1.390\n",
       "suggest             0.7387      0.370      1.994      0.046       0.012       1.465\n",
       "suggesting          0.4651      0.280      1.659      0.097      -0.084       1.015\n",
       "suggestion          0.0846      0.222      0.381      0.703      -0.351       0.520\n",
       "suggestions        -0.1680      0.172     -0.976      0.329      -0.505       0.169\n",
       "suggests            0.1554      0.337      0.461      0.645      -0.505       0.816\n",
       "sumatra             0.6128      0.384      1.597      0.110      -0.139       1.365\n",
       "superb              0.9087      0.263      3.453      0.001       0.393       1.425\n",
       "support             0.3024      0.398      0.759      0.448      -0.479       1.083\n",
       "supported           0.1792      0.209      0.857      0.392      -0.231       0.589\n",
       "supporting          0.2884      0.392      0.736      0.462      -0.480       1.056\n",
       "surfaces           -0.6810      0.314     -2.166      0.030      -1.298      -0.065\n",
       "surprising          1.1399      0.384      2.972      0.003       0.388       1.892\n",
       "surprisingly        0.3284      0.239      1.373      0.170      -0.140       0.797\n",
       "sustained          -0.0469      0.311     -0.151      0.880      -0.657       0.563\n",
       "sweet               0.2672      0.130      2.063      0.039       0.013       0.521\n",
       "sweetening         -0.0576      0.359     -0.160      0.873      -0.761       0.646\n",
       "sweetens            0.6322      0.239      2.643      0.008       0.163       1.101\n",
       "sweetly             0.2099      0.126      1.667      0.096      -0.037       0.457\n",
       "sweetness           0.5802      0.234      2.481      0.013       0.122       1.039\n",
       "syrup              -1.3917      0.655     -2.126      0.034      -2.675      -0.108\n",
       "syrupy             -0.2425      0.162     -1.494      0.135      -0.561       0.076\n",
       "tamarind            0.6992      0.232      3.010      0.003       0.244       1.155\n",
       "tangerine           0.3016      0.184      1.636      0.102      -0.060       0.663\n",
       "tangy               0.3414      0.387      0.881      0.378      -0.418       1.101\n",
       "tart                0.0790      0.145      0.544      0.586      -0.205       0.363\n",
       "tartly              0.0104      0.229      0.045      0.964      -0.439       0.460\n",
       "taste              -2.2688      0.335     -6.770      0.000      -2.926      -1.612\n",
       "taster             -0.7303      0.608     -1.200      0.230      -1.923       0.463\n",
       "tea                -0.0090      0.256     -0.035      0.972      -0.512       0.494\n",
       "ted                 0.4908      0.511      0.960      0.337      -0.512       1.493\n",
       "tested             -1.3233      0.867     -1.527      0.127      -3.022       0.376\n",
       "textured           -0.0047      0.379     -0.012      0.990      -0.748       0.739\n",
       "think              -0.3643      0.358     -1.018      0.309      -1.066       0.337\n",
       "throughline        -0.0549      0.307     -0.179      0.858      -0.656       0.546\n",
       "thyme               0.0766      0.264      0.290      0.772      -0.441       0.594\n",
       "tickle              0.4624      0.338      1.368      0.171      -0.200       1.125\n",
       "tight              -0.9219      0.503     -1.834      0.067      -1.908       0.064\n",
       "toast               0.0164      0.292      0.056      0.955      -0.556       0.588\n",
       "toasted            -0.1762      0.405     -0.435      0.664      -0.971       0.618\n",
       "toasty              1.0435      0.447      2.335      0.020       0.167       1.920\n",
       "tobacco             0.0507      0.422      0.120      0.904      -0.776       0.877\n",
       "toffee              0.2754      0.247      1.116      0.264      -0.208       0.759\n",
       "tomato              0.0507      0.299      0.169      0.866      -0.536       0.638\n",
       "toned              -0.1698      0.138     -1.229      0.219      -0.441       0.101\n",
       "tones              -0.0164      0.174     -0.094      0.925      -0.358       0.325\n",
       "touch               0.6071      0.296      2.053      0.040       0.027       1.187\n",
       "tropical            0.5359      0.311      1.723      0.085      -0.074       1.146\n",
       "turn                0.4446      0.306      1.451      0.147      -0.156       1.045\n",
       "turned              0.2158      0.409      0.527      0.598      -0.586       1.018\n",
       "turning            -1.0458      0.321     -3.259      0.001      -1.675      -0.417\n",
       "turns              -0.1486      0.174     -0.852      0.394      -0.491       0.193\n",
       "underlying          0.7531      0.373      2.021      0.043       0.023       1.484\n",
       "understated        -0.0309      0.332     -0.093      0.926      -0.683       0.621\n",
       "undertones          0.1018      0.134      0.758      0.448      -0.161       0.365\n",
       "unusual             0.2573      0.312      0.825      0.410      -0.355       0.869\n",
       "using               0.5943      0.622      0.956      0.339      -0.625       1.814\n",
       "vanilla            -0.0607      0.160     -0.380      0.704      -0.373       0.252\n",
       "velvety            -0.1262      0.151     -0.837      0.403      -0.422       0.169\n",
       "verbena             0.1458      0.220      0.662      0.508      -0.286       0.578\n",
       "version            -0.5490      0.348     -1.579      0.114      -1.231       0.133\n",
       "vibrant             0.2710      0.221      1.229      0.219      -0.162       0.704\n",
       "vibrantly           0.3633      0.256      1.417      0.157      -0.139       0.866\n",
       "violet              0.1689      0.244      0.693      0.489      -0.309       0.647\n",
       "viscous             0.1532      0.172      0.892      0.373      -0.184       0.490\n",
       "vivacious           0.3707      0.315      1.178      0.239      -0.246       0.988\n",
       "volume             -0.3502      0.944     -0.371      0.711      -2.201       1.501\n",
       "walnut              0.2051      0.228      0.898      0.369      -0.243       0.653\n",
       "water               1.4787      0.630      2.346      0.019       0.243       2.715\n",
       "watermelon          0.1029      0.382      0.270      0.788      -0.645       0.851\n",
       "way                 0.7849      0.455      1.726      0.084      -0.107       1.676\n",
       "whisky              0.4506      0.511      0.882      0.378      -0.551       1.453\n",
       "white               0.1806      0.281      0.642      0.521      -0.371       0.732\n",
       "wild                0.4234      0.292      1.450      0.147      -0.149       0.996\n",
       "willem              0.1294      0.478      0.271      0.787      -0.808       1.067\n",
       "wine                1.7887      0.238      7.517      0.000       1.322       2.255\n",
       "winy                1.3868      0.340      4.084      0.000       0.721       2.053\n",
       "wisteria            0.2205      0.243      0.907      0.364      -0.256       0.697\n",
       "wood               -0.0255      0.246     -0.104      0.917      -0.507       0.456\n",
       "woody              -1.6804      0.370     -4.541      0.000      -2.406      -0.955\n",
       "zest                0.1572      0.145      1.083      0.279      -0.127       0.442\n",
       "zesty               0.0675      0.274      0.246      0.805      -0.470       0.605\n",
       "==============================================================================\n",
       "Omnibus:                     1123.358   Durbin-Watson:                   2.005\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            48378.375\n",
       "Skew:                          -0.518   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.606   Cond. No.                         268.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Instantiate Model\n",
    "final_model = sm.OLS(y_remain, X_mm_remain_constant)\n",
    "\n",
    "# 2. Fit Model (this returns a seperate object with the parameters)\n",
    "final_model_results = final_model.fit()\n",
    "\n",
    "# Looking at the summary\n",
    "final_model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53d695",
   "metadata": {},
   "source": [
    "This basic version has a pretty strong R2 value as is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b89e79",
   "metadata": {},
   "source": [
    "Given the number of variables, it will be useful to sort the coef and p values. This will highlight which coefficients are strongest, and which have the strongest p-value, indicating that there is a real relationship there and its very unlikely that the finding is just due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a97c23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = final_model_results.pvalues\n",
    "coeff = final_model_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a768686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'pvals': pvalues, 'coeff': coeff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a7cfe30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          0.000000e+00\n",
       "aroma         6.447536e-198\n",
       "body           1.671878e-85\n",
       "aftertaste     1.139581e-66\n",
       "acidity        2.808161e-48\n",
       "                  ...      \n",
       "nib            9.936214e-01\n",
       "smoothly       9.937915e-01\n",
       "owing          9.939611e-01\n",
       "emerges        9.940881e-01\n",
       "cited          9.951813e-01\n",
       "Name: pvals, Length: 631, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have lowest p-values\n",
    "results_df['pvals'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "301de1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cups          -3.666332\n",
       "hard          -3.334453\n",
       "sharp         -2.867576\n",
       "pruny         -2.636289\n",
       "flat          -2.488458\n",
       "taste         -2.268752\n",
       "nice          -1.804585\n",
       "produced      -1.736396\n",
       "woody         -1.680383\n",
       "brewing       -1.660594\n",
       "ounces        -1.607816\n",
       "bitter        -1.593575\n",
       "burned        -1.548007\n",
       "single        -1.426630\n",
       "sharpness     -1.402802\n",
       "syrup         -1.391686\n",
       "fermented     -1.332488\n",
       "tested        -1.323276\n",
       "shadow        -1.271760\n",
       "ferment       -1.266647\n",
       "capsule       -1.213137\n",
       "mustiness     -1.169683\n",
       "limited       -1.138262\n",
       "nuts          -1.114368\n",
       "astringency   -1.058132\n",
       "interesting   -1.049306\n",
       "turning       -1.045835\n",
       "intrigue      -1.026479\n",
       "mild          -1.012632\n",
       "pod           -1.004869\n",
       "sugar         -0.995962\n",
       "sample        -0.980799\n",
       "dimension     -0.962583\n",
       "shallow       -0.950614\n",
       "tight         -0.921932\n",
       "astringent    -0.919369\n",
       "sour          -0.918180\n",
       "hot           -0.863846\n",
       "bean_agtron   -0.857069\n",
       "bitterish     -0.819133\n",
       "lean          -0.762218\n",
       "substantial   -0.752649\n",
       "taster        -0.730263\n",
       "attractive    -0.726926\n",
       "surfaces      -0.681049\n",
       "prune         -0.677753\n",
       "origin_lat    -0.663736\n",
       "faint         -0.642812\n",
       "rosemary      -0.641436\n",
       "evaluated     -0.621025\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have strongest negative coeff\n",
    "results_df['coeff'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44bdccb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const            66.885003\n",
       "aroma             9.072227\n",
       "aftertaste        6.036401\n",
       "acidity           5.271777\n",
       "body              4.538222\n",
       "flavor            4.401500\n",
       "device            2.438479\n",
       "impression        2.098567\n",
       "cold              2.083839\n",
       "kenya             1.957656\n",
       "wine              1.788698\n",
       "brewer            1.756532\n",
       "best              1.754638\n",
       "jim               1.749378\n",
       "maple             1.737234\n",
       "espresso          1.611224\n",
       "knit              1.509965\n",
       "brown             1.506762\n",
       "water             1.478715\n",
       "balance           1.478537\n",
       "ground_agtron     1.439422\n",
       "cherryish         1.427809\n",
       "agave             1.411080\n",
       "winy              1.386787\n",
       "flower            1.155079\n",
       "berry             1.154712\n",
       "ethan             1.150636\n",
       "miguel            1.149456\n",
       "surprising        1.139928\n",
       "toasty            1.043473\n",
       "lushly            1.012561\n",
       "earth             0.977164\n",
       "leaves            0.960167\n",
       "byron             0.936812\n",
       "honeyish          0.918957\n",
       "straight          0.912373\n",
       "superb            0.908711\n",
       "deepens           0.888830\n",
       "explicit          0.883973\n",
       "low               0.868995\n",
       "sean              0.857915\n",
       "robust            0.856623\n",
       "aftertaste.1      0.852430\n",
       "butterscotch      0.846079\n",
       "cane              0.845391\n",
       "bodied            0.842732\n",
       "rum               0.838126\n",
       "keurig            0.835782\n",
       "bracing           0.818996\n",
       "raisiny           0.796107\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have strongest positive coeff\n",
    "results_df['coeff'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a03ffeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const             0.000000e+00\n",
       "aroma            6.447536e-198\n",
       "body              1.671878e-85\n",
       "aftertaste        1.139581e-66\n",
       "acidity           2.808161e-48\n",
       "flavor            1.216882e-39\n",
       "sharp             2.335595e-16\n",
       "hard              1.072871e-15\n",
       "cups              2.872930e-14\n",
       "wine              7.045913e-14\n",
       "taste             1.501059e-11\n",
       "pruny             1.544540e-11\n",
       "berry             3.479064e-10\n",
       "balance           3.752362e-09\n",
       "cherryish         1.805471e-08\n",
       "flat              3.451145e-08\n",
       "chocolate         2.415010e-07\n",
       "kenya             9.101756e-07\n",
       "long              1.484716e-06\n",
       "floral            1.728150e-06\n",
       "flowers           2.253615e-06\n",
       "ground_agtron     4.259815e-06\n",
       "woody             5.771337e-06\n",
       "astringency       9.970650e-06\n",
       "complex           1.365204e-05\n",
       "bitter            2.179252e-05\n",
       "ferment           2.513399e-05\n",
       "impression        2.532665e-05\n",
       "astringent        2.752585e-05\n",
       "high              3.254102e-05\n",
       "winy              4.522906e-05\n",
       "bodied            5.220893e-05\n",
       "origin_lat        7.616854e-05\n",
       "best              9.534003e-05\n",
       "low               1.176319e-04\n",
       "burned            1.226720e-04\n",
       "lushly            1.328048e-04\n",
       "richly            1.881589e-04\n",
       "sharpness         2.098927e-04\n",
       "cocoa             2.125174e-04\n",
       "deeply            2.983739e-04\n",
       "earth             3.304836e-04\n",
       "fermented         4.644582e-04\n",
       "superb            5.617574e-04\n",
       "espresso          7.051135e-04\n",
       "slight            7.700372e-04\n",
       "apple             9.061115e-04\n",
       "complicated       9.572731e-04\n",
       "deepens           1.044598e-03\n",
       "turning           1.127168e-03\n",
       "Name: pvals, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have lowest pvalues\n",
    "results_df['pvals'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77918bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cited           0.995181\n",
       "emerges         0.994088\n",
       "owing           0.993961\n",
       "smoothly        0.993792\n",
       "nib             0.993621\n",
       "scorched        0.990468\n",
       "baking          0.990392\n",
       "textured        0.990136\n",
       "slightly        0.988923\n",
       "roaster_lon     0.986894\n",
       "hibiscus        0.980340\n",
       "pleasingly      0.977215\n",
       "did             0.973663\n",
       "tea             0.971926\n",
       "platinum        0.968645\n",
       "amplified       0.964061\n",
       "tartly          0.963871\n",
       "buoyant         0.955770\n",
       "satisfying      0.955346\n",
       "toast           0.955132\n",
       "edged           0.954095\n",
       "blooms          0.951438\n",
       "promise         0.947610\n",
       "simplifies      0.945603\n",
       "centered        0.945062\n",
       "semi            0.937007\n",
       "brightness      0.930666\n",
       "understated     0.926056\n",
       "tones           0.924943\n",
       "persists        0.924364\n",
       "nutty           0.921356\n",
       "blend           0.921330\n",
       "wood            0.917367\n",
       "dominated       0.912683\n",
       "quickly         0.909343\n",
       "expressed       0.904476\n",
       "tobacco         0.904270\n",
       "lead            0.900776\n",
       "rounding        0.899831\n",
       "serve           0.899538\n",
       "rings           0.898229\n",
       "green           0.895569\n",
       "described       0.894739\n",
       "blossom         0.890751\n",
       "complicating    0.888364\n",
       "persistent      0.887233\n",
       "authority       0.886192\n",
       "power           0.884867\n",
       "minty           0.883931\n",
       "sustained       0.880074\n",
       "Name: pvals, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which have highest pvalues\n",
    "results_df['pvals'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "15356419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pvals</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>66.885003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bean_agtron</th>\n",
       "      <td>2.170556e-02</td>\n",
       "      <td>-0.857069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ground_agtron</th>\n",
       "      <td>4.259815e-06</td>\n",
       "      <td>1.439422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aroma</th>\n",
       "      <td>6.447536e-198</td>\n",
       "      <td>9.072227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acidity</th>\n",
       "      <td>2.808161e-48</td>\n",
       "      <td>5.271777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>underlying</th>\n",
       "      <td>4.330379e-02</td>\n",
       "      <td>0.753095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>1.904994e-02</td>\n",
       "      <td>1.478715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>7.045913e-14</td>\n",
       "      <td>1.788698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winy</th>\n",
       "      <td>4.522906e-05</td>\n",
       "      <td>1.386787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woody</th>\n",
       "      <td>5.771337e-06</td>\n",
       "      <td>-1.680383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pvals      coeff\n",
       "const           0.000000e+00  66.885003\n",
       "bean_agtron     2.170556e-02  -0.857069\n",
       "ground_agtron   4.259815e-06   1.439422\n",
       "aroma          6.447536e-198   9.072227\n",
       "acidity         2.808161e-48   5.271777\n",
       "...                      ...        ...\n",
       "underlying      4.330379e-02   0.753095\n",
       "water           1.904994e-02   1.478715\n",
       "wine            7.045913e-14   1.788698\n",
       "winy            4.522906e-05   1.386787\n",
       "woody           5.771337e-06  -1.680383\n",
       "\n",
       "[164 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_results_df = results_df.loc[results_df['pvals'] <= 0.05]\n",
    "sig_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd12fcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cups          -3.666332\n",
       "hard          -3.334453\n",
       "sharp         -2.867576\n",
       "pruny         -2.636289\n",
       "flat          -2.488458\n",
       "taste         -2.268752\n",
       "nice          -1.804585\n",
       "produced      -1.736396\n",
       "woody         -1.680383\n",
       "ounces        -1.607816\n",
       "bitter        -1.593575\n",
       "burned        -1.548007\n",
       "sharpness     -1.402802\n",
       "syrup         -1.391686\n",
       "fermented     -1.332488\n",
       "shadow        -1.271760\n",
       "ferment       -1.266647\n",
       "mustiness     -1.169683\n",
       "limited       -1.138262\n",
       "nuts          -1.114368\n",
       "astringency   -1.058132\n",
       "interesting   -1.049306\n",
       "turning       -1.045835\n",
       "intrigue      -1.026479\n",
       "mild          -1.012632\n",
       "sample        -0.980799\n",
       "dimension     -0.962583\n",
       "shallow       -0.950614\n",
       "astringent    -0.919369\n",
       "hot           -0.863846\n",
       "bean_agtron   -0.857069\n",
       "bitterish     -0.819133\n",
       "lean          -0.762218\n",
       "attractive    -0.726926\n",
       "surfaces      -0.681049\n",
       "prune         -0.677753\n",
       "origin_lat    -0.663736\n",
       "faint         -0.642812\n",
       "evaluated     -0.621025\n",
       "complicated   -0.554697\n",
       "nose          -0.516739\n",
       "like          -0.382200\n",
       "drying        -0.359497\n",
       "short         -0.353925\n",
       "balanced       0.237337\n",
       "sweet          0.267153\n",
       "cedar          0.273824\n",
       "gently         0.292512\n",
       "bright         0.294092\n",
       "notes          0.297679\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which variables with significant pvalues have strongest neg coeff\n",
    "sig_results_df['coeff'].sort_values()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f51ac319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const            66.885003\n",
       "aroma             9.072227\n",
       "aftertaste        6.036401\n",
       "acidity           5.271777\n",
       "body              4.538222\n",
       "flavor            4.401500\n",
       "impression        2.098567\n",
       "cold              2.083839\n",
       "kenya             1.957656\n",
       "wine              1.788698\n",
       "brewer            1.756532\n",
       "best              1.754638\n",
       "jim               1.749378\n",
       "maple             1.737234\n",
       "espresso          1.611224\n",
       "knit              1.509965\n",
       "water             1.478715\n",
       "balance           1.478537\n",
       "ground_agtron     1.439422\n",
       "cherryish         1.427809\n",
       "agave             1.411080\n",
       "winy              1.386787\n",
       "flower            1.155079\n",
       "berry             1.154712\n",
       "miguel            1.149456\n",
       "surprising        1.139928\n",
       "toasty            1.043473\n",
       "lushly            1.012561\n",
       "earth             0.977164\n",
       "honeyish          0.918957\n",
       "straight          0.912373\n",
       "superb            0.908711\n",
       "deepens           0.888830\n",
       "explicit          0.883973\n",
       "low               0.868995\n",
       "robust            0.856623\n",
       "aftertaste.1      0.852430\n",
       "butterscotch      0.846079\n",
       "bodied            0.842732\n",
       "bracing           0.818996\n",
       "raisiny           0.796107\n",
       "sugary            0.784343\n",
       "fragrant          0.776319\n",
       "persimmon         0.775899\n",
       "powerful          0.766900\n",
       "plumeria          0.763021\n",
       "subtle            0.757755\n",
       "high              0.756682\n",
       "chocolate         0.755799\n",
       "underlying        0.753095\n",
       "Name: coeff, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting to see which variables with significant pvalues have strongest pos coeff\n",
    "sig_results_df['coeff'].sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### continue - sort\n",
    "\n",
    "# make coeff absolute to compare strength or chart with some kind of limit (top 50)\n",
    "#find top 50 for lowest p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "8fe811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#picklign model\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "savedir = mkdtemp()\n",
    "\n",
    "import os\n",
    "filename = os.path.join(savedir, 'test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c76012eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/var/folders/jm/x73vvhpx2cd14qw0zx2ccfsc0000gn/T/tmpjmg6rmr_/test.joblib']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(final_model_results, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd0880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
