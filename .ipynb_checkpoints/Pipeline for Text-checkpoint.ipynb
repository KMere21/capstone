{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b64dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tempfile import mkdtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e42c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv('coffee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391860dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = coffee[['p1','overall_score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5685fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blind Assessment: Elegantly fruit- and cocoa-t...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blind Assessment: Gently fruit-toned, integrat...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blind Assessment: Richly sweet, spice-toned. L...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blind Assessment: Gently fruit-forward, sweetl...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blind Assessment: Gently sweet-tart, floral-to...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>Blind Assessment: Pungent, chocolate notes enl...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553</th>\n",
       "      <td>Blind Assessment: An intense coffee, particula...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>Blind Assessment: An exquisitely balanced trad...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6555</th>\n",
       "      <td>Blind Assessment: This coffee gets better as i...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6556</th>\n",
       "      <td>Blind Assessment: This coffee is so complex at...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6557 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     p1  overall_score\n",
       "0     Blind Assessment: Elegantly fruit- and cocoa-t...             94\n",
       "1     Blind Assessment: Gently fruit-toned, integrat...             94\n",
       "2     Blind Assessment: Richly sweet, spice-toned. L...             93\n",
       "3     Blind Assessment: Gently fruit-forward, sweetl...             92\n",
       "4     Blind Assessment: Gently sweet-tart, floral-to...             93\n",
       "...                                                 ...            ...\n",
       "6552  Blind Assessment: Pungent, chocolate notes enl...             74\n",
       "6553  Blind Assessment: An intense coffee, particula...             77\n",
       "6554  Blind Assessment: An exquisitely balanced trad...             90\n",
       "6555  Blind Assessment: This coffee gets better as i...             88\n",
       "6556  Blind Assessment: This coffee is so complex at...             85\n",
       "\n",
       "[6557 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e12c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ecfa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['overall_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f82209b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 594, in __call__\n    return self._cached_call(args, kwargs)[0]\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 537, in _cached_call\n    out, metadata = self.call(*args, **kwargs)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 779, in call\n    output = self.func(*args, **kwargs)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 2079, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1338, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1209, in _count_vocab\n    for feature in analyze(doc):\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 111, in _analyze\n    doc = preprocessor(doc)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 69, in _preprocess\n    doc = doc.lower()\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/scipy/sparse/base.py\", line 687, in __getattr__\n    raise AttributeError(attr + \" not found\")\nAttributeError: lower not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, parameters, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m fittedgrid \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    850\u001b[0m     )\n\u001b[0;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 594, in __call__\n    return self._cached_call(args, kwargs)[0]\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 537, in _cached_call\n    out, metadata = self.call(*args, **kwargs)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/joblib/memory.py\", line 779, in call\n    output = self.func(*args, **kwargs)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 2079, in fit_transform\n    X = super().fit_transform(raw_documents)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1338, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 1209, in _count_vocab\n    for feature in analyze(doc):\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 111, in _analyze\n    doc = preprocessor(doc)\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\", line 69, in _preprocess\n    doc = doc.lower()\n  File \"/Users/katemondal/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/scipy/sparse/base.py\", line 687, in __getattr__\n    raise AttributeError(attr + \" not found\")\nAttributeError: lower not found\n"
     ]
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "estimators = [(\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"model\", LinearRegression())]\n",
    "\n",
    "pipeline = Pipeline(estimators, memory=cachedir)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": [500,1000,10000],\n",
    "    \"vect__stop_words\": ['english'],\n",
    "    \"tfidf__stop_words\": ['english'],\n",
    "    \"tfidf__max_features\": [None, 100, 2000],\n",
    "    \"tfidf__min_df\": [1,50],\n",
    "    'model': [LinearRegression()],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd5446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
